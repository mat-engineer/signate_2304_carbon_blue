{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03a0877d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import pickle\n",
    "import csv\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import lightgbm as lgb\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e12b79",
   "metadata": {},
   "source": [
    "# 1 データ読み込み\n",
    "- trainデータとtestデータ共に読み込んでマージ、不要な情報列を削除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5b3071e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tr = pd.read_csv('train_data.csv',index_col=0)\n",
    "df_test = pd.read_csv(\"test_data.csv\",index_col=0)\n",
    "df_test['cover'] = 'a'\n",
    "df = pd.concat([df_tr,df_test])\n",
    "df.drop(columns=['Landsat_StartTime','YMD','PRODUCT_ID'],inplace=True)\n",
    "df['year'] = df['year'].astype(int)\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d19c5a",
   "metadata": {},
   "source": [
    "# 2 データ前処理\n",
    "## 2-1 クラスタリング\n",
    "### 2-1-1 ラベルエンコーディング\n",
    "- 'mesh20'をラベルエンコーディング実施"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ea2e671",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()    \n",
    "le.fit(df[['mesh20']])\n",
    "list_label = sorted(list(set(le.classes_)))\n",
    "map_label = {j:i for i,j in enumerate(list_label)}\n",
    "dict_mesh = {}\n",
    "dict_mesh['map_label'] = map_label\n",
    "map_label = dict_mesh['map_label']\n",
    "df['mesh20'] = df['mesh20'].map(map_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a41ecc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tr = df[df['cover']!='a']\n",
    "df_ts = df[df['cover'] == 'a']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e8f7f6",
   "metadata": {},
   "source": [
    "### 2-1-2 地理的に３つの区域（３クラス）にクラスタリング\n",
    "- 経度、緯度情報のみを使用して３クラスに分類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef4eb3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "clst = KMeans(n_clusters=3,\n",
    "            init='k-means++',\n",
    "            n_init=10,\n",
    "            max_iter=300,\n",
    "            random_state=0)\n",
    "pred = clst.fit_predict(df_tr[['lat','lon']])\n",
    "df_tr['cluster_id'] = pred\n",
    "pred_ts = clst.predict(df_ts[['lat', 'lon']])\n",
    "df_ts['cluster_id'] = pred_ts\n",
    "df = pd.concat([df_tr,df_ts])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c767cda6",
   "metadata": {},
   "source": [
    "### 2-1-3 サブクラス作成\n",
    "- 3つの区域（クラス）毎にサブクラスを３クラス作成_今回は全データを使ってクラスタリング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "401ced98",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tr = df[df['cover'] != 'a']\n",
    "df_ts = df[df['cover'] == 'a']\n",
    "df_ts = df_ts.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10faa4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cls_tr = df_tr.copy()\n",
    "df_cls_tr.drop(columns=['cover','cluster_id'],inplace=True)\n",
    "df_cls_tr = df_cls_tr.fillna(df_cls_tr.median())\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(df_cls_tr)\n",
    "df_cls_tr = pd.DataFrame(scaler.transform(df_cls_tr),columns=df_cls_tr.columns)\n",
    "df_cls_tr['cluster_id'] = df_tr['cluster_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1f8a583",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cls_ts = df_ts.copy()\n",
    "df_cls_ts.drop(columns=['cover','cluster_id'],inplace=True)\n",
    "df_cls_ts = df_cls_ts.fillna(df_cls_ts.median())\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(df_cls_ts)\n",
    "df_cls_ts = pd.DataFrame(scaler.transform(df_cls_ts),columns=df_cls_ts.columns)\n",
    "df_cls_ts['cluster_id'] = df_ts['cluster_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f36052cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "clst = KMeans(n_clusters=3,\n",
    "            init='k-means++',\n",
    "            n_init=10,\n",
    "            max_iter=300,\n",
    "            random_state=0)\n",
    "tmp_df_tr = pd.DataFrame()\n",
    "for i in range(3):\n",
    "    pred = clst.fit_predict(df_cls_tr[df_cls_tr['cluster_id'] == i])\n",
    "    filename = 'kmeans_model.pkl'\n",
    "    pickle.dump(clst, open(filename, 'wb'))\n",
    "    tmp_tr = pd.DataFrame({'id': df_cls_tr[df_cls_tr['cluster_id'] == i].index, \n",
    "                        'cls_id_2': pred})\n",
    "    \n",
    "    tmp_df_tr = pd.concat([tmp_df_tr,tmp_tr])\n",
    "    \n",
    "tmp_tr = tmp_df_tr.sort_values('id').reset_index(drop=True)\n",
    "df_tr['cls_id_2'] = tmp_tr['cls_id_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f13ea42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tmp_df_ts = pd.DataFrame()\n",
    "filename = 'kmeans_model.pkl'\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "for i in range(3):\n",
    "    subset = df_cls_ts[df_cls_ts['cluster_id'] == i]\n",
    "    pred_ts = loaded_model.predict(subset)\n",
    "    tmp_ts = pd.DataFrame({'id': df_cls_ts[df_cls_ts['cluster_id'] == i].index, \n",
    "                        'cls_id_2': pred_ts})\n",
    "    tmp_df_ts = pd.concat([tmp_df_ts,tmp_ts])\n",
    "\n",
    "tmp_ts = tmp_df_ts.sort_values('id').reset_index(drop=True)\n",
    "df_ts['cls_id_2'] = tmp_ts['cls_id_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd5ce056",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_tr,df_ts])\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540b6f14",
   "metadata": {},
   "source": [
    "## 2-2 欠損値補完\n",
    "- 主に画像データの欠損値を補完する"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31bb16a5",
   "metadata": {},
   "source": [
    "### 2-2-1 欠損値行の特定\n",
    "   - 画像データのうち、50％以上が欠損値の行を補完する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e428e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 行内のNaNの割合を計算する\n",
    "nan_rows = df.iloc[:,85:3460].isna().sum(axis=1) / df.iloc[:,85:3460].shape[1]\n",
    "# NaNの割合が50%以上の行を抽出する\n",
    "high_nan_rows = df.iloc[:,85:3460][nan_rows >= 0.5]\n",
    "nan_row_list = high_nan_rows.index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc17ef04",
   "metadata": {},
   "source": [
    "### 2-2-2 欠損値補完A\n",
    "- 年毎のランドサットデータは前後1年のデータで補完する、2000年時は2001、2002のデータで補完"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59a34f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillna_with_column_values(arr, row, cols):\n",
    "    for col in cols:\n",
    "        if not np.isnan(arr[row, col]):\n",
    "            return arr[row, col]\n",
    "    return np.nan\n",
    "arr = df.iloc[:,310:3460].to_numpy(dtype=float)\n",
    "# 各列の欠損値を指定された条件で埋める\n",
    "for j in range(3150):\n",
    "    missing_rows = np.where(np.isnan(arr[:, j]))[0]\n",
    "    for i in missing_rows:\n",
    "        if j >= 0 and j < 150:\n",
    "            cols = [j + 150, j + 300]\n",
    "            cols = [col for col in cols if col >= 0 and col < arr.shape[1]]\n",
    "            arr[i, j] = fillna_with_column_values(arr, i, cols)\n",
    "        else:\n",
    "            cols = [j - 150, j + 150]\n",
    "            cols = [col for col in cols if col >= 0 and col < arr.shape[1]]\n",
    "            arr[i, j] = fillna_with_column_values(arr, i, cols)\n",
    "        \n",
    "df.iloc[:,310:3460] = pd.DataFrame(arr, columns=df.iloc[:,310:3460].columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97aae43",
   "metadata": {},
   "source": [
    "### 2-2-3 欠損値補完B\n",
    "- Aで補完できなかった行を補完する\n",
    "- 最寄りの５箇所を特定して、５箇所の平均値で補完する"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3fd679",
   "metadata": {},
   "source": [
    "#### 2-2-3-1 最寄りの５箇所を抽出\n",
    "   - 緯度経度からターゲットから最も近い５箇所を抽出する（trainデータで補完する）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67ed2038",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tr = df[df['cover'] != 'a']\n",
    "\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    R = 6371\n",
    "    lat1_rad, lon1_rad = np.radians(lat1), np.radians(lon1)\n",
    "    lat2_rad, lon2_rad = np.radians(lat2), np.radians(lon2)\n",
    "    dlat = lat2_rad - lat1_rad\n",
    "    dlon = lon2_rad - lon1_rad\n",
    "\n",
    "    a = np.sin(dlat / 2) ** 2 + np.cos(lat1_rad) * np.cos(lat2_rad) * np.sin(dlon / 2) ** 2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
    "    return R * c\n",
    "\n",
    "def closest_n_locations(df, index, n, exclude_indices):\n",
    "    target_lat, target_lon = df.loc[index, 'lat'], df.loc[index, 'lon']\n",
    "    distances = df.apply(lambda row: haversine(\n",
    "        target_lat, target_lon, row['lat'], row['lon']), axis=1)\n",
    "    distances = distances.drop(exclude_indices)\n",
    "    closest_indices = distances.nsmallest(n+1).iloc[1:].index\n",
    "    closest_rows = df.loc[closest_indices].copy()\n",
    "    closest_rows['元の行番号'] = index  \n",
    "    closest_rows['距離'] = distances[closest_indices].values  # 距離を追加\n",
    "    return closest_rows\n",
    "\n",
    "def closest_n_locations_for_indices(df, indices, n):\n",
    "    result_df = pd.DataFrame()\n",
    "    for index in indices:\n",
    "        closest_n = closest_n_locations(df, index, n, indices)\n",
    "        result_df = pd.concat([result_df, closest_n])\n",
    "    return result_df.reset_index().rename(columns={'index': '抽出された行番号'})\n",
    "\n",
    "# リスト内の各行番号に対して最も近い場所5箇所を抽出\n",
    "closest_5_for_indices = closest_n_locations_for_indices(\n",
    "    df_tr[['lat','lon']], nan_row_list, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507aea12",
   "metadata": {},
   "source": [
    "#### 2-2-3-2 ５箇所の平均値で欠損値を補完"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "209de2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = closest_5_for_indices[['元の行番号','抽出された行番号']]\n",
    "for original_index in tmp['元の行番号'].unique():\n",
    "    closest_rows = tmp.loc[tmp['元の行番号'] == original_index, '抽出された行番号']\n",
    "    mean_values = df.iloc[closest_rows,310:3460].mean()\n",
    "    df.iloc[original_index,310:3460] = df.iloc[original_index,310:3460].fillna(\n",
    "        mean_values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67f2651",
   "metadata": {},
   "source": [
    "### 2-2-4　欠損値補間C\n",
    "- 時系列ランドサットデータの欠損値を補完する（測定年と同年の年ごとのランドセット画像MEDで補完する）\n",
    "#### 2-2-4-1 補完対応表の作成\n",
    "   - 時系列ランドサットデータと年毎のランドサット画像MEDの補完する際の列対応表を作成する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c09e560",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_table = pd.read_csv('df_table_1.csv').reset_index(drop=True)\n",
    "table_dict = {}\n",
    "for index, row in df_table.iterrows():\n",
    "    key = int(row['A'])\n",
    "    value = row['B']    \n",
    "    if pd.notna(value) and float(value).is_integer():\n",
    "        value = int(value)\n",
    "    elif pd.isna(value):\n",
    "        value = float('nan')\n",
    "    table_dict[key] = value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48bce0ab",
   "metadata": {},
   "source": [
    "#### 2-2-4-2 欠損値補完（対応表に従って）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4249950b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# M列の値に応じて欠損値を埋める関数\n",
    "def fillna_based_on_m(row):\n",
    "    m = row[\"year\"]\n",
    "    # M列の値が0から20の範囲内である場合のみ、欠損値を埋める処理を実行\n",
    "    if 1999 <= m <= 2020:\n",
    "        if m != 1999:\n",
    "            start_col = 24\n",
    "            end_col = 84\n",
    "            offset = 150 * (m - 2000)\n",
    "\n",
    "            for i in range(start_col, end_col):\n",
    "                if np.isnan(row[i]):\n",
    "                    if i in table_dict:\n",
    "                        # 対応する列を計算し、値をコピー\n",
    "                        source_col = table_dict[i-23] + 359 + offset\n",
    "                        if not math.isnan(source_col):\n",
    "                            row[i] = row[source_col]\n",
    "                        else:\n",
    "                            row[i] = float(\"nan\")\n",
    "                    else:\n",
    "                        # 対応する列がない場合はNanに\n",
    "                        row[i] = float(\"nan\")\n",
    "        else:\n",
    "            start_col = 24\n",
    "            end_col = 84\n",
    "            offset = 0\n",
    "\n",
    "            for i in range(start_col, end_col):\n",
    "                if np.isnan(row[i]):\n",
    "                    if i in table_dict:\n",
    "                        # 対応する列を計算し、値をコピー\n",
    "                        source_col = table_dict[i-23] + 359 + offset\n",
    "                        if not math.isnan(source_col):\n",
    "                            row[i] = row[source_col]\n",
    "                        else:\n",
    "                            row[i] = float(\"nan\")\n",
    "                    else:\n",
    "                        # 対応する列がない場合はNanに\n",
    "                        row[i] = float(\"nan\")\n",
    "\n",
    "    return row\n",
    "# dfにfillna_based_on_m関数を適用\n",
    "df = df.apply(fillna_based_on_m, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec69588",
   "metadata": {},
   "source": [
    "## 2-3 特徴量作成\n",
    "### 2-3-1 最寄りの'cover'を特徴量に追加\n",
    "- 予測箇所から最も近い場所１０箇所を抽出して、予測箇所からの距離毎に特徴量に追加する\n",
    "- 特徴量追加は、trainデータには、traiｎデータから、testデータにはtrain+testデータから追加する"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605ffd60",
   "metadata": {},
   "source": [
    "#### 2-3-1-1 traiｎデータとtestデータに分割する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a0a29520",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tr = df[df['cover'] != 'a']\n",
    "df_ts = df[df['cover'] == 'a']\n",
    "df_tr_list = df_tr.index\n",
    "df_ts_list = df_ts.index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ebbdac",
   "metadata": {},
   "source": [
    "#### 2-3-1-2 最寄りの１０箇所を抽出する\n",
    "- trainデータ用の１０箇所とtestデータ用の１０箇所それぞれ抽出する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3c4b707b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine_10(lat1, lon1, lat2, lon2):\n",
    "    R = 6371\n",
    "    lat1_rad, lon1_rad = np.radians(lat1), np.radians(lon1)\n",
    "    lat2_rad, lon2_rad = np.radians(lat2), np.radians(lon2)\n",
    "    dlat = lat2_rad - lat1_rad\n",
    "    dlon = lon2_rad - lon1_rad\n",
    "\n",
    "    a = np.sin(dlat / 2) ** 2 + np.cos(lat1_rad) * np.cos(lat2_rad) * np.sin(dlon / 2) ** 2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
    "    return R * c\n",
    "\n",
    "def closest_10_locations(df, index, n, exclude_indices):\n",
    "    target_lat, target_lon = df.loc[index, 'lat'], df.loc[index, 'lon']\n",
    "    distances = df.apply(lambda row: haversine_10(\n",
    "        target_lat, target_lon, row['lat'], row['lon']), axis=1)\n",
    "    distances = distances.drop(exclude_indices)\n",
    "    closest_indices = distances.nsmallest(n+1).iloc[1:].index\n",
    "    closest_rows = df.loc[closest_indices].copy()\n",
    "    closest_rows['元の行番号'] = index  \n",
    "    closest_rows['距離'] = distances[closest_indices].values  # 距離を追加\n",
    "    return closest_rows\n",
    "\n",
    "def closest_10_locations_for_indices(df, indices,exclude_indices, n):\n",
    "    result_df = pd.DataFrame()\n",
    "    for index in indices:\n",
    "        closest_n = closest_n_locations(df, index, n, exclude_indices)\n",
    "        result_df = pd.concat([result_df, closest_n])\n",
    "    return result_df.reset_index().rename(columns={'index': '抽出された行番号'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a24476e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# リスト内の各行番号に対して最も近い場所5箇所を抽出\n",
    "closest_10_for_test = closest_10_locations_for_indices(\n",
    "    df[['lat','lon']], df_ts_list, df_ts_list, 10)\n",
    "closest_10_for_train = closest_10_locations_for_indices(\n",
    "    df[['lat','lon']], df_tr_list, df_ts_list, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f588234",
   "metadata": {},
   "source": [
    "#### 2-3-1-3 抽出した１０箇所を距離毎に分類して特徴量に加える\n",
    "- trainデータ用testデータ用をマージして'cover'の値を取り出せるように加工\n",
    "- ターゲットからの距離が100m未満は’cover_0'列へ100-200m以内は’cover_1'列へ、、、1km以上は'cover_10'列に追加するようにする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "37f9b518",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp_1 = pd.concat([closest_10_for_train,closest_10_for_test]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3a4ce817",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_tmp_1 = df_tmp_1.sort_values(['元の行番号','距離']).groupby(\n",
    "    '元の行番号')['抽出された行番号'].apply(list).reset_index()\n",
    "grouped_tmp_2 = df_tmp_1.sort_values(['元の行番号','距離']).groupby(\n",
    "    '元の行番号')['距離'].apply(list).reset_index()\n",
    "grouped = pd.concat([grouped_tmp_1,grouped_tmp_2['距離']],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4f3f7343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_tmp_3を作成\n",
    "df_tmp_3 = pd.DataFrame()\n",
    "for i, row in grouped.iterrows():\n",
    "    extracted_row_numbers = row['抽出された行番号']\n",
    "    distances = row['距離']\n",
    "    \n",
    "    distance_cover_dict = dict(zip(distances, extracted_row_numbers))\n",
    "    \n",
    "    for j in range(11):\n",
    "        lower_bound = j * 0.1\n",
    "        \n",
    "        if j < 10:\n",
    "            upper_bound = (j + 1) * 0.1\n",
    "            cover_indices = [v for k, v in distance_cover_dict.items() if lower_bound <= k < upper_bound]\n",
    "        else:\n",
    "            cover_indices = [v for k, v in distance_cover_dict.items() if lower_bound <= k]\n",
    "        \n",
    "        if cover_indices:\n",
    "            covers = df.loc[cover_indices, 'cover'].values\n",
    "            df_tmp_3.loc[row['元の行番号'], f'cover_{j}'] = np.mean(covers, dtype=np.float64) \n",
    "        else:\n",
    "            df_tmp_3.loc[row['元の行番号'], f'cover_{j}'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0303b26",
   "metadata": {},
   "source": [
    "#### 2-3-1-4 上記の特徴量の統計値を特徴量に加える\n",
    "- 平均、標準偏差、最大、最小、max-minを加える"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a042d331",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp_3['mean'] = df_tmp_3.mean(axis=1)\n",
    "df_tmp_3['max'] = df_tmp_3.max(axis=1)\n",
    "df_tmp_3['min'] = df_tmp_3.min(axis=1)\n",
    "df_tmp_3['max_min'] = df_tmp_3['max'] - df_tmp_3['min']\n",
    "df_tmp_3['std'] = df_tmp_3.std(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f9441ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df,df_tmp_3],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fa7918",
   "metadata": {},
   "source": [
    "### 2-3-2 外れ値対応\n",
    "- ４分位をとって75%-25%の10倍以上離れた値をNanに置き換え"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "50fca09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(cl_df):\n",
    "    for column in cl_df.columns:\n",
    "        # 列が数値データの場合のみ四分位範囲を計算\n",
    "        if np.issubdtype(cl_df[column].dtypes, np.number):\n",
    "            Q1 = cl_df[column].quantile(0.25)\n",
    "            Q3 = cl_df[column].quantile(0.75)\n",
    "            median = cl_df[column].median()\n",
    "            IQR = Q3 - Q1 \n",
    "            if IQR < median/10 :\n",
    "                # 25%パーセンタイル値と75%パーセンタイル値が同じ場合、平均値の10倍以上を外れ値とする\n",
    "                cl_df[column] = cl_df[column].apply(\n",
    "                    lambda x: x if( median / 10 <= x <= median * 10 )else np.nan)                   \n",
    "            else:\n",
    "                # 外れ値の範囲を定義\n",
    "                lower_bound = Q1 - 10 * IQR\n",
    "                upper_bound = Q3 + 10 * IQR\n",
    "\n",
    "                # 範囲内の値に制限\n",
    "                cl_df[column] = cl_df[column].apply(\n",
    "                    lambda x: x if lower_bound <= x <= upper_bound else np.nan)\n",
    "    return cl_df\n",
    "# 外れ値を取り除いたDataFrameを作成\n",
    "df = remove_outliers(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0531ddaa",
   "metadata": {},
   "source": [
    "### 2-3-3 海洋環境要因データを加工して特徴量に加える\n",
    "- ’cover'に影響があると推測される下記特徴量を追加する\n",
    "    - ’ef_cliff'を追加→'cliff_length'(海崖長)が０ではなく'coastal_dist'(海岸までの距離)が近いと影響があると仮説\n",
    "    - ’ef_art'を追加→'aicial_length'(人工海岸線長）は埋立で'beach_length'(海浜長)’coast_length'と比較して値が大きく、かつ海岸線までの距離が近いと影響があると仮説\n",
    "    - 'ef_bch'を追加→’biach_length'(海浜長）の比率が高く、かつ'coastal_dist'(海岸までの距離)が近いと影響があると仮説\n",
    "    - 'ef_river'を追加→’river_area'(集水面積)が大きく'river_dist'(河口までの距離）が近いと影響があると仮説"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3c434927",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df['cliff_length'].isnull()) & \n",
    "       (~df['aicial_length'].isnull() | \n",
    "        ~df['beach_length'].isnull()), 'cliff_length'] = 1\n",
    "# df_tmp['ef_cliff'] = df['cliff_length']\n",
    "df['ef_cliff'] = df.apply(\n",
    "    lambda row: row['cliff_length'] * 2 \n",
    "    if row['coastal_dist'] == 0 else row['cliff_length'] / row['coastal_dist'], axis=1)\n",
    "\n",
    "df['ef_art'] = df['aicial_length'] \\\n",
    "/ (df['aicial_length'] + df['beach_length'])\n",
    "df.loc[(df['ef_art'].isnull()) & (\n",
    "    ~df['aicial_length'].isnull() | ~df['beach_length'].isnull()), 'ef_art'] = 0\n",
    "\n",
    "df['ef_art'] = df.apply(\n",
    "    lambda row: row['ef_art'] * 2 \n",
    "    if row['coastal_dist'] == 0 else row['ef_art'] / row['coastal_dist'], axis=1)\n",
    "\n",
    "df['ef_bch'] = df['beach_length'] / df['coast_length'].replace(0, float('inf'))\n",
    "df['ef_bch'] = df['ef_bch'].replace(float('inf'), 0)\n",
    "df['ef_bch'] = df['ef_bch'] * df['coast_length']\n",
    "df['ef_bch'] = df.apply(\n",
    "    lambda row: row['ef_bch'] * 2 \n",
    "    if row['coastal_dist'] == 0 else row['ef_bch'] / row['coastal_dist'], axis=1)\n",
    "df['ef_river'] = df['river_area'] / df['river_dist']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e91aa9f",
   "metadata": {},
   "source": [
    "# 3 学習\n",
    "## 3-1 学習用データ作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "68e60ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df[df['cover'] != 'a']\n",
    "df_train['cover'] = df_train['cover'].astype(float)\n",
    "col_cat = ['mesh20','cluster_id','cls_id_2']\n",
    "for col in col_cat:\n",
    "    df_train[col] = df_train[col].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "84e37735",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop(columns=['cover'])\n",
    "y_train = df_train[[\"cover\",'cluster_id','cls_id_2']]\n",
    "id_train = pd.DataFrame(df_train.index)\n",
    "id_train['cluster_id'] = df_train['cluster_id']\n",
    "id_train['cls_id_2'] = df_train['cls_id_2']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4b1486",
   "metadata": {},
   "source": [
    "## 3-2 学習\n",
    "### 3-2-1 全データを一括学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f7bed096",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lgb_1(input_X,\n",
    "              input_y,\n",
    "              input_id,\n",
    "              params,\n",
    "              list_nfold=[0,1,2,3,4],\n",
    "              n_splits=5,\n",
    "             ):\n",
    "    train_oof = np.zeros(len(input_X))\n",
    "    metrics = []\n",
    "    imp = pd.DataFrame()\n",
    "    input_y = input_y.drop(columns=['cluster_id','cls_id_2'])\n",
    "    input_id = input_id.drop(columns=['cluster_id','cls_id_2'])\n",
    "                             \n",
    "    cv = list(KFold(n_splits, random_state=123, shuffle=True).split(input_X, input_y))\n",
    "    for nfold in list_nfold:\n",
    "        print(\"-\"*20, nfold, \"-\"*20)\n",
    "        idx_tr, idx_va = cv[nfold][0], cv[nfold][1]\n",
    "        X_tr, y_tr, id_tr = input_X.loc[idx_tr, :], input_y.loc[idx_tr], input_id.loc[idx_tr, :]\n",
    "        X_va, y_va, id_va = input_X.loc[idx_va, :], input_y.loc[idx_va], input_id.loc[idx_va, :]\n",
    "        print(X_tr.shape, y_tr.shape)\n",
    "        \n",
    "        #train\n",
    "        model = lgb.LGBMRegressor(**params)\n",
    "        model.fit(X_tr,\n",
    "                  y_tr,\n",
    "                  eval_set=[(X_tr,y_tr), (X_va,y_va)],\n",
    "                  early_stopping_rounds=50,\n",
    "                  verbose=100,\n",
    "                 )\n",
    "        fname_lgb = \"model_sbmt_1_6_lgb_fold{}.pickle\".format(nfold)\n",
    "        with open(fname_lgb, \"wb\") as f:\n",
    "            pickle.dump(model, f, protocol=4)\n",
    "        \n",
    "        #evaluate\n",
    "        y_tr_pred = model.predict(X_tr)\n",
    "        y_va_pred = model.predict(X_va)\n",
    "        metric_tr = np.sqrt(mean_squared_error(y_tr, y_tr_pred))\n",
    "        metric_va = np.sqrt(mean_squared_error(y_va, y_va_pred))\n",
    "        metrics.append([nfold, metric_tr, metric_va])\n",
    "        print(\"[RMSE] tr: {:.4f}, va: {:.4f}\".format(metric_tr, metric_va))\n",
    "        \n",
    "        # oof\n",
    "        train_oof[idx_va] = y_va_pred\n",
    "        \n",
    "        # imp\n",
    "        _imp = pd.DataFrame({\"col\": input_X.columns, \n",
    "                             \"imp\": model.feature_importances_,\"nfold\":nfold})\n",
    "        imp = pd.concat([imp, _imp])\n",
    "    \n",
    "    # metric\n",
    "    print(\"-\"*20, \"result\", \"-\"*20)\n",
    "    metrics = np.array(metrics)\n",
    "    print(metrics)\n",
    "    print(\"[cv] tr: {:.4f}+-{:.4f}, va: {:.4f}+-{:.4f}\".format(\n",
    "        metrics[:,1].mean(), metrics[:,1].std(),\n",
    "        metrics[:,2].mean(), metrics[:,2].std(),\n",
    "    ))\n",
    "    print(\"[oof]{:.4f}\".format(np.sqrt(mean_squared_error(input_y, train_oof))))\n",
    "    \n",
    "    # oof\n",
    "    train_oof = pd.concat([input_id, pd.DataFrame({\"pred\" : train_oof})], axis=1)\n",
    "    \n",
    "    # importance\n",
    "    imp = imp.groupby(\"col\")[\"imp\"].agg([\"mean\", \"std\"]).reset_index(drop=False)\n",
    "    imp.columns = [\"col\", \"imp\", \"imp_std\"]\n",
    "    \n",
    "    return train_oof, imp, metrics     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3927062a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 0 --------------------\n",
      "(11312, 3482) (11312, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.0799263\tvalid_1's rmse: 0.116828\n",
      "[200]\ttraining's rmse: 0.0642602\tvalid_1's rmse: 0.114661\n",
      "[300]\ttraining's rmse: 0.0538535\tvalid_1's rmse: 0.112897\n",
      "[400]\ttraining's rmse: 0.0464674\tvalid_1's rmse: 0.111868\n",
      "[500]\ttraining's rmse: 0.0410587\tvalid_1's rmse: 0.111289\n",
      "[600]\ttraining's rmse: 0.0368198\tvalid_1's rmse: 0.110879\n",
      "[700]\ttraining's rmse: 0.0332483\tvalid_1's rmse: 0.11051\n",
      "[800]\ttraining's rmse: 0.0304556\tvalid_1's rmse: 0.110233\n",
      "[900]\ttraining's rmse: 0.0279864\tvalid_1's rmse: 0.109955\n",
      "[1000]\ttraining's rmse: 0.0259883\tvalid_1's rmse: 0.109845\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's rmse: 0.0259883\tvalid_1's rmse: 0.109845\n",
      "[RMSE] tr: 0.0260, va: 0.1098\n",
      "-------------------- 1 --------------------\n",
      "(11312, 3482) (11312, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.078439\tvalid_1's rmse: 0.117851\n",
      "[200]\ttraining's rmse: 0.0624626\tvalid_1's rmse: 0.116535\n",
      "[300]\ttraining's rmse: 0.052062\tvalid_1's rmse: 0.115952\n",
      "[400]\ttraining's rmse: 0.0446034\tvalid_1's rmse: 0.115307\n",
      "[500]\ttraining's rmse: 0.0392086\tvalid_1's rmse: 0.11519\n",
      "Early stopping, best iteration is:\n",
      "[464]\ttraining's rmse: 0.0409861\tvalid_1's rmse: 0.115067\n",
      "[RMSE] tr: 0.0410, va: 0.1151\n",
      "-------------------- 2 --------------------\n",
      "(11312, 3482) (11312, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.0812867\tvalid_1's rmse: 0.105695\n",
      "[200]\ttraining's rmse: 0.0645491\tvalid_1's rmse: 0.102778\n",
      "[300]\ttraining's rmse: 0.0541632\tvalid_1's rmse: 0.102085\n",
      "[400]\ttraining's rmse: 0.0465343\tvalid_1's rmse: 0.101611\n",
      "[500]\ttraining's rmse: 0.0409045\tvalid_1's rmse: 0.101295\n",
      "[600]\ttraining's rmse: 0.0364307\tvalid_1's rmse: 0.101039\n",
      "Early stopping, best iteration is:\n",
      "[616]\ttraining's rmse: 0.035789\tvalid_1's rmse: 0.101025\n",
      "[RMSE] tr: 0.0358, va: 0.1010\n",
      "-------------------- 3 --------------------\n",
      "(11312, 3482) (11312, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.0790304\tvalid_1's rmse: 0.11279\n",
      "[200]\ttraining's rmse: 0.0630364\tvalid_1's rmse: 0.111782\n",
      "[300]\ttraining's rmse: 0.0527501\tvalid_1's rmse: 0.111109\n",
      "Early stopping, best iteration is:\n",
      "[328]\ttraining's rmse: 0.0504321\tvalid_1's rmse: 0.110972\n",
      "[RMSE] tr: 0.0504, va: 0.1110\n",
      "-------------------- 4 --------------------\n",
      "(11312, 3482) (11312, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.0808\tvalid_1's rmse: 0.109431\n",
      "[200]\ttraining's rmse: 0.0648869\tvalid_1's rmse: 0.107469\n",
      "[300]\ttraining's rmse: 0.0544013\tvalid_1's rmse: 0.106133\n",
      "[400]\ttraining's rmse: 0.046973\tvalid_1's rmse: 0.105398\n",
      "[500]\ttraining's rmse: 0.0412386\tvalid_1's rmse: 0.105218\n",
      "[600]\ttraining's rmse: 0.0368474\tvalid_1's rmse: 0.10495\n",
      "[700]\ttraining's rmse: 0.0332532\tvalid_1's rmse: 0.104578\n",
      "Early stopping, best iteration is:\n",
      "[703]\ttraining's rmse: 0.0331644\tvalid_1's rmse: 0.104575\n",
      "[RMSE] tr: 0.0332, va: 0.1046\n",
      "-------------------- result --------------------\n",
      "[[0.         0.02598826 0.1098448 ]\n",
      " [1.         0.04098608 0.1150667 ]\n",
      " [2.         0.03578896 0.1010246 ]\n",
      " [3.         0.05043215 0.11097162]\n",
      " [4.         0.03316445 0.10457523]]\n",
      "[cv] tr: 0.0373+-0.0082, va: 0.1083+-0.0049\n",
      "[oof]0.1084\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression_l2',\n",
    "    'metric': 'Root_Mean_Squared_Error',\n",
    "    'learning_rate': 0.05,\n",
    "    'num_leaves': 32,\n",
    "    'subsample': 0.7,\n",
    "    'subsample_freq': 1,\n",
    "    'feature_fraction': 0.8,\n",
    "    'min_data_in_leaf': 50,\n",
    "    'min_sum_hessian_in_leaf': 50,\n",
    "    'n_estimators': 1000,\n",
    "    'random_state': 123,\n",
    "    'importance_type': 'gain',\n",
    "}\n",
    "\n",
    "train_oof, imp, metrics = train_lgb_1(X_train,\n",
    "                                    y_train,\n",
    "                                    id_train,\n",
    "                                    params,\n",
    "                                    list_nfold=[0,1,2,3,4],\n",
    "                                    n_splits=5,\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bd4242c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col</th>\n",
       "      <th>imp</th>\n",
       "      <th>imp_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3442</th>\n",
       "      <td>cover_0</td>\n",
       "      <td>3162.132915</td>\n",
       "      <td>23.000437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3470</th>\n",
       "      <td>min</td>\n",
       "      <td>554.130821</td>\n",
       "      <td>37.532947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3468</th>\n",
       "      <td>mean</td>\n",
       "      <td>490.743012</td>\n",
       "      <td>39.652056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3477</th>\n",
       "      <td>std</td>\n",
       "      <td>152.736055</td>\n",
       "      <td>27.585806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3466</th>\n",
       "      <td>max</td>\n",
       "      <td>55.509729</td>\n",
       "      <td>8.812687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3445</th>\n",
       "      <td>cover_2</td>\n",
       "      <td>13.563583</td>\n",
       "      <td>2.230082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3443</th>\n",
       "      <td>cover_1</td>\n",
       "      <td>10.547260</td>\n",
       "      <td>3.516138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2739</th>\n",
       "      <td>MIN_GARI</td>\n",
       "      <td>9.216533</td>\n",
       "      <td>2.869157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3467</th>\n",
       "      <td>max_min</td>\n",
       "      <td>6.955440</td>\n",
       "      <td>0.710658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3471</th>\n",
       "      <td>month</td>\n",
       "      <td>6.905245</td>\n",
       "      <td>0.680669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1128</th>\n",
       "      <td>MAX_mCRIG_2015</td>\n",
       "      <td>6.276852</td>\n",
       "      <td>3.657444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3469</th>\n",
       "      <td>mesh20</td>\n",
       "      <td>5.756755</td>\n",
       "      <td>1.428823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3358</th>\n",
       "      <td>MIN_VARIgreen_2016</td>\n",
       "      <td>4.735072</td>\n",
       "      <td>1.878867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2225</th>\n",
       "      <td>MED_VARIgreen_2008</td>\n",
       "      <td>4.569359</td>\n",
       "      <td>3.715645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3454</th>\n",
       "      <td>depth_original</td>\n",
       "      <td>4.500251</td>\n",
       "      <td>1.391225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3425</th>\n",
       "      <td>SLAVI</td>\n",
       "      <td>4.408111</td>\n",
       "      <td>1.191977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3476</th>\n",
       "      <td>sst_ymd</td>\n",
       "      <td>4.303991</td>\n",
       "      <td>1.467237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3475</th>\n",
       "      <td>sst_diff</td>\n",
       "      <td>4.224670</td>\n",
       "      <td>1.217249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1863</th>\n",
       "      <td>MED_MVI</td>\n",
       "      <td>3.632333</td>\n",
       "      <td>1.822621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2232</th>\n",
       "      <td>MED_VARIgreen_2015</td>\n",
       "      <td>3.439371</td>\n",
       "      <td>1.724509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>MAX_CSI</td>\n",
       "      <td>3.302372</td>\n",
       "      <td>1.023911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1855</th>\n",
       "      <td>MED_MCARI_MTVI2</td>\n",
       "      <td>3.179257</td>\n",
       "      <td>0.883916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2221</th>\n",
       "      <td>MED_VARIgreen_2004</td>\n",
       "      <td>3.127903</td>\n",
       "      <td>1.403121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Date_Acquired</td>\n",
       "      <td>2.968817</td>\n",
       "      <td>1.050492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3161</th>\n",
       "      <td>MIN_RDVI_2013</td>\n",
       "      <td>2.955122</td>\n",
       "      <td>2.219959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3432</th>\n",
       "      <td>VARIgreen</td>\n",
       "      <td>2.928740</td>\n",
       "      <td>0.659623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3430</th>\n",
       "      <td>TIRS2</td>\n",
       "      <td>2.913116</td>\n",
       "      <td>1.476761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>MAX_VARIgreen_2004</td>\n",
       "      <td>2.854159</td>\n",
       "      <td>1.439930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3419</th>\n",
       "      <td>PPR</td>\n",
       "      <td>2.782292</td>\n",
       "      <td>0.956509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1106</th>\n",
       "      <td>MAX_VARIgreen_2015</td>\n",
       "      <td>2.763665</td>\n",
       "      <td>1.123975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     col          imp    imp_std\n",
       "3442             cover_0  3162.132915  23.000437\n",
       "3470                 min   554.130821  37.532947\n",
       "3468                mean   490.743012  39.652056\n",
       "3477                 std   152.736055  27.585806\n",
       "3466                 max    55.509729   8.812687\n",
       "3445             cover_2    13.563583   2.230082\n",
       "3443             cover_1    10.547260   3.516138\n",
       "2739            MIN_GARI     9.216533   2.869157\n",
       "3467             max_min     6.955440   0.710658\n",
       "3471               month     6.905245   0.680669\n",
       "1128      MAX_mCRIG_2015     6.276852   3.657444\n",
       "3469              mesh20     5.756755   1.428823\n",
       "3358  MIN_VARIgreen_2016     4.735072   1.878867\n",
       "2225  MED_VARIgreen_2008     4.569359   3.715645\n",
       "3454      depth_original     4.500251   1.391225\n",
       "3425               SLAVI     4.408111   1.191977\n",
       "3476             sst_ymd     4.303991   1.467237\n",
       "3475            sst_diff     4.224670   1.217249\n",
       "1863             MED_MVI     3.632333   1.822621\n",
       "2232  MED_VARIgreen_2015     3.439371   1.724509\n",
       "184              MAX_CSI     3.302372   1.023911\n",
       "1855     MED_MCARI_MTVI2     3.179257   0.883916\n",
       "2221  MED_VARIgreen_2004     3.127903   1.403121\n",
       "16         Date_Acquired     2.968817   1.050492\n",
       "3161       MIN_RDVI_2013     2.955122   2.219959\n",
       "3432           VARIgreen     2.928740   0.659623\n",
       "3430               TIRS2     2.913116   1.476761\n",
       "1095  MAX_VARIgreen_2004     2.854159   1.439930\n",
       "3419                 PPR     2.782292   0.956509\n",
       "1106  MAX_VARIgreen_2015     2.763665   1.123975"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp.sort_values('imp',ascending=False).head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2277b20b",
   "metadata": {},
   "source": [
    "### 3-2-2 地理的な３つの区域毎に学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "263d8d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lgb_3(input_X,\n",
    "              input_y,\n",
    "              input_id,\n",
    "              params,\n",
    "              list_nfold=[0, 1, 2, 3, 4],\n",
    "              n_splits=5,\n",
    "              ):\n",
    "    metrics_list = []\n",
    "    train_oof_list =[]\n",
    "    imp_list =[]\n",
    "    for i in range(3):\n",
    "            tmp_X = input_X[input_X['cluster_id'] == i]\n",
    "            tmp_y = input_y[input_y['cluster_id'] == i]\n",
    "            tmp_id = input_id[input_id['cluster_id'] == i]\n",
    "\n",
    "            tmp_y.drop(columns=['cluster_id','cls_id_2'], inplace=True)\n",
    "            tmp_id.drop(columns=['cluster_id','cls_id_2'], inplace=True)\n",
    "            tmp_X.reset_index(drop=True, inplace=True)\n",
    "            tmp_y.reset_index(drop=True, inplace=True)\n",
    "            tmp_id.reset_index(drop=True, inplace=True)\n",
    "\n",
    "            train_oof = np.zeros(len(tmp_X))\n",
    "            metrics = []\n",
    "            imp = pd.DataFrame()\n",
    "\n",
    "                # cross-validation\n",
    "            cv = list(KFold(n_splits, random_state=123, shuffle=True).split(\n",
    "                    tmp_X, tmp_y))\n",
    "\n",
    "            for nfold in list_nfold:\n",
    "                print(\"-\" * 20, nfold, \"-\" * 20)\n",
    "                idx_tr, idx_va = cv[nfold][0], cv[nfold][1]\n",
    "                X_tr, y_tr, id_tr = tmp_X.loc[idx_tr, :], tmp_y.loc[idx_tr], \\\n",
    "                                    tmp_id.loc[idx_tr, :]\n",
    "                X_va, y_va, id_va = tmp_X.loc[idx_va, :], tmp_y.loc[idx_va], \\\n",
    "                                    tmp_id.loc[idx_va, :]\n",
    "                print(X_tr.shape, y_tr.shape)\n",
    "\n",
    "                # train\n",
    "                model = lgb.LGBMRegressor(**params)\n",
    "                model.fit(X_tr,\n",
    "                          y_tr,\n",
    "                          eval_set=[(X_tr, y_tr), (X_va, y_va)],\n",
    "                          early_stopping_rounds=50,\n",
    "                          verbose=100,\n",
    "                         )\n",
    "                fname_lgb = \"model_sbmt_1_6_cls{0}_lgb_fold{1}.pickle\".format(i, nfold)\n",
    "                with open(fname_lgb, \"wb\") as f:\n",
    "                    pickle.dump(model, f, protocol=4)\n",
    "                    \n",
    "                # evaluate\n",
    "                y_tr_pred = model.predict(X_tr)\n",
    "                y_va_pred = model.predict(X_va)\n",
    "                metric_tr = np.sqrt(mean_squared_error(y_tr, y_tr_pred))\n",
    "                metric_va = np.sqrt(mean_squared_error(y_va, y_va_pred))\n",
    "                metrics.append([nfold, metric_tr, metric_va])\n",
    "                print(\"[RMSE] tr: {:.4f}, va: {:.4f}\".format(metric_tr, metric_va))\n",
    "\n",
    "                # oof\n",
    "                train_oof[idx_va] = y_va_pred\n",
    "\n",
    "                # imp\n",
    "                _imp = pd.DataFrame(\n",
    "                    {\"col\": tmp_X.columns, \"imp\": model.feature_importances_, \n",
    "                     \"nfold\": nfold})\n",
    "                imp = pd.concat([imp, _imp])\n",
    "\n",
    "            # metric\n",
    "            print(\"-\" * 20, \"cls{}_result\".format(i), \"-\" * 20)\n",
    "            metrics = np.array(metrics)\n",
    "            print(metrics)\n",
    "            print(\"[cv] tr: {:.4f}+-{:.4f}, va: {:.4f}+-{:.4f}\".format(\n",
    "                metrics[:, 1].mean(), metrics[:, 1].std(),\n",
    "                metrics[:, 2].mean(), metrics[:, 2].std(),\n",
    "                ))\n",
    "            print(\"[oof]{:.4f}\".format(np.sqrt(mean_squared_error(tmp_y, train_oof))))\n",
    "            metrics_list.append(metrics)\n",
    "\n",
    "            # oof\n",
    "            train_oof = pd.concat([tmp_id, pd.DataFrame({\"pred\": train_oof})], axis=1)\n",
    "            train_oof_list.append(train_oof)\n",
    "\n",
    "            # importance\n",
    "            imp = imp.groupby(\"col\")[\"imp\"].agg([\"mean\", \"std\"]).reset_index(drop=False)\n",
    "            imp.columns = [\"col\", \"imp\", \"imp_std\"]\n",
    "            imp_list.append(imp)\n",
    "\n",
    "    return train_oof_list, imp_list, metrics_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f4e3b490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 0 --------------------\n",
      "(4077, 3482) (4077, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.0775861\tvalid_1's rmse: 0.112777\n",
      "[200]\ttraining's rmse: 0.0539212\tvalid_1's rmse: 0.112039\n",
      "[300]\ttraining's rmse: 0.0407875\tvalid_1's rmse: 0.111551\n",
      "Early stopping, best iteration is:\n",
      "[258]\ttraining's rmse: 0.0454688\tvalid_1's rmse: 0.111342\n",
      "[RMSE] tr: 0.0455, va: 0.1113\n",
      "-------------------- 1 --------------------\n",
      "(4077, 3482) (4077, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.0764944\tvalid_1's rmse: 0.128759\n",
      "[200]\ttraining's rmse: 0.0527425\tvalid_1's rmse: 0.127488\n",
      "[300]\ttraining's rmse: 0.0395808\tvalid_1's rmse: 0.126536\n",
      "[400]\ttraining's rmse: 0.0312278\tvalid_1's rmse: 0.126321\n",
      "Early stopping, best iteration is:\n",
      "[383]\ttraining's rmse: 0.0323727\tvalid_1's rmse: 0.126205\n",
      "[RMSE] tr: 0.0324, va: 0.1262\n",
      "-------------------- 2 --------------------\n",
      "(4078, 3482) (4078, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.0758783\tvalid_1's rmse: 0.131892\n",
      "[200]\ttraining's rmse: 0.0525796\tvalid_1's rmse: 0.13053\n",
      "[300]\ttraining's rmse: 0.0395194\tvalid_1's rmse: 0.12945\n",
      "[400]\ttraining's rmse: 0.0315665\tvalid_1's rmse: 0.12884\n",
      "[500]\ttraining's rmse: 0.0263382\tvalid_1's rmse: 0.128804\n",
      "[600]\ttraining's rmse: 0.0226893\tvalid_1's rmse: 0.128434\n",
      "Early stopping, best iteration is:\n",
      "[615]\ttraining's rmse: 0.0222419\tvalid_1's rmse: 0.128404\n",
      "[RMSE] tr: 0.0222, va: 0.1284\n",
      "-------------------- 3 --------------------\n",
      "(4078, 3482) (4078, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.0782037\tvalid_1's rmse: 0.119535\n",
      "[200]\ttraining's rmse: 0.0546591\tvalid_1's rmse: 0.117128\n",
      "[300]\ttraining's rmse: 0.0418201\tvalid_1's rmse: 0.115532\n",
      "Early stopping, best iteration is:\n",
      "[317]\ttraining's rmse: 0.0401734\tvalid_1's rmse: 0.115281\n",
      "[RMSE] tr: 0.0402, va: 0.1153\n",
      "-------------------- 4 --------------------\n",
      "(4078, 3482) (4078, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.0758064\tvalid_1's rmse: 0.131712\n",
      "[200]\ttraining's rmse: 0.0529366\tvalid_1's rmse: 0.129307\n",
      "[300]\ttraining's rmse: 0.040361\tvalid_1's rmse: 0.127469\n",
      "[400]\ttraining's rmse: 0.0325315\tvalid_1's rmse: 0.126688\n",
      "[500]\ttraining's rmse: 0.0274031\tvalid_1's rmse: 0.125827\n",
      "[600]\ttraining's rmse: 0.0236738\tvalid_1's rmse: 0.125572\n",
      "[700]\ttraining's rmse: 0.0210047\tvalid_1's rmse: 0.125075\n",
      "[800]\ttraining's rmse: 0.0190355\tvalid_1's rmse: 0.124968\n",
      "[900]\ttraining's rmse: 0.0175147\tvalid_1's rmse: 0.124714\n",
      "[1000]\ttraining's rmse: 0.0162748\tvalid_1's rmse: 0.124631\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's rmse: 0.0162748\tvalid_1's rmse: 0.124631\n",
      "[RMSE] tr: 0.0163, va: 0.1246\n",
      "-------------------- cls0_result --------------------\n",
      "[[0.         0.04546878 0.11134173]\n",
      " [1.         0.03237271 0.12620493]\n",
      " [2.         0.02224194 0.12840409]\n",
      " [3.         0.04017336 0.11528105]\n",
      " [4.         0.01627479 0.12463069]]\n",
      "[cv] tr: 0.0313+-0.0108, va: 0.1212+-0.0066\n",
      "[oof]0.1214\n",
      "-------------------- 0 --------------------\n",
      "(5162, 3482) (5162, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.0734679\tvalid_1's rmse: 0.106986\n",
      "[200]\ttraining's rmse: 0.0553997\tvalid_1's rmse: 0.104188\n",
      "[300]\ttraining's rmse: 0.045015\tvalid_1's rmse: 0.102999\n",
      "[400]\ttraining's rmse: 0.0379622\tvalid_1's rmse: 0.102213\n",
      "[500]\ttraining's rmse: 0.0328723\tvalid_1's rmse: 0.101823\n",
      "[600]\ttraining's rmse: 0.0290929\tvalid_1's rmse: 0.101538\n",
      "Early stopping, best iteration is:\n",
      "[633]\ttraining's rmse: 0.0280456\tvalid_1's rmse: 0.101396\n",
      "[RMSE] tr: 0.0280, va: 0.1014\n",
      "-------------------- 1 --------------------\n",
      "(5162, 3482) (5162, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.0730109\tvalid_1's rmse: 0.10767\n",
      "[200]\ttraining's rmse: 0.0547188\tvalid_1's rmse: 0.10487\n",
      "[300]\ttraining's rmse: 0.0439102\tvalid_1's rmse: 0.103858\n",
      "[400]\ttraining's rmse: 0.0368104\tvalid_1's rmse: 0.103255\n",
      "Early stopping, best iteration is:\n",
      "[395]\ttraining's rmse: 0.037097\tvalid_1's rmse: 0.103185\n",
      "[RMSE] tr: 0.0371, va: 0.1032\n",
      "-------------------- 2 --------------------\n",
      "(5162, 3482) (5162, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.0720694\tvalid_1's rmse: 0.116171\n",
      "[200]\ttraining's rmse: 0.0541205\tvalid_1's rmse: 0.11492\n",
      "[300]\ttraining's rmse: 0.0438224\tvalid_1's rmse: 0.114408\n",
      "[400]\ttraining's rmse: 0.037044\tvalid_1's rmse: 0.113702\n",
      "[500]\ttraining's rmse: 0.0322943\tvalid_1's rmse: 0.113354\n",
      "[600]\ttraining's rmse: 0.028564\tvalid_1's rmse: 0.113172\n",
      "[700]\ttraining's rmse: 0.0256978\tvalid_1's rmse: 0.112844\n",
      "Early stopping, best iteration is:\n",
      "[708]\ttraining's rmse: 0.0254615\tvalid_1's rmse: 0.112805\n",
      "[RMSE] tr: 0.0255, va: 0.1128\n",
      "-------------------- 3 --------------------\n",
      "(5163, 3482) (5163, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.0739279\tvalid_1's rmse: 0.104521\n",
      "[200]\ttraining's rmse: 0.0551448\tvalid_1's rmse: 0.102013\n",
      "[300]\ttraining's rmse: 0.0442129\tvalid_1's rmse: 0.100724\n",
      "[400]\ttraining's rmse: 0.0369986\tvalid_1's rmse: 0.10003\n",
      "[500]\ttraining's rmse: 0.0318984\tvalid_1's rmse: 0.0994041\n",
      "[600]\ttraining's rmse: 0.0280756\tvalid_1's rmse: 0.0990702\n",
      "[700]\ttraining's rmse: 0.0250177\tvalid_1's rmse: 0.0990148\n",
      "Early stopping, best iteration is:\n",
      "[671]\ttraining's rmse: 0.0258174\tvalid_1's rmse: 0.0989201\n",
      "[RMSE] tr: 0.0258, va: 0.0989\n",
      "-------------------- 4 --------------------\n",
      "(5163, 3482) (5163, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.0714193\tvalid_1's rmse: 0.111264\n",
      "[200]\ttraining's rmse: 0.0530196\tvalid_1's rmse: 0.109163\n",
      "[300]\ttraining's rmse: 0.042963\tvalid_1's rmse: 0.108133\n",
      "[400]\ttraining's rmse: 0.0360524\tvalid_1's rmse: 0.107352\n",
      "[500]\ttraining's rmse: 0.0313789\tvalid_1's rmse: 0.106816\n",
      "[600]\ttraining's rmse: 0.0277276\tvalid_1's rmse: 0.106308\n",
      "Early stopping, best iteration is:\n",
      "[625]\ttraining's rmse: 0.0269624\tvalid_1's rmse: 0.10621\n",
      "[RMSE] tr: 0.0270, va: 0.1062\n",
      "-------------------- cls1_result --------------------\n",
      "[[0.         0.02804565 0.10139611]\n",
      " [1.         0.03709703 0.10318531]\n",
      " [2.         0.02546152 0.11280476]\n",
      " [3.         0.02581744 0.09892013]\n",
      " [4.         0.02696241 0.10620964]]\n",
      "[cv] tr: 0.0287+-0.0043, va: 0.1045+-0.0048\n",
      "[oof]0.1046\n",
      "-------------------- 0 --------------------\n",
      "(2072, 3482) (2072, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.0717777\tvalid_1's rmse: 0.0846936\n",
      "[200]\ttraining's rmse: 0.0565992\tvalid_1's rmse: 0.0818699\n",
      "[300]\ttraining's rmse: 0.046346\tvalid_1's rmse: 0.0804893\n",
      "[400]\ttraining's rmse: 0.0386534\tvalid_1's rmse: 0.0798751\n",
      "Early stopping, best iteration is:\n",
      "[351]\ttraining's rmse: 0.0421582\tvalid_1's rmse: 0.0797395\n",
      "[RMSE] tr: 0.0422, va: 0.0797\n",
      "-------------------- 1 --------------------\n",
      "(2072, 3482) (2072, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.0672163\tvalid_1's rmse: 0.108547\n",
      "[200]\ttraining's rmse: 0.0530432\tvalid_1's rmse: 0.106057\n",
      "[300]\ttraining's rmse: 0.0439592\tvalid_1's rmse: 0.105072\n",
      "[400]\ttraining's rmse: 0.0372892\tvalid_1's rmse: 0.104083\n",
      "[500]\ttraining's rmse: 0.0321004\tvalid_1's rmse: 0.103462\n",
      "[600]\ttraining's rmse: 0.0280885\tvalid_1's rmse: 0.103205\n",
      "Early stopping, best iteration is:\n",
      "[559]\ttraining's rmse: 0.0296882\tvalid_1's rmse: 0.103073\n",
      "[RMSE] tr: 0.0297, va: 0.1031\n",
      "-------------------- 2 --------------------\n",
      "(2072, 3482) (2072, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.0698171\tvalid_1's rmse: 0.08652\n",
      "Early stopping, best iteration is:\n",
      "[74]\ttraining's rmse: 0.0755393\tvalid_1's rmse: 0.0857626\n",
      "[RMSE] tr: 0.0755, va: 0.0858\n",
      "-------------------- 3 --------------------\n",
      "(2072, 3482) (2072, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.0685594\tvalid_1's rmse: 0.0911887\n",
      "[200]\ttraining's rmse: 0.053847\tvalid_1's rmse: 0.0893443\n",
      "[300]\ttraining's rmse: 0.0442457\tvalid_1's rmse: 0.0880138\n",
      "[400]\ttraining's rmse: 0.0375393\tvalid_1's rmse: 0.0869776\n",
      "Early stopping, best iteration is:\n",
      "[407]\ttraining's rmse: 0.0371703\tvalid_1's rmse: 0.0867993\n",
      "[RMSE] tr: 0.0372, va: 0.0868\n",
      "-------------------- 4 --------------------\n",
      "(2072, 3482) (2072, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.0693175\tvalid_1's rmse: 0.0944337\n",
      "[200]\ttraining's rmse: 0.0542805\tvalid_1's rmse: 0.0915478\n",
      "[300]\ttraining's rmse: 0.0435857\tvalid_1's rmse: 0.0901314\n",
      "[400]\ttraining's rmse: 0.0359233\tvalid_1's rmse: 0.0886734\n",
      "[500]\ttraining's rmse: 0.030413\tvalid_1's rmse: 0.0878618\n",
      "[600]\ttraining's rmse: 0.0262137\tvalid_1's rmse: 0.0874096\n",
      "Early stopping, best iteration is:\n",
      "[586]\ttraining's rmse: 0.0268135\tvalid_1's rmse: 0.0871912\n",
      "[RMSE] tr: 0.0268, va: 0.0872\n",
      "-------------------- cls2_result --------------------\n",
      "[[0.         0.04215817 0.07973951]\n",
      " [1.         0.02968822 0.10307291]\n",
      " [2.         0.07553931 0.08576264]\n",
      " [3.         0.03717035 0.08679931]\n",
      " [4.         0.02681353 0.08719117]]\n",
      "[cv] tr: 0.0423+-0.0175, va: 0.0885+-0.0078\n",
      "[oof]0.0889\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression_l2',\n",
    "    'metric': 'Root_Mean_Squared_Error',\n",
    "    'learning_rate': 0.05,\n",
    "    'num_leaves': 32,\n",
    "    'subsample': 0.7,\n",
    "    'subsample_freq': 1,\n",
    "    'feature_fraction': 0.8,\n",
    "    'min_data_in_leaf': 50,\n",
    "    'min_sum_hessian_in_leaf': 50,\n",
    "    'n_estimators': 1000,\n",
    "    'random_state': 123,\n",
    "    'importance_type': 'gain',\n",
    "}\n",
    "\n",
    "train_oof, imp, metrics = train_lgb_3(X_train,\n",
    "                                    y_train,\n",
    "                                    id_train,\n",
    "                                    params,\n",
    "                                    list_nfold=[0,1,2,3,4],\n",
    "                                    n_splits=5,\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e604cb86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.        , 0.04546878, 0.11134173],\n",
       "        [1.        , 0.03237271, 0.12620493],\n",
       "        [2.        , 0.02224194, 0.12840409],\n",
       "        [3.        , 0.04017336, 0.11528105],\n",
       "        [4.        , 0.01627479, 0.12463069]]),\n",
       " array([[0.        , 0.02804565, 0.10139611],\n",
       "        [1.        , 0.03709703, 0.10318531],\n",
       "        [2.        , 0.02546152, 0.11280476],\n",
       "        [3.        , 0.02581744, 0.09892013],\n",
       "        [4.        , 0.02696241, 0.10620964]]),\n",
       " array([[0.        , 0.04215817, 0.07973951],\n",
       "        [1.        , 0.02968822, 0.10307291],\n",
       "        [2.        , 0.07553931, 0.08576264],\n",
       "        [3.        , 0.03717035, 0.08679931],\n",
       "        [4.        , 0.02681353, 0.08719117]])]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6339e33a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col</th>\n",
       "      <th>imp</th>\n",
       "      <th>imp_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3442</th>\n",
       "      <td>cover_0</td>\n",
       "      <td>188.670119</td>\n",
       "      <td>43.606909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3470</th>\n",
       "      <td>min</td>\n",
       "      <td>79.169690</td>\n",
       "      <td>47.593659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3468</th>\n",
       "      <td>mean</td>\n",
       "      <td>55.448515</td>\n",
       "      <td>34.489858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3477</th>\n",
       "      <td>std</td>\n",
       "      <td>28.758034</td>\n",
       "      <td>11.427822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3466</th>\n",
       "      <td>max</td>\n",
       "      <td>6.084168</td>\n",
       "      <td>4.076325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>MAX_GEMI_2017</td>\n",
       "      <td>3.023788</td>\n",
       "      <td>1.074437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1042</th>\n",
       "      <td>MAX_TIRS1_2014</td>\n",
       "      <td>2.451206</td>\n",
       "      <td>3.931257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3443</th>\n",
       "      <td>cover_1</td>\n",
       "      <td>2.441550</td>\n",
       "      <td>0.833542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3356</th>\n",
       "      <td>MIN_VARIgreen_2014</td>\n",
       "      <td>1.860930</td>\n",
       "      <td>1.093803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2803</th>\n",
       "      <td>MIN_GLI_2018</td>\n",
       "      <td>1.736956</td>\n",
       "      <td>1.426598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1052</th>\n",
       "      <td>MAX_TIRS2_2003</td>\n",
       "      <td>1.485362</td>\n",
       "      <td>0.963235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>MAX_BRI</td>\n",
       "      <td>1.472041</td>\n",
       "      <td>1.004456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1354</th>\n",
       "      <td>MED_CVI_2020</td>\n",
       "      <td>1.363068</td>\n",
       "      <td>0.726235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2802</th>\n",
       "      <td>MIN_GLI_2017</td>\n",
       "      <td>1.334591</td>\n",
       "      <td>0.354833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3303</th>\n",
       "      <td>MIN_TIRS2_2003</td>\n",
       "      <td>1.331777</td>\n",
       "      <td>0.759139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3219</th>\n",
       "      <td>MIN_SLAVI_2005</td>\n",
       "      <td>1.308037</td>\n",
       "      <td>0.673442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2910</th>\n",
       "      <td>MIN_IF_2017</td>\n",
       "      <td>1.289306</td>\n",
       "      <td>0.656295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2980</th>\n",
       "      <td>MIN_MCARI_MTVI2</td>\n",
       "      <td>1.252010</td>\n",
       "      <td>0.763125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1375</th>\n",
       "      <td>MED_Chlgreen_2020</td>\n",
       "      <td>1.240267</td>\n",
       "      <td>0.527382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3453</th>\n",
       "      <td>depth</td>\n",
       "      <td>1.185491</td>\n",
       "      <td>1.543779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3232</th>\n",
       "      <td>MIN_SLAVI_2018</td>\n",
       "      <td>1.175109</td>\n",
       "      <td>0.572984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1392</th>\n",
       "      <td>MED_Chlred_edge_2015</td>\n",
       "      <td>1.163705</td>\n",
       "      <td>1.955410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3454</th>\n",
       "      <td>depth_original</td>\n",
       "      <td>1.098139</td>\n",
       "      <td>0.567135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2361</th>\n",
       "      <td>MIN_BWDRVI_2016</td>\n",
       "      <td>1.081077</td>\n",
       "      <td>1.644283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3360</th>\n",
       "      <td>MIN_VARIgreen_2018</td>\n",
       "      <td>1.051595</td>\n",
       "      <td>1.451000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2178</th>\n",
       "      <td>MED_TIRS2_2003</td>\n",
       "      <td>1.044486</td>\n",
       "      <td>1.093290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1765</th>\n",
       "      <td>MED_H_2019</td>\n",
       "      <td>0.977717</td>\n",
       "      <td>1.194490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3361</th>\n",
       "      <td>MIN_VARIgreen_2019</td>\n",
       "      <td>0.936849</td>\n",
       "      <td>1.995720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2800</th>\n",
       "      <td>MIN_GLI_2015</td>\n",
       "      <td>0.876984</td>\n",
       "      <td>0.224950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1418</th>\n",
       "      <td>MED_Cigreen_2020</td>\n",
       "      <td>0.871109</td>\n",
       "      <td>0.494261</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       col         imp    imp_std\n",
       "3442               cover_0  188.670119  43.606909\n",
       "3470                   min   79.169690  47.593659\n",
       "3468                  mean   55.448515  34.489858\n",
       "3477                   std   28.758034  11.427822\n",
       "3466                   max    6.084168   4.076325\n",
       "528          MAX_GEMI_2017    3.023788   1.074437\n",
       "1042        MAX_TIRS1_2014    2.451206   3.931257\n",
       "3443               cover_1    2.441550   0.833542\n",
       "3356    MIN_VARIgreen_2014    1.860930   1.093803\n",
       "2803          MIN_GLI_2018    1.736956   1.426598\n",
       "1052        MAX_TIRS2_2003    1.485362   0.963235\n",
       "91                 MAX_BRI    1.472041   1.004456\n",
       "1354          MED_CVI_2020    1.363068   0.726235\n",
       "2802          MIN_GLI_2017    1.334591   0.354833\n",
       "3303        MIN_TIRS2_2003    1.331777   0.759139\n",
       "3219        MIN_SLAVI_2005    1.308037   0.673442\n",
       "2910           MIN_IF_2017    1.289306   0.656295\n",
       "2980       MIN_MCARI_MTVI2    1.252010   0.763125\n",
       "1375     MED_Chlgreen_2020    1.240267   0.527382\n",
       "3453                 depth    1.185491   1.543779\n",
       "3232        MIN_SLAVI_2018    1.175109   0.572984\n",
       "1392  MED_Chlred_edge_2015    1.163705   1.955410\n",
       "3454        depth_original    1.098139   0.567135\n",
       "2361       MIN_BWDRVI_2016    1.081077   1.644283\n",
       "3360    MIN_VARIgreen_2018    1.051595   1.451000\n",
       "2178        MED_TIRS2_2003    1.044486   1.093290\n",
       "1765            MED_H_2019    0.977717   1.194490\n",
       "3361    MIN_VARIgreen_2019    0.936849   1.995720\n",
       "2800          MIN_GLI_2015    0.876984   0.224950\n",
       "1418      MED_Cigreen_2020    0.871109   0.494261"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp[2].sort_values('imp',ascending=False)[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d209bcc",
   "metadata": {},
   "source": [
    "### 3-2-3 地理的区域毎、かつサブクラス毎に学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cbd6782e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lgb_9(input_X,\n",
    "              input_y,\n",
    "              input_id,\n",
    "              params,\n",
    "              list_nfold=[0, 1, 2, 3, 4],\n",
    "              n_splits=5,\n",
    "              cls_num=3,\n",
    "              cls_num_2=3,\n",
    "              ):\n",
    "    metrics_list = []\n",
    "    train_oof_list =[]\n",
    "    imp_list =[]\n",
    "    for i in range(cls_num):\n",
    "        tmp_2_X = input_X[input_X['cluster_id'] == i]\n",
    "        tmp_2_y = input_y[input_y['cluster_id'] == i]\n",
    "        tmp_2_id = input_id[input_id['cluster_id'] == i]\n",
    "        \n",
    "        for j in range(cls_num_2):\n",
    "                tmp_X = tmp_2_X[tmp_2_X['cls_id_2'] == j]\n",
    "                tmp_y = tmp_2_y[tmp_2_y['cls_id_2'] == j]\n",
    "                tmp_id = tmp_2_id[tmp_2_id['cls_id_2'] == j]\n",
    "            \n",
    "                tmp_y.drop(columns=['cluster_id','cls_id_2'], inplace=True)\n",
    "                tmp_id.drop(columns=['cluster_id','cls_id_2'], inplace=True)\n",
    "                tmp_X.reset_index(drop=True, inplace=True)\n",
    "                tmp_y.reset_index(drop=True, inplace=True)\n",
    "                tmp_id.reset_index(drop=True, inplace=True)\n",
    "\n",
    "                train_oof = np.zeros(len(tmp_X))\n",
    "                metrics = []\n",
    "                imp = pd.DataFrame()\n",
    "\n",
    "                # cross-validation\n",
    "                cv = list(KFold(n_splits, random_state=123, shuffle=True).split(\n",
    "                    tmp_X, tmp_y))\n",
    "\n",
    "                for nfold in list_nfold:\n",
    "                    print(\"-\" * 20, nfold, \"-\" * 20)\n",
    "                    idx_tr, idx_va = cv[nfold][0], cv[nfold][1]\n",
    "                    X_tr, y_tr, id_tr = tmp_X.loc[idx_tr, :], tmp_y.loc[idx_tr], \\\n",
    "                                        tmp_id.loc[idx_tr, :]\n",
    "                    X_va, y_va, id_va = tmp_X.loc[idx_va, :], tmp_y.loc[idx_va], \\\n",
    "                                        tmp_id.loc[idx_va, :]\n",
    "                    print(X_tr.shape, y_tr.shape)\n",
    "\n",
    "                    # train\n",
    "                    model = lgb.LGBMRegressor(**params)\n",
    "                    model.fit(X_tr,\n",
    "                              y_tr,\n",
    "                              eval_set=[(X_tr, y_tr), (X_va, y_va)],\n",
    "                              early_stopping_rounds=50,\n",
    "                              verbose=100,\n",
    "                              )\n",
    "                    fname_lgb = \"model_sbmt_1_6_cls{0}_{1}_lgb_fold{2}.pickle\".format(\n",
    "                        i,j, nfold)\n",
    "                    with open(fname_lgb, \"wb\") as f:\n",
    "                        pickle.dump(model, f, protocol=4)\n",
    "\n",
    "                    # evaluate\n",
    "                    y_tr_pred = model.predict(X_tr)\n",
    "                    y_va_pred = model.predict(X_va)\n",
    "                    metric_tr = np.sqrt(mean_squared_error(y_tr, y_tr_pred))\n",
    "                    metric_va = np.sqrt(mean_squared_error(y_va, y_va_pred))\n",
    "                    metrics.append([nfold, metric_tr, metric_va])\n",
    "                    print(\"[RMSE] tr: {:.4f}, va: {:.4f}\".format(metric_tr, metric_va))\n",
    "\n",
    "                    # oof\n",
    "                    train_oof[idx_va] = y_va_pred\n",
    "\n",
    "                    # imp\n",
    "                    _imp = pd.DataFrame(\n",
    "                        {\"col\": tmp_X.columns, \n",
    "                         \"imp\": model.feature_importances_, \n",
    "                         \"nfold\": nfold})\n",
    "                    imp = pd.concat([imp, _imp])\n",
    "\n",
    "                # metric\n",
    "                print(\"-\" * 20, \"cls{}_{}_result\".format(i,j), \"-\" * 20)\n",
    "                print(fname_lgb)\n",
    "                metrics = np.array(metrics)\n",
    "                print(metrics)\n",
    "                print(\"[cv] tr: {:.4f}+-{:.4f}, va: {:.4f}+-{:.4f}\".format(\n",
    "                    metrics[:, 1].mean(), metrics[:, 1].std(),\n",
    "                    metrics[:, 2].mean(), metrics[:, 2].std(),\n",
    "                ))\n",
    "                print(\"[oof]{:.4f}\".format(np.sqrt(mean_squared_error(tmp_y, train_oof))))\n",
    "                metrics_list.append(metrics)\n",
    "\n",
    "                # oof\n",
    "                train_oof = pd.concat([tmp_id, pd.DataFrame({\"pred\": train_oof})], axis=1)\n",
    "                train_oof_list.append(train_oof)\n",
    "\n",
    "                # importance\n",
    "                imp = imp.groupby(\"col\")[\"imp\"].agg([\"mean\", \"std\"]).reset_index(drop=False)\n",
    "                imp.columns = [\"col\", \"imp\", \"imp_std\"]\n",
    "                imp_list.append(imp)        \n",
    "\n",
    "    return train_oof_list, imp_list, metrics_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0ee1a682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 0 --------------------\n",
      "(1878, 3482) (1878, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.059129\tvalid_1's rmse: 0.0782347\n",
      "[200]\ttraining's rmse: 0.0454301\tvalid_1's rmse: 0.0741665\n",
      "[300]\ttraining's rmse: 0.0363441\tvalid_1's rmse: 0.0729395\n",
      "Early stopping, best iteration is:\n",
      "[298]\ttraining's rmse: 0.0364765\tvalid_1's rmse: 0.0728426\n",
      "[RMSE] tr: 0.0365, va: 0.0728\n",
      "-------------------- 1 --------------------\n",
      "(1878, 3482) (1878, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.0583327\tvalid_1's rmse: 0.0741628\n",
      "[200]\ttraining's rmse: 0.0434231\tvalid_1's rmse: 0.0721873\n",
      "[300]\ttraining's rmse: 0.0344103\tvalid_1's rmse: 0.0708473\n",
      "Early stopping, best iteration is:\n",
      "[313]\ttraining's rmse: 0.033507\tvalid_1's rmse: 0.0706604\n",
      "[RMSE] tr: 0.0335, va: 0.0707\n",
      "-------------------- 2 --------------------\n",
      "(1878, 3482) (1878, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.0601633\tvalid_1's rmse: 0.0683374\n",
      "Early stopping, best iteration is:\n",
      "[126]\ttraining's rmse: 0.0553453\tvalid_1's rmse: 0.06792\n",
      "[RMSE] tr: 0.0553, va: 0.0679\n",
      "-------------------- 3 --------------------\n",
      "(1879, 3482) (1879, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.058157\tvalid_1's rmse: 0.0804962\n",
      "[200]\ttraining's rmse: 0.0423402\tvalid_1's rmse: 0.0793106\n",
      "[300]\ttraining's rmse: 0.0324666\tvalid_1's rmse: 0.078065\n",
      "[400]\ttraining's rmse: 0.0267071\tvalid_1's rmse: 0.078003\n",
      "Early stopping, best iteration is:\n",
      "[361]\ttraining's rmse: 0.0286011\tvalid_1's rmse: 0.0778659\n",
      "[RMSE] tr: 0.0286, va: 0.0779\n",
      "-------------------- 4 --------------------\n",
      "(1879, 3482) (1879, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.058746\tvalid_1's rmse: 0.0778789\n",
      "[200]\ttraining's rmse: 0.0431686\tvalid_1's rmse: 0.0763855\n",
      "Early stopping, best iteration is:\n",
      "[189]\ttraining's rmse: 0.0445058\tvalid_1's rmse: 0.0762884\n",
      "[RMSE] tr: 0.0445, va: 0.0763\n",
      "-------------------- cls0_0_result --------------------\n",
      "model_sbmt_1_6_cls0_0_lgb_fold4.pickle\n",
      "[[0.         0.03647651 0.0728426 ]\n",
      " [1.         0.033507   0.07066042]\n",
      " [2.         0.05534527 0.06791999]\n",
      " [3.         0.02860113 0.07786594]\n",
      " [4.         0.04450576 0.07628838]]\n",
      "[cv] tr: 0.0397+-0.0094, va: 0.0731+-0.0036\n",
      "[oof]0.0732\n",
      "-------------------- 0 --------------------\n",
      "(993, 3482) (993, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.0705852\tvalid_1's rmse: 0.0964837\n",
      "[200]\ttraining's rmse: 0.0485104\tvalid_1's rmse: 0.0928575\n",
      "Early stopping, best iteration is:\n",
      "[242]\ttraining's rmse: 0.0429028\tvalid_1's rmse: 0.0924406\n",
      "[RMSE] tr: 0.0429, va: 0.0924\n",
      "-------------------- 1 --------------------\n",
      "(993, 3482) (993, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.0646503\tvalid_1's rmse: 0.120552\n",
      "Early stopping, best iteration is:\n",
      "[139]\ttraining's rmse: 0.0543161\tvalid_1's rmse: 0.119226\n",
      "[RMSE] tr: 0.0543, va: 0.1192\n",
      "-------------------- 2 --------------------\n",
      "(994, 3482) (994, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.0707233\tvalid_1's rmse: 0.0985239\n",
      "[200]\ttraining's rmse: 0.0485604\tvalid_1's rmse: 0.0922892\n",
      "[300]\ttraining's rmse: 0.0368067\tvalid_1's rmse: 0.0906155\n",
      "[400]\ttraining's rmse: 0.0287879\tvalid_1's rmse: 0.0893935\n",
      "Early stopping, best iteration is:\n",
      "[394]\ttraining's rmse: 0.0292174\tvalid_1's rmse: 0.0893508\n",
      "[RMSE] tr: 0.0292, va: 0.0894\n",
      "-------------------- 3 --------------------\n",
      "(994, 3482) (994, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.0710047\tvalid_1's rmse: 0.101551\n",
      "[200]\ttraining's rmse: 0.0488813\tvalid_1's rmse: 0.0973625\n",
      "[300]\ttraining's rmse: 0.0370659\tvalid_1's rmse: 0.0963822\n",
      "[400]\ttraining's rmse: 0.0289847\tvalid_1's rmse: 0.0957912\n",
      "Early stopping, best iteration is:\n",
      "[384]\ttraining's rmse: 0.0300363\tvalid_1's rmse: 0.0956763\n",
      "[RMSE] tr: 0.0300, va: 0.0957\n",
      "-------------------- 4 --------------------\n",
      "(994, 3482) (994, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.0706178\tvalid_1's rmse: 0.0954753\n",
      "[200]\ttraining's rmse: 0.0490325\tvalid_1's rmse: 0.0915088\n",
      "[300]\ttraining's rmse: 0.0372264\tvalid_1's rmse: 0.0911795\n",
      "Early stopping, best iteration is:\n",
      "[293]\ttraining's rmse: 0.0379627\tvalid_1's rmse: 0.0909529\n",
      "[RMSE] tr: 0.0380, va: 0.0910\n",
      "-------------------- cls0_1_result --------------------\n",
      "model_sbmt_1_6_cls0_1_lgb_fold4.pickle\n",
      "[[0.         0.04290283 0.09244065]\n",
      " [1.         0.05431614 0.11922596]\n",
      " [2.         0.02921737 0.08935079]\n",
      " [3.         0.03003635 0.0956763 ]\n",
      " [4.         0.03796265 0.09095293]]\n",
      "[cv] tr: 0.0389+-0.0092, va: 0.0975+-0.0110\n",
      "[oof]0.0982\n",
      "-------------------- 0 --------------------\n",
      "(1205, 3482) (1205, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.116257\tvalid_1's rmse: 0.171628\n",
      "Early stopping, best iteration is:\n",
      "[115]\ttraining's rmse: 0.108388\tvalid_1's rmse: 0.170817\n",
      "[RMSE] tr: 0.1084, va: 0.1708\n",
      "-------------------- 1 --------------------\n",
      "(1205, 3482) (1205, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.112742\tvalid_1's rmse: 0.188755\n",
      "Early stopping, best iteration is:\n",
      "[107]\ttraining's rmse: 0.108862\tvalid_1's rmse: 0.188725\n",
      "[RMSE] tr: 0.1089, va: 0.1887\n",
      "-------------------- 2 --------------------\n",
      "(1206, 3482) (1206, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.115474\tvalid_1's rmse: 0.182712\n",
      "[200]\ttraining's rmse: 0.0788784\tvalid_1's rmse: 0.17563\n",
      "[300]\ttraining's rmse: 0.0594936\tvalid_1's rmse: 0.172698\n",
      "[400]\ttraining's rmse: 0.048129\tvalid_1's rmse: 0.17144\n",
      "[500]\ttraining's rmse: 0.0404937\tvalid_1's rmse: 0.170211\n",
      "[600]\ttraining's rmse: 0.0352742\tvalid_1's rmse: 0.169803\n",
      "Early stopping, best iteration is:\n",
      "[573]\ttraining's rmse: 0.0365452\tvalid_1's rmse: 0.169663\n",
      "[RMSE] tr: 0.0365, va: 0.1697\n",
      "-------------------- 3 --------------------\n",
      "(1206, 3482) (1206, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.116437\tvalid_1's rmse: 0.187228\n",
      "[200]\ttraining's rmse: 0.0808518\tvalid_1's rmse: 0.17882\n",
      "[300]\ttraining's rmse: 0.0614908\tvalid_1's rmse: 0.174248\n",
      "[400]\ttraining's rmse: 0.0494267\tvalid_1's rmse: 0.171977\n",
      "[500]\ttraining's rmse: 0.0413974\tvalid_1's rmse: 0.170512\n",
      "[600]\ttraining's rmse: 0.0359822\tvalid_1's rmse: 0.169535\n",
      "[700]\ttraining's rmse: 0.0319563\tvalid_1's rmse: 0.169042\n",
      "[800]\ttraining's rmse: 0.0287803\tvalid_1's rmse: 0.168481\n",
      "[900]\ttraining's rmse: 0.0262856\tvalid_1's rmse: 0.168172\n",
      "[1000]\ttraining's rmse: 0.0242204\tvalid_1's rmse: 0.168011\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's rmse: 0.0242204\tvalid_1's rmse: 0.168011\n",
      "[RMSE] tr: 0.0242, va: 0.1680\n",
      "-------------------- 4 --------------------\n",
      "(1206, 3482) (1206, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.111801\tvalid_1's rmse: 0.20509\n",
      "[200]\ttraining's rmse: 0.0770309\tvalid_1's rmse: 0.198521\n",
      "[300]\ttraining's rmse: 0.0572959\tvalid_1's rmse: 0.196415\n",
      "[400]\ttraining's rmse: 0.0456452\tvalid_1's rmse: 0.195982\n",
      "Early stopping, best iteration is:\n",
      "[384]\ttraining's rmse: 0.0471925\tvalid_1's rmse: 0.195792\n",
      "[RMSE] tr: 0.0472, va: 0.1958\n",
      "-------------------- cls0_2_result --------------------\n",
      "model_sbmt_1_6_cls0_2_lgb_fold4.pickle\n",
      "[[0.         0.10838769 0.17081666]\n",
      " [1.         0.10886234 0.18872474]\n",
      " [2.         0.03654521 0.16966297]\n",
      " [3.         0.0242204  0.16801129]\n",
      " [4.         0.04719253 0.19579161]]\n",
      "[cv] tr: 0.0650+-0.0363, va: 0.1786+-0.0114\n",
      "[oof]0.1790\n",
      "-------------------- 0 --------------------\n",
      "(3031, 3482) (3031, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.0493272\tvalid_1's rmse: 0.0655954\n",
      "Early stopping, best iteration is:\n",
      "[109]\ttraining's rmse: 0.0479939\tvalid_1's rmse: 0.0653217\n",
      "[RMSE] tr: 0.0480, va: 0.0653\n",
      "-------------------- 1 --------------------\n",
      "(3031, 3482) (3031, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.0510948\tvalid_1's rmse: 0.0635829\n",
      "[200]\ttraining's rmse: 0.03878\tvalid_1's rmse: 0.0623229\n",
      "[300]\ttraining's rmse: 0.031182\tvalid_1's rmse: 0.0617858\n",
      "Early stopping, best iteration is:\n",
      "[326]\ttraining's rmse: 0.0296509\tvalid_1's rmse: 0.0617027\n",
      "[RMSE] tr: 0.0297, va: 0.0617\n",
      "-------------------- 2 --------------------\n",
      "(3031, 3482) (3031, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.0498072\tvalid_1's rmse: 0.0740931\n",
      "[200]\ttraining's rmse: 0.0383262\tvalid_1's rmse: 0.0735705\n",
      "Early stopping, best iteration is:\n",
      "[220]\ttraining's rmse: 0.0364896\tvalid_1's rmse: 0.0734118\n",
      "[RMSE] tr: 0.0365, va: 0.0734\n",
      "-------------------- 3 --------------------\n",
      "(3031, 3482) (3031, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.0511836\tvalid_1's rmse: 0.0628559\n",
      "[200]\ttraining's rmse: 0.0392678\tvalid_1's rmse: 0.0600147\n",
      "[300]\ttraining's rmse: 0.031825\tvalid_1's rmse: 0.0596613\n",
      "[400]\ttraining's rmse: 0.0269742\tvalid_1's rmse: 0.0594971\n",
      "Early stopping, best iteration is:\n",
      "[363]\ttraining's rmse: 0.0285545\tvalid_1's rmse: 0.0593137\n",
      "[RMSE] tr: 0.0286, va: 0.0593\n",
      "-------------------- 4 --------------------\n",
      "(3032, 3482) (3032, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.0488374\tvalid_1's rmse: 0.0760299\n",
      "[200]\ttraining's rmse: 0.0370177\tvalid_1's rmse: 0.0739233\n",
      "[300]\ttraining's rmse: 0.029946\tvalid_1's rmse: 0.0731602\n",
      "[400]\ttraining's rmse: 0.0252924\tvalid_1's rmse: 0.0724701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[500]\ttraining's rmse: 0.0220159\tvalid_1's rmse: 0.0721249\n",
      "[600]\ttraining's rmse: 0.0197198\tvalid_1's rmse: 0.0718434\n",
      "[700]\ttraining's rmse: 0.0179016\tvalid_1's rmse: 0.0714938\n",
      "[800]\ttraining's rmse: 0.0164509\tvalid_1's rmse: 0.0713463\n",
      "[900]\ttraining's rmse: 0.0153277\tvalid_1's rmse: 0.071332\n",
      "[1000]\ttraining's rmse: 0.0144372\tvalid_1's rmse: 0.0712344\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's rmse: 0.0144372\tvalid_1's rmse: 0.0712344\n",
      "[RMSE] tr: 0.0144, va: 0.0712\n",
      "-------------------- cls1_0_result --------------------\n",
      "model_sbmt_1_6_cls1_0_lgb_fold4.pickle\n",
      "[[0.         0.04799395 0.0653217 ]\n",
      " [1.         0.02965093 0.06170268]\n",
      " [2.         0.03648964 0.07341182]\n",
      " [3.         0.02855446 0.05931372]\n",
      " [4.         0.01443721 0.07123444]]\n",
      "[cv] tr: 0.0314+-0.0110, va: 0.0662+-0.0054\n",
      "[oof]0.0664\n",
      "-------------------- 0 --------------------\n",
      "(1781, 3482) (1781, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.0973069\tvalid_1's rmse: 0.149098\n",
      "[200]\ttraining's rmse: 0.0706556\tvalid_1's rmse: 0.144067\n",
      "[300]\ttraining's rmse: 0.056086\tvalid_1's rmse: 0.140796\n",
      "[400]\ttraining's rmse: 0.0468015\tvalid_1's rmse: 0.138934\n",
      "[500]\ttraining's rmse: 0.0403576\tvalid_1's rmse: 0.138319\n",
      "Early stopping, best iteration is:\n",
      "[503]\ttraining's rmse: 0.0402053\tvalid_1's rmse: 0.138263\n",
      "[RMSE] tr: 0.0402, va: 0.1383\n",
      "-------------------- 1 --------------------\n",
      "(1781, 3482) (1781, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.0979962\tvalid_1's rmse: 0.149351\n",
      "[200]\ttraining's rmse: 0.0700337\tvalid_1's rmse: 0.145298\n",
      "[300]\ttraining's rmse: 0.0547989\tvalid_1's rmse: 0.142923\n",
      "[400]\ttraining's rmse: 0.0456377\tvalid_1's rmse: 0.141531\n",
      "[500]\ttraining's rmse: 0.0393946\tvalid_1's rmse: 0.141356\n",
      "[600]\ttraining's rmse: 0.034856\tvalid_1's rmse: 0.14129\n",
      "Early stopping, best iteration is:\n",
      "[575]\ttraining's rmse: 0.0358288\tvalid_1's rmse: 0.141046\n",
      "[RMSE] tr: 0.0358, va: 0.1410\n",
      "-------------------- 2 --------------------\n",
      "(1782, 3482) (1782, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.0965553\tvalid_1's rmse: 0.1399\n",
      "[200]\ttraining's rmse: 0.0698269\tvalid_1's rmse: 0.137569\n",
      "[300]\ttraining's rmse: 0.0550192\tvalid_1's rmse: 0.137157\n",
      "Early stopping, best iteration is:\n",
      "[269]\ttraining's rmse: 0.0587599\tvalid_1's rmse: 0.13667\n",
      "[RMSE] tr: 0.0588, va: 0.1367\n",
      "-------------------- 3 --------------------\n",
      "(1782, 3482) (1782, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.0974363\tvalid_1's rmse: 0.154277\n",
      "[200]\ttraining's rmse: 0.0698023\tvalid_1's rmse: 0.152709\n",
      "[300]\ttraining's rmse: 0.0539181\tvalid_1's rmse: 0.152457\n",
      "Early stopping, best iteration is:\n",
      "[272]\ttraining's rmse: 0.0576277\tvalid_1's rmse: 0.152021\n",
      "[RMSE] tr: 0.0576, va: 0.1520\n",
      "-------------------- 4 --------------------\n",
      "(1782, 3482) (1782, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.0939526\tvalid_1's rmse: 0.156332\n",
      "[200]\ttraining's rmse: 0.0664264\tvalid_1's rmse: 0.154335\n",
      "Early stopping, best iteration is:\n",
      "[228]\ttraining's rmse: 0.0612984\tvalid_1's rmse: 0.153937\n",
      "[RMSE] tr: 0.0613, va: 0.1539\n",
      "-------------------- cls1_1_result --------------------\n",
      "model_sbmt_1_6_cls1_1_lgb_fold4.pickle\n",
      "[[0.         0.0402053  0.13826291]\n",
      " [1.         0.03582878 0.14104572]\n",
      " [2.         0.05875991 0.13667027]\n",
      " [3.         0.05762774 0.15202095]\n",
      " [4.         0.06129838 0.1539367 ]]\n",
      "[cv] tr: 0.0507+-0.0106, va: 0.1444+-0.0072\n",
      "[oof]0.1446\n",
      "-------------------- 0 --------------------\n",
      "(349, 3482) (349, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.116209\tvalid_1's rmse: 0.128468\n",
      "Early stopping, best iteration is:\n",
      "[114]\ttraining's rmse: 0.111773\tvalid_1's rmse: 0.127111\n",
      "[RMSE] tr: 0.1118, va: 0.1271\n",
      "-------------------- 1 --------------------\n",
      "(349, 3482) (349, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.115114\tvalid_1's rmse: 0.165758\n",
      "[200]\ttraining's rmse: 0.0946599\tvalid_1's rmse: 0.15834\n",
      "Early stopping, best iteration is:\n",
      "[239]\ttraining's rmse: 0.0901343\tvalid_1's rmse: 0.15703\n",
      "[RMSE] tr: 0.0901, va: 0.1570\n",
      "-------------------- 2 --------------------\n",
      "(350, 3482) (350, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.115119\tvalid_1's rmse: 0.132953\n",
      "Early stopping, best iteration is:\n",
      "[143]\ttraining's rmse: 0.103163\tvalid_1's rmse: 0.129514\n",
      "[RMSE] tr: 0.1032, va: 0.1295\n",
      "-------------------- 3 --------------------\n",
      "(350, 3482) (350, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.114687\tvalid_1's rmse: 0.153\n",
      "[200]\ttraining's rmse: 0.0918608\tvalid_1's rmse: 0.147406\n",
      "Early stopping, best iteration is:\n",
      "[247]\ttraining's rmse: 0.0855099\tvalid_1's rmse: 0.145935\n",
      "[RMSE] tr: 0.0855, va: 0.1459\n",
      "-------------------- 4 --------------------\n",
      "(350, 3482) (350, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's rmse: 0.1095\tvalid_1's rmse: 0.169626\n",
      "[200]\ttraining's rmse: 0.0913697\tvalid_1's rmse: 0.166004\n",
      "[300]\ttraining's rmse: 0.0809048\tvalid_1's rmse: 0.163402\n",
      "[400]\ttraining's rmse: 0.0731084\tvalid_1's rmse: 0.161362\n",
      "Early stopping, best iteration is:\n",
      "[435]\ttraining's rmse: 0.0708008\tvalid_1's rmse: 0.160471\n",
      "[RMSE] tr: 0.0708, va: 0.1605\n",
      "-------------------- cls1_2_result --------------------\n",
      "model_sbmt_1_6_cls1_2_lgb_fold4.pickle\n",
      "[[0.         0.11177341 0.12711073]\n",
      " [1.         0.09013427 0.15703035]\n",
      " [2.         0.10316292 0.1295139 ]\n",
      " [3.         0.08550993 0.14593457]\n",
      " [4.         0.07080083 0.16047111]]\n",
      "[cv] tr: 0.0923+-0.0142, va: 0.1440+-0.0137\n",
      "[oof]0.1447\n",
      "-------------------- 0 --------------------\n",
      "(210, 3482) (210, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.173458\tvalid_1's rmse: 0.217715\n",
      "[200]\ttraining's rmse: 0.146067\tvalid_1's rmse: 0.205517\n",
      "[300]\ttraining's rmse: 0.127542\tvalid_1's rmse: 0.196521\n",
      "[400]\ttraining's rmse: 0.11325\tvalid_1's rmse: 0.190298\n",
      "[500]\ttraining's rmse: 0.102539\tvalid_1's rmse: 0.186303\n",
      "[600]\ttraining's rmse: 0.0930193\tvalid_1's rmse: 0.183045\n",
      "[700]\ttraining's rmse: 0.0855109\tvalid_1's rmse: 0.181941\n",
      "[800]\ttraining's rmse: 0.0785866\tvalid_1's rmse: 0.179788\n",
      "[900]\ttraining's rmse: 0.0725629\tvalid_1's rmse: 0.178846\n",
      "[1000]\ttraining's rmse: 0.0667554\tvalid_1's rmse: 0.178681\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's rmse: 0.0667554\tvalid_1's rmse: 0.178681\n",
      "[RMSE] tr: 0.0668, va: 0.1787\n",
      "-------------------- 1 --------------------\n",
      "(210, 3482) (210, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.165374\tvalid_1's rmse: 0.241871\n",
      "[200]\ttraining's rmse: 0.134348\tvalid_1's rmse: 0.235048\n",
      "[300]\ttraining's rmse: 0.115477\tvalid_1's rmse: 0.230382\n",
      "Early stopping, best iteration is:\n",
      "[334]\ttraining's rmse: 0.110406\tvalid_1's rmse: 0.229551\n",
      "[RMSE] tr: 0.1104, va: 0.2296\n",
      "-------------------- 2 --------------------\n",
      "(210, 3482) (210, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.176018\tvalid_1's rmse: 0.199418\n",
      "[200]\ttraining's rmse: 0.142108\tvalid_1's rmse: 0.1991\n",
      "Early stopping, best iteration is:\n",
      "[151]\ttraining's rmse: 0.155157\tvalid_1's rmse: 0.196836\n",
      "[RMSE] tr: 0.1552, va: 0.1968\n",
      "-------------------- 3 --------------------\n",
      "(211, 3482) (211, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.167176\tvalid_1's rmse: 0.227965\n",
      "[200]\ttraining's rmse: 0.141285\tvalid_1's rmse: 0.215692\n",
      "[300]\ttraining's rmse: 0.123632\tvalid_1's rmse: 0.211926\n",
      "[400]\ttraining's rmse: 0.109151\tvalid_1's rmse: 0.209022\n",
      "[500]\ttraining's rmse: 0.0981637\tvalid_1's rmse: 0.207581\n",
      "Early stopping, best iteration is:\n",
      "[480]\ttraining's rmse: 0.100166\tvalid_1's rmse: 0.206763\n",
      "[RMSE] tr: 0.1002, va: 0.2068\n",
      "-------------------- 4 --------------------\n",
      "(211, 3482) (211, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.175423\tvalid_1's rmse: 0.198019\n",
      "Early stopping, best iteration is:\n",
      "[101]\ttraining's rmse: 0.175127\tvalid_1's rmse: 0.197429\n",
      "[RMSE] tr: 0.1751, va: 0.1974\n",
      "-------------------- cls2_0_result --------------------\n",
      "model_sbmt_1_6_cls2_0_lgb_fold4.pickle\n",
      "[[0.         0.06675535 0.17868147]\n",
      " [1.         0.1104064  0.22955083]\n",
      " [2.         0.15515709 0.19683562]\n",
      " [3.         0.10016575 0.20676318]\n",
      " [4.         0.17512736 0.1974285 ]]\n",
      "[cv] tr: 0.1215+-0.0389, va: 0.2019+-0.0166\n",
      "[oof]0.2025\n",
      "-------------------- 0 --------------------\n",
      "(538, 3482) (538, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.0878582\tvalid_1's rmse: 0.126914\n",
      "[200]\ttraining's rmse: 0.0651547\tvalid_1's rmse: 0.117401\n",
      "[300]\ttraining's rmse: 0.0526412\tvalid_1's rmse: 0.114274\n",
      "Early stopping, best iteration is:\n",
      "[320]\ttraining's rmse: 0.0508361\tvalid_1's rmse: 0.113452\n",
      "[RMSE] tr: 0.0508, va: 0.1135\n",
      "-------------------- 1 --------------------\n",
      "(538, 3482) (538, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.085752\tvalid_1's rmse: 0.11067\n",
      "[200]\ttraining's rmse: 0.0655574\tvalid_1's rmse: 0.108334\n",
      "Early stopping, best iteration is:\n",
      "[211]\ttraining's rmse: 0.0642501\tvalid_1's rmse: 0.107695\n",
      "[RMSE] tr: 0.0643, va: 0.1077\n",
      "-------------------- 2 --------------------\n",
      "(538, 3482) (538, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.083075\tvalid_1's rmse: 0.124906\n",
      "Early stopping, best iteration is:\n",
      "[65]\ttraining's rmse: 0.0981803\tvalid_1's rmse: 0.124622\n",
      "[RMSE] tr: 0.0982, va: 0.1246\n",
      "-------------------- 3 --------------------\n",
      "(539, 3482) (539, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.0912197\tvalid_1's rmse: 0.0794755\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\ttraining's rmse: 0.0658104\tvalid_1's rmse: 0.0759091\n",
      "Early stopping, best iteration is:\n",
      "[233]\ttraining's rmse: 0.0610281\tvalid_1's rmse: 0.0744093\n",
      "[RMSE] tr: 0.0610, va: 0.0744\n",
      "-------------------- 4 --------------------\n",
      "(539, 3482) (539, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.0838524\tvalid_1's rmse: 0.141262\n",
      "[200]\ttraining's rmse: 0.0565119\tvalid_1's rmse: 0.137349\n",
      "Early stopping, best iteration is:\n",
      "[164]\ttraining's rmse: 0.0639676\tvalid_1's rmse: 0.13677\n",
      "[RMSE] tr: 0.0640, va: 0.1368\n",
      "-------------------- cls2_1_result --------------------\n",
      "model_sbmt_1_6_cls2_1_lgb_fold4.pickle\n",
      "[[0.         0.05083611 0.11345184]\n",
      " [1.         0.06425011 0.10769543]\n",
      " [2.         0.09818035 0.12462152]\n",
      " [3.         0.06102805 0.07440933]\n",
      " [4.         0.06396758 0.13677025]]\n",
      "[cv] tr: 0.0677+-0.0160, va: 0.1114+-0.0210\n",
      "[oof]0.1134\n",
      "-------------------- 0 --------------------\n",
      "(1323, 3482) (1323, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.030799\tvalid_1's rmse: 0.0238602\n",
      "Early stopping, best iteration is:\n",
      "[117]\ttraining's rmse: 0.0295365\tvalid_1's rmse: 0.023792\n",
      "[RMSE] tr: 0.0295, va: 0.0238\n",
      "-------------------- 1 --------------------\n",
      "(1323, 3482) (1323, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[47]\ttraining's rmse: 0.0345907\tvalid_1's rmse: 0.033659\n",
      "[RMSE] tr: 0.0346, va: 0.0337\n",
      "-------------------- 2 --------------------\n",
      "(1323, 3482) (1323, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.0287647\tvalid_1's rmse: 0.0408307\n",
      "[200]\ttraining's rmse: 0.0234013\tvalid_1's rmse: 0.0388843\n",
      "[300]\ttraining's rmse: 0.0195549\tvalid_1's rmse: 0.0374647\n",
      "[400]\ttraining's rmse: 0.0166925\tvalid_1's rmse: 0.0367685\n",
      "[500]\ttraining's rmse: 0.0142963\tvalid_1's rmse: 0.0364657\n",
      "[600]\ttraining's rmse: 0.0125089\tvalid_1's rmse: 0.0361907\n",
      "Early stopping, best iteration is:\n",
      "[607]\ttraining's rmse: 0.0123981\tvalid_1's rmse: 0.0361495\n",
      "[RMSE] tr: 0.0124, va: 0.0361\n",
      "-------------------- 3 --------------------\n",
      "(1323, 3482) (1323, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.0254383\tvalid_1's rmse: 0.0481988\n",
      "[200]\ttraining's rmse: 0.0198926\tvalid_1's rmse: 0.0469883\n",
      "[300]\ttraining's rmse: 0.0161294\tvalid_1's rmse: 0.0465607\n",
      "[400]\ttraining's rmse: 0.0133553\tvalid_1's rmse: 0.0461832\n",
      "[500]\ttraining's rmse: 0.0111901\tvalid_1's rmse: 0.0461622\n",
      "Early stopping, best iteration is:\n",
      "[458]\ttraining's rmse: 0.0119576\tvalid_1's rmse: 0.0460631\n",
      "[RMSE] tr: 0.0120, va: 0.0461\n",
      "-------------------- 4 --------------------\n",
      "(1324, 3482) (1324, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.0310407\tvalid_1's rmse: 0.0273317\n",
      "[200]\ttraining's rmse: 0.024984\tvalid_1's rmse: 0.0271279\n",
      "Early stopping, best iteration is:\n",
      "[208]\ttraining's rmse: 0.0246196\tvalid_1's rmse: 0.0269139\n",
      "[RMSE] tr: 0.0246, va: 0.0269\n",
      "-------------------- cls2_2_result --------------------\n",
      "model_sbmt_1_6_cls2_2_lgb_fold4.pickle\n",
      "[[0.         0.02953648 0.02379196]\n",
      " [1.         0.03459074 0.03365895]\n",
      " [2.         0.01239806 0.0361495 ]\n",
      " [3.         0.01195763 0.04606313]\n",
      " [4.         0.02461962 0.02691394]]\n",
      "[cv] tr: 0.0226+-0.0091, va: 0.0333+-0.0078\n",
      "[oof]0.0342\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression_l2',\n",
    "    'metric': 'Root_Mean_Squared_Error',\n",
    "    'learning_rate': 0.05,\n",
    "    'num_leaves': 32,\n",
    "    'subsample': 0.7,\n",
    "    'subsample_freq': 1,\n",
    "    'feature_fraction': 0.8,\n",
    "    'min_data_in_leaf': 50,\n",
    "    'min_sum_hessian_in_leaf': 50,\n",
    "    'n_estimators': 1000,\n",
    "    'random_state': 123,\n",
    "    'importance_type': 'gain',\n",
    "}\n",
    "\n",
    "train_oof_list, imp_list, metrics_list = train_lgb_9(X_train,\n",
    "                                                   y_train,\n",
    "                                                   id_train,\n",
    "                                                   params,\n",
    "                                                   list_nfold=[0,1,2,3,4],\n",
    "                                                   n_splits=5,\n",
    "                                                   cls_num=3,\n",
    "                                                   cls_num_2=3,\n",
    "                                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "58b4fc42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.        , 0.03647651, 0.0728426 ],\n",
       "        [1.        , 0.033507  , 0.07066042],\n",
       "        [2.        , 0.05534527, 0.06791999],\n",
       "        [3.        , 0.02860113, 0.07786594],\n",
       "        [4.        , 0.04450576, 0.07628838]]),\n",
       " array([[0.        , 0.04290283, 0.09244065],\n",
       "        [1.        , 0.05431614, 0.11922596],\n",
       "        [2.        , 0.02921737, 0.08935079],\n",
       "        [3.        , 0.03003635, 0.0956763 ],\n",
       "        [4.        , 0.03796265, 0.09095293]]),\n",
       " array([[0.        , 0.10838769, 0.17081666],\n",
       "        [1.        , 0.10886234, 0.18872474],\n",
       "        [2.        , 0.03654521, 0.16966297],\n",
       "        [3.        , 0.0242204 , 0.16801129],\n",
       "        [4.        , 0.04719253, 0.19579161]]),\n",
       " array([[0.        , 0.04799395, 0.0653217 ],\n",
       "        [1.        , 0.02965093, 0.06170268],\n",
       "        [2.        , 0.03648964, 0.07341182],\n",
       "        [3.        , 0.02855446, 0.05931372],\n",
       "        [4.        , 0.01443721, 0.07123444]]),\n",
       " array([[0.        , 0.0402053 , 0.13826291],\n",
       "        [1.        , 0.03582878, 0.14104572],\n",
       "        [2.        , 0.05875991, 0.13667027],\n",
       "        [3.        , 0.05762774, 0.15202095],\n",
       "        [4.        , 0.06129838, 0.1539367 ]]),\n",
       " array([[0.        , 0.11177341, 0.12711073],\n",
       "        [1.        , 0.09013427, 0.15703035],\n",
       "        [2.        , 0.10316292, 0.1295139 ],\n",
       "        [3.        , 0.08550993, 0.14593457],\n",
       "        [4.        , 0.07080083, 0.16047111]]),\n",
       " array([[0.        , 0.06675535, 0.17868147],\n",
       "        [1.        , 0.1104064 , 0.22955083],\n",
       "        [2.        , 0.15515709, 0.19683562],\n",
       "        [3.        , 0.10016575, 0.20676318],\n",
       "        [4.        , 0.17512736, 0.1974285 ]]),\n",
       " array([[0.        , 0.05083611, 0.11345184],\n",
       "        [1.        , 0.06425011, 0.10769543],\n",
       "        [2.        , 0.09818035, 0.12462152],\n",
       "        [3.        , 0.06102805, 0.07440933],\n",
       "        [4.        , 0.06396758, 0.13677025]]),\n",
       " array([[0.        , 0.02953648, 0.02379196],\n",
       "        [1.        , 0.03459074, 0.03365895],\n",
       "        [2.        , 0.01239806, 0.0361495 ],\n",
       "        [3.        , 0.01195763, 0.04606313],\n",
       "        [4.        , 0.02461962, 0.02691394]])]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "42ac7c1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col</th>\n",
       "      <th>imp</th>\n",
       "      <th>imp_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3468</th>\n",
       "      <td>mean</td>\n",
       "      <td>2.992015</td>\n",
       "      <td>0.587527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3477</th>\n",
       "      <td>std</td>\n",
       "      <td>1.241368</td>\n",
       "      <td>0.357132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2783</th>\n",
       "      <td>MIN_GI</td>\n",
       "      <td>0.585221</td>\n",
       "      <td>0.286874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2044</th>\n",
       "      <td>MED_RGR</td>\n",
       "      <td>0.494331</td>\n",
       "      <td>0.392119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3443</th>\n",
       "      <td>cover_1</td>\n",
       "      <td>0.426484</td>\n",
       "      <td>0.141066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>MED_CVI</td>\n",
       "      <td>0.400815</td>\n",
       "      <td>0.400078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>MAX_RGR</td>\n",
       "      <td>0.354363</td>\n",
       "      <td>0.152733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3467</th>\n",
       "      <td>max_min</td>\n",
       "      <td>0.337712</td>\n",
       "      <td>0.124076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2286</th>\n",
       "      <td>MIN_ARVI</td>\n",
       "      <td>0.271498</td>\n",
       "      <td>0.110500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3297</th>\n",
       "      <td>MIN_TIRS1_2018</td>\n",
       "      <td>0.241780</td>\n",
       "      <td>0.201852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3466</th>\n",
       "      <td>max</td>\n",
       "      <td>0.204353</td>\n",
       "      <td>0.160068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>MAX_ARI</td>\n",
       "      <td>0.198755</td>\n",
       "      <td>0.062978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1107</th>\n",
       "      <td>MAX_VARIgreen_2016</td>\n",
       "      <td>0.185246</td>\n",
       "      <td>0.106979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096</th>\n",
       "      <td>MAX_VARIgreen_2005</td>\n",
       "      <td>0.170202</td>\n",
       "      <td>0.161961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3169</th>\n",
       "      <td>MIN_RGR</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>0.084980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1658</th>\n",
       "      <td>MED_GI</td>\n",
       "      <td>0.155200</td>\n",
       "      <td>0.111622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1681</th>\n",
       "      <td>MED_GRNDVI</td>\n",
       "      <td>0.151802</td>\n",
       "      <td>0.093565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>MAX_Bcc</td>\n",
       "      <td>0.143424</td>\n",
       "      <td>0.115812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2983</th>\n",
       "      <td>MIN_MIRBI</td>\n",
       "      <td>0.142868</td>\n",
       "      <td>0.126738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>MED_PPR_2019</td>\n",
       "      <td>0.140508</td>\n",
       "      <td>0.130924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768</th>\n",
       "      <td>MAX_NDWI2</td>\n",
       "      <td>0.116259</td>\n",
       "      <td>0.084484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2306</th>\n",
       "      <td>MIN_AVI_2018</td>\n",
       "      <td>0.112531</td>\n",
       "      <td>0.165491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>MAX_CI_2016</td>\n",
       "      <td>0.111594</td>\n",
       "      <td>0.109911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2222</th>\n",
       "      <td>MED_VARIgreen_2005</td>\n",
       "      <td>0.107356</td>\n",
       "      <td>0.137643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3446</th>\n",
       "      <td>cover_3</td>\n",
       "      <td>0.105937</td>\n",
       "      <td>0.111118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>MAX_BRI</td>\n",
       "      <td>0.102816</td>\n",
       "      <td>0.089506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>MAX_PPR_2018</td>\n",
       "      <td>0.095185</td>\n",
       "      <td>0.081170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>MED_CRI550_2019</td>\n",
       "      <td>0.091673</td>\n",
       "      <td>0.071491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2958</th>\n",
       "      <td>MIN_MCARI2</td>\n",
       "      <td>0.084447</td>\n",
       "      <td>0.082219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1789</th>\n",
       "      <td>MED_IO</td>\n",
       "      <td>0.080318</td>\n",
       "      <td>0.146882</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     col       imp   imp_std\n",
       "3468                mean  2.992015  0.587527\n",
       "3477                 std  1.241368  0.357132\n",
       "2783              MIN_GI  0.585221  0.286874\n",
       "2044             MED_RGR  0.494331  0.392119\n",
       "3443             cover_1  0.426484  0.141066\n",
       "1333             MED_CVI  0.400815  0.400078\n",
       "918              MAX_RGR  0.354363  0.152733\n",
       "3467             max_min  0.337712  0.124076\n",
       "2286            MIN_ARVI  0.271498  0.110500\n",
       "3297      MIN_TIRS1_2018  0.241780  0.201852\n",
       "3466                 max  0.204353  0.160068\n",
       "33               MAX_ARI  0.198755  0.062978\n",
       "1107  MAX_VARIgreen_2016  0.185246  0.106979\n",
       "1096  MAX_VARIgreen_2005  0.170202  0.161961\n",
       "3169             MIN_RGR  0.156250  0.084980\n",
       "1658              MED_GI  0.155200  0.111622\n",
       "1681          MED_GRNDVI  0.151802  0.093565\n",
       "114              MAX_Bcc  0.143424  0.115812\n",
       "2983           MIN_MIRBI  0.142868  0.126738\n",
       "1998        MED_PPR_2019  0.140508  0.130924\n",
       "768            MAX_NDWI2  0.116259  0.084484\n",
       "2306        MIN_AVI_2018  0.112531  0.165491\n",
       "154          MAX_CI_2016  0.111594  0.109911\n",
       "2222  MED_VARIgreen_2005  0.107356  0.137643\n",
       "3446             cover_3  0.105937  0.111118\n",
       "91               MAX_BRI  0.102816  0.089506\n",
       "871         MAX_PPR_2018  0.095185  0.081170\n",
       "1308     MED_CRI550_2019  0.091673  0.071491\n",
       "2958          MIN_MCARI2  0.084447  0.082219\n",
       "1789              MED_IO  0.080318  0.146882"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp_list[8].sort_values('imp',ascending=False).head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2f7b98",
   "metadata": {},
   "source": [
    "# 4 予測\n",
    "## 4-1 予測用データ作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7d368928",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df[df['cover'] == 'a'].reset_index(drop=True)\n",
    "df_test = df_test.drop(columns=['cover'])\n",
    "col_cat = ['mesh20','cluster_id','cls_id_2']\n",
    "for col in col_cat:\n",
    "    df_test[col] = df_test[col].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ec8cc107",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df_test.copy()\n",
    "id_test = pd.DataFrame(df_test.index)\n",
    "id_test['cluster_id'] = df_test['cluster_id']\n",
    "id_test['cls_id_2'] = df_test['cls_id_2']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ec2844",
   "metadata": {},
   "source": [
    "## 4-2 予測\n",
    "- ３つの学習モデルをアンサンブル実施。重みづけは実施せず、平均値を予測値とした"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "067487e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_lgb_9(input_X,\n",
    "                input_id,\n",
    "                list_nfold_0=[0,1,2,3,4],\n",
    "                list_nfold_1=[0,1,2,3,4],\n",
    "                list_nfold_2=[0,1,2,3,4],\n",
    "               ):\n",
    "    pred_list = []\n",
    "    for i in range(3):\n",
    "            tmp_2_X = input_X[input_X['cluster_id'] == i]\n",
    "            tmp_2_id = input_id[input_id['cluster_id'] == i]\n",
    "            tmp_2_id.drop(columns=['cluster_id'], inplace=True)\n",
    "            \n",
    "            for j in range(3):                 \n",
    "                    tmp_X = tmp_2_X[tmp_2_X['cls_id_2'] == j]\n",
    "                    tmp_id = tmp_2_id[tmp_2_id['cls_id_2'] == j]\n",
    "                    tmp_id.drop(columns=['cls_id_2'], inplace=True)\n",
    "                    pred = np.zeros((len(tmp_X), \n",
    "                                     len(list_nfold_0)\n",
    "                                    + len(list_nfold_1) \n",
    "                                     + len(list_nfold_2)))\n",
    "                    \n",
    "                    for nfold in list_nfold_2:\n",
    "                        print(\"-\"*20, nfold, \"-\"*20)\n",
    "                        fname_lgb_1 = \"model_sbmt_1_6_cls{}_lgb_fold{}.pickle\".format(\n",
    "                            i,nfold)\n",
    "                        with open(fname_lgb_1, \"rb\") as f:\n",
    "                            model = pickle.load(f)\n",
    "                        pred[:, len(list_nfold_0) + \n",
    "                             len(list_nfold_1) + nfold] = model.predict(tmp_X)\n",
    "                                            \n",
    "                    for nfold in list_nfold_1:\n",
    "                        print(\"-\"*20, nfold, \"-\"*20)\n",
    "                        fname_lgb_2 = \"model_sbmt_1_6_cls{}_{}_lgb_fold{}.pickle\".format(\n",
    "                            i,j,nfold)\n",
    "                        with open(fname_lgb_2, \"rb\") as f:\n",
    "                            model = pickle.load(f)\n",
    "                        pred[:, len(list_nfold_0) + nfold] = model.predict(tmp_X)\n",
    "                    \n",
    "                    for nfold in list_nfold_0:\n",
    "                        print(\"-\"*20, nfold, \"-\"*20)\n",
    "                        fname_lgb_3 = \"model_sbmt_1_6_lgb_fold{}.pickle\".format(nfold)\n",
    "                        with open(fname_lgb_3, \"rb\") as f:\n",
    "                            model = pickle.load(f)\n",
    "                        pred[:, nfold] = model.predict(tmp_X)\n",
    "                    \n",
    "                    df_pred = pd.DataFrame({\"pred\": pred.mean(axis=1)})\n",
    "                    df_pred.index = tmp_id.index\n",
    "                    pred = pd.concat([\n",
    "                        tmp_id,df_pred,], axis=1)\n",
    "                    pred_list.append(pred)\n",
    "                    text = 'cls{}_{}_Done.'.format(i,j)\n",
    "                    print(len(tmp_X))\n",
    "                    print(text + '_' + fname_lgb_3 + '_' + fname_lgb_1 + '_' + fname_lgb_2)\n",
    "                    print(len(pred))                    \n",
    "\n",
    "    return pred_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2255bc27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 0 --------------------\n",
      "-------------------- 1 --------------------\n",
      "-------------------- 2 --------------------\n",
      "-------------------- 3 --------------------\n",
      "-------------------- 4 --------------------\n",
      "-------------------- 0 --------------------\n",
      "-------------------- 1 --------------------\n",
      "-------------------- 2 --------------------\n",
      "-------------------- 3 --------------------\n",
      "-------------------- 4 --------------------\n",
      "-------------------- 0 --------------------\n",
      "-------------------- 1 --------------------\n",
      "-------------------- 2 --------------------\n",
      "-------------------- 3 --------------------\n",
      "-------------------- 4 --------------------\n",
      "130\n",
      "cls0_0_Done._model_sbmt_1_6_lgb_fold4.pickle_model_sbmt_1_6_cls0_lgb_fold4.pickle_model_sbmt_1_6_cls0_0_lgb_fold4.pickle\n",
      "130\n",
      "-------------------- 0 --------------------\n",
      "-------------------- 1 --------------------\n",
      "-------------------- 2 --------------------\n",
      "-------------------- 3 --------------------\n",
      "-------------------- 4 --------------------\n",
      "-------------------- 0 --------------------\n",
      "-------------------- 1 --------------------\n",
      "-------------------- 2 --------------------\n",
      "-------------------- 3 --------------------\n",
      "-------------------- 4 --------------------\n",
      "-------------------- 0 --------------------\n",
      "-------------------- 1 --------------------\n",
      "-------------------- 2 --------------------\n",
      "-------------------- 3 --------------------\n",
      "-------------------- 4 --------------------\n",
      "281\n",
      "cls0_1_Done._model_sbmt_1_6_lgb_fold4.pickle_model_sbmt_1_6_cls0_lgb_fold4.pickle_model_sbmt_1_6_cls0_1_lgb_fold4.pickle\n",
      "281\n",
      "-------------------- 0 --------------------\n",
      "-------------------- 1 --------------------\n",
      "-------------------- 2 --------------------\n",
      "-------------------- 3 --------------------\n",
      "-------------------- 4 --------------------\n",
      "-------------------- 0 --------------------\n",
      "-------------------- 1 --------------------\n",
      "-------------------- 2 --------------------\n",
      "-------------------- 3 --------------------\n",
      "-------------------- 4 --------------------\n",
      "-------------------- 0 --------------------\n",
      "-------------------- 1 --------------------\n",
      "-------------------- 2 --------------------\n",
      "-------------------- 3 --------------------\n",
      "-------------------- 4 --------------------\n",
      "729\n",
      "cls0_2_Done._model_sbmt_1_6_lgb_fold4.pickle_model_sbmt_1_6_cls0_lgb_fold4.pickle_model_sbmt_1_6_cls0_2_lgb_fold4.pickle\n",
      "729\n",
      "-------------------- 0 --------------------\n",
      "-------------------- 1 --------------------\n",
      "-------------------- 2 --------------------\n",
      "-------------------- 3 --------------------\n",
      "-------------------- 4 --------------------\n",
      "-------------------- 0 --------------------\n",
      "-------------------- 1 --------------------\n",
      "-------------------- 2 --------------------\n",
      "-------------------- 3 --------------------\n",
      "-------------------- 4 --------------------\n",
      "-------------------- 0 --------------------\n",
      "-------------------- 1 --------------------\n",
      "-------------------- 2 --------------------\n",
      "-------------------- 3 --------------------\n",
      "-------------------- 4 --------------------\n",
      "77\n",
      "cls1_0_Done._model_sbmt_1_6_lgb_fold4.pickle_model_sbmt_1_6_cls1_lgb_fold4.pickle_model_sbmt_1_6_cls1_0_lgb_fold4.pickle\n",
      "77\n",
      "-------------------- 0 --------------------\n",
      "-------------------- 1 --------------------\n",
      "-------------------- 2 --------------------\n",
      "-------------------- 3 --------------------\n",
      "-------------------- 4 --------------------\n",
      "-------------------- 0 --------------------\n",
      "-------------------- 1 --------------------\n",
      "-------------------- 2 --------------------\n",
      "-------------------- 3 --------------------\n",
      "-------------------- 4 --------------------\n",
      "-------------------- 0 --------------------\n",
      "-------------------- 1 --------------------\n",
      "-------------------- 2 --------------------\n",
      "-------------------- 3 --------------------\n",
      "-------------------- 4 --------------------\n",
      "599\n",
      "cls1_1_Done._model_sbmt_1_6_lgb_fold4.pickle_model_sbmt_1_6_cls1_lgb_fold4.pickle_model_sbmt_1_6_cls1_1_lgb_fold4.pickle\n",
      "599\n",
      "-------------------- 0 --------------------\n",
      "-------------------- 1 --------------------\n",
      "-------------------- 2 --------------------\n",
      "-------------------- 3 --------------------\n",
      "-------------------- 4 --------------------\n",
      "-------------------- 0 --------------------\n",
      "-------------------- 1 --------------------\n",
      "-------------------- 2 --------------------\n",
      "-------------------- 3 --------------------\n",
      "-------------------- 4 --------------------\n",
      "-------------------- 0 --------------------\n",
      "-------------------- 1 --------------------\n",
      "-------------------- 2 --------------------\n",
      "-------------------- 3 --------------------\n",
      "-------------------- 4 --------------------\n",
      "986\n",
      "cls1_2_Done._model_sbmt_1_6_lgb_fold4.pickle_model_sbmt_1_6_cls1_lgb_fold4.pickle_model_sbmt_1_6_cls1_2_lgb_fold4.pickle\n",
      "986\n",
      "-------------------- 0 --------------------\n",
      "-------------------- 1 --------------------\n",
      "-------------------- 2 --------------------\n",
      "-------------------- 3 --------------------\n",
      "-------------------- 4 --------------------\n",
      "-------------------- 0 --------------------\n",
      "-------------------- 1 --------------------\n",
      "-------------------- 2 --------------------\n",
      "-------------------- 3 --------------------\n",
      "-------------------- 4 --------------------\n",
      "-------------------- 0 --------------------\n",
      "-------------------- 1 --------------------\n",
      "-------------------- 2 --------------------\n",
      "-------------------- 3 --------------------\n",
      "-------------------- 4 --------------------\n",
      "305\n",
      "cls2_0_Done._model_sbmt_1_6_lgb_fold4.pickle_model_sbmt_1_6_cls2_lgb_fold4.pickle_model_sbmt_1_6_cls2_0_lgb_fold4.pickle\n",
      "305\n",
      "-------------------- 0 --------------------\n",
      "-------------------- 1 --------------------\n",
      "-------------------- 2 --------------------\n",
      "-------------------- 3 --------------------\n",
      "-------------------- 4 --------------------\n",
      "-------------------- 0 --------------------\n",
      "-------------------- 1 --------------------\n",
      "-------------------- 2 --------------------\n",
      "-------------------- 3 --------------------\n",
      "-------------------- 4 --------------------\n",
      "-------------------- 0 --------------------\n",
      "-------------------- 1 --------------------\n",
      "-------------------- 2 --------------------\n",
      "-------------------- 3 --------------------\n",
      "-------------------- 4 --------------------\n",
      "462\n",
      "cls2_1_Done._model_sbmt_1_6_lgb_fold4.pickle_model_sbmt_1_6_cls2_lgb_fold4.pickle_model_sbmt_1_6_cls2_1_lgb_fold4.pickle\n",
      "462\n",
      "-------------------- 0 --------------------\n",
      "-------------------- 1 --------------------\n",
      "-------------------- 2 --------------------\n",
      "-------------------- 3 --------------------\n",
      "-------------------- 4 --------------------\n",
      "-------------------- 0 --------------------\n",
      "-------------------- 1 --------------------\n",
      "-------------------- 2 --------------------\n",
      "-------------------- 3 --------------------\n",
      "-------------------- 4 --------------------\n",
      "-------------------- 0 --------------------\n",
      "-------------------- 1 --------------------\n",
      "-------------------- 2 --------------------\n",
      "-------------------- 3 --------------------\n",
      "-------------------- 4 --------------------\n",
      "470\n",
      "cls2_2_Done._model_sbmt_1_6_lgb_fold4.pickle_model_sbmt_1_6_cls2_lgb_fold4.pickle_model_sbmt_1_6_cls2_2_lgb_fold4.pickle\n",
      "470\n"
     ]
    }
   ],
   "source": [
    "test_pred_2 = predict_lgb_9(\n",
    "    X_test,id_test,list_nfold_1=[0,1,2,3,4],list_nfold_2=[0,1,2,3,4],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f65072c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = pd.DataFrame()\n",
    "for i in range(9):\n",
    "    tmp = test_pred_2[i]\n",
    "    test_pred = pd.concat([test_pred,tmp])\n",
    "test_pred = test_pred.sort_values(0)\n",
    "# 負の値はゼロに、１を超えた値は１に修正\n",
    "test_pred['pred'] = test_pred['pred'].apply(lambda x: 0 if x<0 else (1 if x>1 else x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c126f87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred.to_csv(\"sbmt_test_1_6.csv\", header=False,index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
