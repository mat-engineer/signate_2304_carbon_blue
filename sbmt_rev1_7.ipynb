{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "03a0877d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import pickle\n",
    "import csv\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import lightgbm as lgb\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e12b79",
   "metadata": {},
   "source": [
    "# 1 データ読み込み\n",
    "- trainデータとtestデータ共に読み込んでマージ、不要な情報列を削除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c5b3071e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tr = pd.read_csv('train_data.csv',index_col=0)\n",
    "df_test = pd.read_csv(\"test_data.csv\",index_col=0)\n",
    "df_test['cover'] = 'a'\n",
    "df = pd.concat([df_tr,df_test])\n",
    "df.drop(columns=['Landsat_StartTime','YMD','PRODUCT_ID'],inplace=True)\n",
    "df['year'] = df['year'].astype(int)\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d19c5a",
   "metadata": {},
   "source": [
    "# 2 データ前処理\n",
    "## 2-1 クラスタリング\n",
    "### 2-1-1 ラベルエンコーディング\n",
    "- 'mesh20'をラベルエンコーディング実施"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9ea2e671",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()    \n",
    "le.fit(df[['mesh20']])\n",
    "list_label = sorted(list(set(le.classes_)))\n",
    "map_label = {j:i for i,j in enumerate(list_label)}\n",
    "dict_mesh = {}\n",
    "dict_mesh['map_label'] = map_label\n",
    "map_label = dict_mesh['map_label']\n",
    "df['mesh20'] = df['mesh20'].map(map_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e8f7f6",
   "metadata": {},
   "source": [
    "# ルール違反でした、、、\n",
    "### 2-1-2 地理的に３つの区域（３クラス）にクラスタリング\n",
    "- 経度、緯度情報のみを使用して３クラスに分類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ef4eb3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "clst = KMeans(n_clusters=3,\n",
    "            init='k-means++',\n",
    "            n_init=10,\n",
    "            max_iter=300,\n",
    "            random_state=0)\n",
    "pred = clst.fit_predict(df[['lat','lon']])\n",
    "df['cluster_id'] = pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c767cda6",
   "metadata": {},
   "source": [
    "# ルール違反でした、、、\n",
    "### 2-1-3 サブクラス作成\n",
    "- 3つの区域（クラス）毎にサブクラスを３クラス作成_今回は全データを使ってクラスタリング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f36052cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cls = df.copy()\n",
    "df_cls.drop(columns=['cover','cluster_id'],inplace=True)\n",
    "df_cls = df_cls.fillna(df_cls.median())\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(df_cls)\n",
    "df_cls = pd.DataFrame(scaler.transform(df_cls),columns=df_cls.columns)\n",
    "df_cls['cluster_id'] = df['cluster_id']\n",
    "from sklearn.cluster import KMeans\n",
    "clst = KMeans(n_clusters=3,\n",
    "            init='k-means++',\n",
    "            n_init=10,\n",
    "            max_iter=300,\n",
    "            random_state=0)\n",
    "tmp_df = pd.DataFrame()\n",
    "for i in range(3):\n",
    "    pred = clst.fit_predict(df_cls[df_cls['cluster_id'] == i])\n",
    "    tmp = pd.DataFrame({'id': df_cls[df_cls['cluster_id'] == i].index, \n",
    "                        'cls_id_2': pred})\n",
    "    tmp_df = pd.concat([tmp_df,tmp])\n",
    "tmp = tmp_df.sort_values('id').reset_index(drop=True)\n",
    "df['cls_id_2'] = tmp['cls_id_2']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540b6f14",
   "metadata": {},
   "source": [
    "## 2-2 欠損値補完\n",
    "- 主に画像データの欠損値を補完する"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31bb16a5",
   "metadata": {},
   "source": [
    "### 2-2-1 欠損値行の特定\n",
    "   - 画像データのうち、50％以上が欠損値の行を補完する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4e428e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 行内のNaNの割合を計算する\n",
    "nan_rows = df.iloc[:,85:3460].isna().sum(axis=1) / df.iloc[:,85:3460].shape[1]\n",
    "# NaNの割合が50%以上の行を抽出する\n",
    "high_nan_rows = df.iloc[:,85:3460][nan_rows >= 0.5]\n",
    "nan_row_list = high_nan_rows.index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc17ef04",
   "metadata": {},
   "source": [
    "### 2-2-2 欠損値補完A\n",
    "- 年毎のランドサットデータは前後1年のデータで補完する、2000年時は2001、2002のデータで補完"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "59a34f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillna_with_column_values(arr, row, cols):\n",
    "    for col in cols:\n",
    "        if not np.isnan(arr[row, col]):\n",
    "            return arr[row, col]\n",
    "    return np.nan\n",
    "arr = df.iloc[:,310:3460].to_numpy(dtype=float)\n",
    "# 各列の欠損値を指定された条件で埋める\n",
    "for j in range(3150):\n",
    "    missing_rows = np.where(np.isnan(arr[:, j]))[0]\n",
    "    for i in missing_rows:\n",
    "        if j >= 0 and j < 150:\n",
    "            cols = [j + 150, j + 300]\n",
    "            cols = [col for col in cols if col >= 0 and col < arr.shape[1]]\n",
    "            arr[i, j] = fillna_with_column_values(arr, i, cols)\n",
    "        else:\n",
    "            cols = [j - 150, j + 150]\n",
    "            cols = [col for col in cols if col >= 0 and col < arr.shape[1]]\n",
    "            arr[i, j] = fillna_with_column_values(arr, i, cols)\n",
    "        \n",
    "df.iloc[:,310:3460] = pd.DataFrame(arr, columns=df.iloc[:,310:3460].columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97aae43",
   "metadata": {},
   "source": [
    "### 2-2-3 欠損値補完B\n",
    "- Aで補完できなかった行を補完する\n",
    "- 最寄りの５箇所を特定して、５箇所の平均値で補完する"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3fd679",
   "metadata": {},
   "source": [
    "#### 2-2-3-1 最寄りの５箇所を抽出\n",
    "   - 緯度経度からターゲットから最も近い５箇所を抽出する（trainデータで補完する）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "67ed2038",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tr = df[df['cover'] != 'a']\n",
    "\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    R = 6371\n",
    "    lat1_rad, lon1_rad = np.radians(lat1), np.radians(lon1)\n",
    "    lat2_rad, lon2_rad = np.radians(lat2), np.radians(lon2)\n",
    "    dlat = lat2_rad - lat1_rad\n",
    "    dlon = lon2_rad - lon1_rad\n",
    "\n",
    "    a = np.sin(dlat / 2) ** 2 + np.cos(lat1_rad) * np.cos(lat2_rad) * np.sin(dlon / 2) ** 2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
    "    return R * c\n",
    "\n",
    "def closest_n_locations(df, index, n, exclude_indices):\n",
    "    target_lat, target_lon = df.loc[index, 'lat'], df.loc[index, 'lon']\n",
    "    distances = df.apply(lambda row: haversine(\n",
    "        target_lat, target_lon, row['lat'], row['lon']), axis=1)\n",
    "    distances = distances.drop(exclude_indices)\n",
    "    closest_indices = distances.nsmallest(n+1).iloc[1:].index\n",
    "    closest_rows = df.loc[closest_indices].copy()\n",
    "    closest_rows['元の行番号'] = index  \n",
    "    closest_rows['距離'] = distances[closest_indices].values  # 距離を追加\n",
    "    return closest_rows\n",
    "\n",
    "def closest_n_locations_for_indices(df, indices, n):\n",
    "    result_df = pd.DataFrame()\n",
    "    for index in indices:\n",
    "        closest_n = closest_n_locations(df, index, n, indices)\n",
    "        result_df = pd.concat([result_df, closest_n])\n",
    "    return result_df.reset_index().rename(columns={'index': '抽出された行番号'})\n",
    "\n",
    "# リスト内の各行番号に対して最も近い場所5箇所を抽出\n",
    "closest_5_for_indices = closest_n_locations_for_indices(\n",
    "    df_tr[['lat','lon']], nan_row_list, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507aea12",
   "metadata": {},
   "source": [
    "#### 2-2-3-2 ５箇所の平均値で欠損値を補完"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "209de2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = closest_5_for_indices[['元の行番号','抽出された行番号']]\n",
    "for original_index in tmp['元の行番号'].unique():\n",
    "    closest_rows = tmp.loc[tmp['元の行番号'] == original_index, '抽出された行番号']\n",
    "    mean_values = df.iloc[closest_rows,310:3460].mean()\n",
    "    df.iloc[original_index,310:3460] = df.iloc[original_index,310:3460].fillna(\n",
    "        mean_values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67f2651",
   "metadata": {},
   "source": [
    "### 2-2-4　欠損値補間C\n",
    "- 時系列ランドサットデータの欠損値を補完する（測定年と同年の年ごとのランドセット画像MEDで補完する）\n",
    "#### 2-2-4-1 補完対応表の作成\n",
    "   - 時系列ランドサットデータと年毎のランドサット画像MEDの補完する際の列対応表を作成する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0c09e560",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_table = pd.read_csv('df_table_1.csv').reset_index(drop=True)\n",
    "table_dict = {}\n",
    "for index, row in df_table.iterrows():\n",
    "    key = int(row['A'])\n",
    "    value = row['B']    \n",
    "    if pd.notna(value) and float(value).is_integer():\n",
    "        value = int(value)\n",
    "    elif pd.isna(value):\n",
    "        value = float('nan')\n",
    "    table_dict[key] = value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48bce0ab",
   "metadata": {},
   "source": [
    "#### 2-2-4-2 欠損値補完（対応表に従って）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4249950b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# M列の値に応じて欠損値を埋める関数\n",
    "def fillna_based_on_m(row):\n",
    "    m = row[\"year\"]\n",
    "    # M列の値が0から20の範囲内である場合のみ、欠損値を埋める処理を実行\n",
    "    if 1999 <= m <= 2020:\n",
    "        if m != 1999:\n",
    "            start_col = 24\n",
    "            end_col = 84\n",
    "            offset = 150 * (m - 2000)\n",
    "\n",
    "            for i in range(start_col, end_col):\n",
    "                if np.isnan(row[i]):\n",
    "                    if i in table_dict:\n",
    "                        # 対応する列を計算し、値をコピー\n",
    "                        source_col = table_dict[i-23] + 359 + offset\n",
    "                        if not math.isnan(source_col):\n",
    "                            row[i] = row[source_col]\n",
    "                        else:\n",
    "                            row[i] = float(\"nan\")\n",
    "                    else:\n",
    "                        # 対応する列がない場合はNanに\n",
    "                        row[i] = float(\"nan\")\n",
    "        else:\n",
    "            start_col = 24\n",
    "            end_col = 84\n",
    "            offset = 0\n",
    "\n",
    "            for i in range(start_col, end_col):\n",
    "                if np.isnan(row[i]):\n",
    "                    if i in table_dict:\n",
    "                        # 対応する列を計算し、値をコピー\n",
    "                        source_col = table_dict[i-23] + 359 + offset\n",
    "                        if not math.isnan(source_col):\n",
    "                            row[i] = row[source_col]\n",
    "                        else:\n",
    "                            row[i] = float(\"nan\")\n",
    "                    else:\n",
    "                        # 対応する列がない場合はNanに\n",
    "                        row[i] = float(\"nan\")\n",
    "\n",
    "    return row\n",
    "# dfにfillna_based_on_m関数を適用\n",
    "df = df.apply(fillna_based_on_m, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec69588",
   "metadata": {},
   "source": [
    "## 2-3 特徴量作成\n",
    "### 2-3-1 最寄りの'cover'を特徴量に追加\n",
    "- 予測箇所から最も近い場所１０箇所を抽出して、予測箇所からの距離毎に特徴量に追加する\n",
    "- 特徴量追加は、trainデータには、traiｎデータから、testデータにはtrain+testデータから追加する"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605ffd60",
   "metadata": {},
   "source": [
    "#### 2-3-1-1 traiｎデータとtestデータに分割する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a0a29520",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tr = df[df['cover'] != 'a']\n",
    "df_ts = df[df['cover'] == 'a']\n",
    "df_tr_list = df_tr.index\n",
    "df_ts_list = df_ts.index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ebbdac",
   "metadata": {},
   "source": [
    "#### 2-3-1-2 最寄りの１０箇所を抽出する\n",
    "- trainデータ用の１０箇所とtestデータ用の１０箇所それぞれ抽出する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3c4b707b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine_10(lat1, lon1, lat2, lon2):\n",
    "    R = 6371\n",
    "    lat1_rad, lon1_rad = np.radians(lat1), np.radians(lon1)\n",
    "    lat2_rad, lon2_rad = np.radians(lat2), np.radians(lon2)\n",
    "    dlat = lat2_rad - lat1_rad\n",
    "    dlon = lon2_rad - lon1_rad\n",
    "\n",
    "    a = np.sin(dlat / 2) ** 2 + np.cos(lat1_rad) * np.cos(lat2_rad) * np.sin(dlon / 2) ** 2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
    "    return R * c\n",
    "\n",
    "def closest_10_locations(df, index, n, exclude_indices):\n",
    "    target_lat, target_lon = df.loc[index, 'lat'], df.loc[index, 'lon']\n",
    "    distances = df.apply(lambda row: haversine_10(\n",
    "        target_lat, target_lon, row['lat'], row['lon']), axis=1)\n",
    "    distances = distances.drop(exclude_indices)\n",
    "    closest_indices = distances.nsmallest(n+1).iloc[1:].index\n",
    "    closest_rows = df.loc[closest_indices].copy()\n",
    "    closest_rows['元の行番号'] = index  \n",
    "    closest_rows['距離'] = distances[closest_indices].values  # 距離を追加\n",
    "    return closest_rows\n",
    "\n",
    "def closest_10_locations_for_indices(df, indices,exclude_indices, n):\n",
    "    result_df = pd.DataFrame()\n",
    "    for index in indices:\n",
    "        closest_n = closest_n_locations(df, index, n, exclude_indices)\n",
    "        result_df = pd.concat([result_df, closest_n])\n",
    "    return result_df.reset_index().rename(columns={'index': '抽出された行番号'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a24476e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# リスト内の各行番号に対して最も近い場所5箇所を抽出\n",
    "closest_10_for_test = closest_10_locations_for_indices(\n",
    "    df[['lat','lon']], df_ts_list, df_ts_list, 10)\n",
    "closest_10_for_train = closest_10_locations_for_indices(\n",
    "    df[['lat','lon']], df_tr_list, df_ts_list, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f588234",
   "metadata": {},
   "source": [
    "#### 2-3-1-3 抽出した１０箇所を距離毎に分類して特徴量に加える\n",
    "- trainデータ用testデータ用をマージして'cover'の値を取り出せるように加工\n",
    "- ターゲットからの距離が100m未満は’cover_0'列へ100-200m以内は’cover_1'列へ、、、1km以上は'cover_10'列に追加するようにする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "37f9b518",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp_1 = pd.concat([closest_10_for_train,closest_10_for_test]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3a4ce817",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_tmp_1 = df_tmp_1.sort_values(['元の行番号','距離']).groupby(\n",
    "    '元の行番号')['抽出された行番号'].apply(list).reset_index()\n",
    "grouped_tmp_2 = df_tmp_1.sort_values(['元の行番号','距離']).groupby(\n",
    "    '元の行番号')['距離'].apply(list).reset_index()\n",
    "grouped = pd.concat([grouped_tmp_1,grouped_tmp_2['距離']],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4f3f7343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_tmp_3を作成\n",
    "df_tmp_3 = pd.DataFrame()\n",
    "for i, row in grouped.iterrows():\n",
    "    extracted_row_numbers = row['抽出された行番号']\n",
    "    distances = row['距離']\n",
    "    \n",
    "    distance_cover_dict = dict(zip(distances, extracted_row_numbers))\n",
    "    \n",
    "    for j in range(11):\n",
    "        lower_bound = j * 0.1\n",
    "        \n",
    "        if j < 10:\n",
    "            upper_bound = (j + 1) * 0.1\n",
    "            cover_indices = [v for k, v in distance_cover_dict.items() if lower_bound <= k < upper_bound]\n",
    "        else:\n",
    "            cover_indices = [v for k, v in distance_cover_dict.items() if lower_bound <= k]\n",
    "        \n",
    "        if cover_indices:\n",
    "            covers = df.loc[cover_indices, 'cover'].values\n",
    "            df_tmp_3.loc[row['元の行番号'], f'cover_{j}'] = np.mean(covers, dtype=np.float64) \n",
    "        else:\n",
    "            df_tmp_3.loc[row['元の行番号'], f'cover_{j}'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0303b26",
   "metadata": {},
   "source": [
    "#### 2-3-1-4 上記の特徴量の統計値を特徴量に加える\n",
    "- 平均、標準偏差、最大、最小、max-minを加える"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a042d331",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp_3['mean'] = df_tmp_3.mean(axis=1)\n",
    "df_tmp_3['max'] = df_tmp_3.max(axis=1)\n",
    "df_tmp_3['min'] = df_tmp_3.min(axis=1)\n",
    "df_tmp_3['max_min'] = df_tmp_3['max'] - df_tmp_3['min']\n",
    "df_tmp_3['std'] = df_tmp_3.std(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f9441ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df,df_tmp_3],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fa7918",
   "metadata": {},
   "source": [
    "### 2-3-2 外れ値対応\n",
    "- ４分位をとって75%-25%の10倍以上離れた値をNanに置き換え"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "50fca09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(cl_df):\n",
    "    for column in cl_df.columns:\n",
    "        # 列が数値データの場合のみ四分位範囲を計算\n",
    "        if np.issubdtype(cl_df[column].dtypes, np.number):\n",
    "            Q1 = cl_df[column].quantile(0.25)\n",
    "            Q3 = cl_df[column].quantile(0.75)\n",
    "            median = cl_df[column].median()\n",
    "            IQR = Q3 - Q1 \n",
    "            if IQR < median/10 :\n",
    "                # 25%パーセンタイル値と75%パーセンタイル値が同じ場合、平均値の10倍以上を外れ値とする\n",
    "                cl_df[column] = cl_df[column].apply(\n",
    "                    lambda x: x if( median / 10 <= x <= median * 10 )else np.nan)                   \n",
    "            else:\n",
    "                # 外れ値の範囲を定義\n",
    "                lower_bound = Q1 - 10 * IQR\n",
    "                upper_bound = Q3 + 10 * IQR\n",
    "\n",
    "                # 範囲内の値に制限\n",
    "                cl_df[column] = cl_df[column].apply(\n",
    "                    lambda x: x if lower_bound <= x <= upper_bound else np.nan)\n",
    "    return cl_df\n",
    "# 外れ値を取り除いたDataFrameを作成\n",
    "df = remove_outliers(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0531ddaa",
   "metadata": {},
   "source": [
    "### 2-3-3 海洋環境要因データを加工して特徴量に加える\n",
    "- ’cover'に影響があると推測される下記特徴量を追加する\n",
    "    - ’ef_cliff'を追加→'cliff_length'(海崖長)が０ではなく'coastal_dist'(海岸までの距離)が近いと影響があると仮説\n",
    "    - ’ef_art'を追加→'aicial_length'(人工海岸線長）は埋立で'beach_length'(海浜長)’coast_length'と比較して値が大きく、かつ海岸線までの距離が近いと影響があると仮説\n",
    "    - 'ef_bch'を追加→’biach_length'(海浜長）の比率が高く、かつ'coastal_dist'(海岸までの距離)が近いと影響があると仮説\n",
    "    - 'ef_river'を追加→’river_area'(集水面積)が大きく'river_dist'(河口までの距離）が近いと影響があると仮説"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3c434927",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df['cliff_length'].isnull()) & \n",
    "       (~df['aicial_length'].isnull() | \n",
    "        ~df['beach_length'].isnull()), 'cliff_length'] = 1\n",
    "# df_tmp['ef_cliff'] = df['cliff_length']\n",
    "df['ef_cliff'] = df.apply(\n",
    "    lambda row: row['cliff_length'] * 2 \n",
    "    if row['coastal_dist'] == 0 else row['cliff_length'] / row['coastal_dist'], axis=1)\n",
    "\n",
    "df['ef_art'] = df['aicial_length'] \\\n",
    "/ (df['aicial_length'] + df['beach_length'])\n",
    "df.loc[(df['ef_art'].isnull()) & (\n",
    "    ~df['aicial_length'].isnull() | ~df['beach_length'].isnull()), 'ef_art'] = 0\n",
    "\n",
    "df['ef_art'] = df.apply(\n",
    "    lambda row: row['ef_art'] * 2 \n",
    "    if row['coastal_dist'] == 0 else row['ef_art'] / row['coastal_dist'], axis=1)\n",
    "\n",
    "df['ef_bch'] = df['beach_length'] / df['coast_length'].replace(0, float('inf'))\n",
    "df['ef_bch'] = df['ef_bch'].replace(float('inf'), 0)\n",
    "df['ef_bch'] = df['ef_bch'] * df['coast_length']\n",
    "df['ef_bch'] = df.apply(\n",
    "    lambda row: row['ef_bch'] * 2 \n",
    "    if row['coastal_dist'] == 0 else row['ef_bch'] / row['coastal_dist'], axis=1)\n",
    "df['ef_river'] = df['river_area'] / df['river_dist']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e91aa9f",
   "metadata": {},
   "source": [
    "# 3 学習\n",
    "## 3-1 学習用データ作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "68e60ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df[df['cover'] != 'a']\n",
    "df_train['cover'] = df_train['cover'].astype(float)\n",
    "col_cat = ['mesh20','cluster_id','cls_id_2']\n",
    "for col in col_cat:\n",
    "    df_train[col] = df_train[col].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "84e37735",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop(columns=['cover'])\n",
    "y_train = df_train[[\"cover\",'cluster_id','cls_id_2']]\n",
    "id_train = pd.DataFrame(df_train.index)\n",
    "id_train['cluster_id'] = df_train['cluster_id']\n",
    "id_train['cls_id_2'] = df_train['cls_id_2']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4b1486",
   "metadata": {},
   "source": [
    "## 3-2 学習\n",
    "### 3-2-1 全データを一括学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f7bed096",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lgb_1(input_X,\n",
    "              input_y,\n",
    "              input_id,\n",
    "              params,\n",
    "              list_nfold=[0,1,2,3,4],\n",
    "              n_splits=5,\n",
    "             ):\n",
    "    train_oof = np.zeros(len(input_X))\n",
    "    metrics = []\n",
    "    imp = pd.DataFrame()\n",
    "    input_y = input_y.drop(columns=['cluster_id','cls_id_2'])\n",
    "    input_id = input_id.drop(columns=['cluster_id','cls_id_2'])\n",
    "                             \n",
    "    cv = list(KFold(n_splits, random_state=123, shuffle=True).split(input_X, input_y))\n",
    "    for nfold in list_nfold:\n",
    "        print(\"-\"*20, nfold, \"-\"*20)\n",
    "        idx_tr, idx_va = cv[nfold][0], cv[nfold][1]\n",
    "        X_tr, y_tr, id_tr = input_X.loc[idx_tr, :], input_y.loc[idx_tr], input_id.loc[idx_tr, :]\n",
    "        X_va, y_va, id_va = input_X.loc[idx_va, :], input_y.loc[idx_va], input_id.loc[idx_va, :]\n",
    "        print(X_tr.shape, y_tr.shape)\n",
    "        \n",
    "        #train\n",
    "        model = lgb.LGBMRegressor(**params)\n",
    "        model.fit(X_tr,\n",
    "                  y_tr,\n",
    "                  eval_set=[(X_tr,y_tr), (X_va,y_va)],\n",
    "                  early_stopping_rounds=50,\n",
    "                  verbose=100,\n",
    "                 )\n",
    "        fname_lgb = \"model_sbmt_1_6_lgb_fold{}.pickle\".format(nfold)\n",
    "        with open(fname_lgb, \"wb\") as f:\n",
    "            pickle.dump(model, f, protocol=4)\n",
    "        \n",
    "        #evaluate\n",
    "        y_tr_pred = model.predict(X_tr)\n",
    "        y_va_pred = model.predict(X_va)\n",
    "        metric_tr = np.sqrt(mean_squared_error(y_tr, y_tr_pred))\n",
    "        metric_va = np.sqrt(mean_squared_error(y_va, y_va_pred))\n",
    "        metrics.append([nfold, metric_tr, metric_va])\n",
    "        print(\"[RMSE] tr: {:.4f}, va: {:.4f}\".format(metric_tr, metric_va))\n",
    "        \n",
    "        # oof\n",
    "        train_oof[idx_va] = y_va_pred\n",
    "        \n",
    "        # imp\n",
    "        _imp = pd.DataFrame({\"col\": input_X.columns, \n",
    "                             \"imp\": model.feature_importances_,\"nfold\":nfold})\n",
    "        imp = pd.concat([imp, _imp])\n",
    "    \n",
    "    # metric\n",
    "    print(\"-\"*20, \"result\", \"-\"*20)\n",
    "    metrics = np.array(metrics)\n",
    "    print(metrics)\n",
    "    print(\"[cv] tr: {:.4f}+-{:.4f}, va: {:.4f}+-{:.4f}\".format(\n",
    "        metrics[:,1].mean(), metrics[:,1].std(),\n",
    "        metrics[:,2].mean(), metrics[:,2].std(),\n",
    "    ))\n",
    "    print(\"[oof]{:.4f}\".format(np.sqrt(mean_squared_error(input_y, train_oof))))\n",
    "    \n",
    "    # oof\n",
    "    train_oof = pd.concat([input_id, pd.DataFrame({\"pred\" : train_oof})], axis=1)\n",
    "    \n",
    "    # importance\n",
    "    imp = imp.groupby(\"col\")[\"imp\"].agg([\"mean\", \"std\"]).reset_index(drop=False)\n",
    "    imp.columns = [\"col\", \"imp\", \"imp_std\"]\n",
    "    \n",
    "    return train_oof, imp, metrics     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3927062a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 0 --------------------\n",
      "(11312, 3482) (11312, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.0799263\tvalid_1's rmse: 0.116828\n",
      "[200]\ttraining's rmse: 0.0642602\tvalid_1's rmse: 0.114661\n",
      "[300]\ttraining's rmse: 0.0538535\tvalid_1's rmse: 0.112897\n",
      "[400]\ttraining's rmse: 0.0464674\tvalid_1's rmse: 0.111868\n",
      "[500]\ttraining's rmse: 0.0410587\tvalid_1's rmse: 0.111289\n",
      "[600]\ttraining's rmse: 0.0368198\tvalid_1's rmse: 0.110879\n",
      "[700]\ttraining's rmse: 0.0332483\tvalid_1's rmse: 0.11051\n",
      "[800]\ttraining's rmse: 0.0304542\tvalid_1's rmse: 0.110225\n",
      "[900]\ttraining's rmse: 0.0279867\tvalid_1's rmse: 0.110048\n",
      "[1000]\ttraining's rmse: 0.0259353\tvalid_1's rmse: 0.109964\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's rmse: 0.0259353\tvalid_1's rmse: 0.109964\n",
      "[RMSE] tr: 0.0259, va: 0.1100\n",
      "-------------------- 1 --------------------\n",
      "(11312, 3482) (11312, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.078439\tvalid_1's rmse: 0.117851\n",
      "[200]\ttraining's rmse: 0.0624626\tvalid_1's rmse: 0.116535\n",
      "[300]\ttraining's rmse: 0.052062\tvalid_1's rmse: 0.115952\n",
      "[400]\ttraining's rmse: 0.0446034\tvalid_1's rmse: 0.115307\n",
      "[500]\ttraining's rmse: 0.0392086\tvalid_1's rmse: 0.11519\n",
      "Early stopping, best iteration is:\n",
      "[464]\ttraining's rmse: 0.0409861\tvalid_1's rmse: 0.115067\n",
      "[RMSE] tr: 0.0410, va: 0.1151\n",
      "-------------------- 2 --------------------\n",
      "(11312, 3482) (11312, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.0812867\tvalid_1's rmse: 0.105695\n",
      "[200]\ttraining's rmse: 0.0645491\tvalid_1's rmse: 0.102778\n",
      "[300]\ttraining's rmse: 0.0541632\tvalid_1's rmse: 0.102085\n",
      "[400]\ttraining's rmse: 0.0465343\tvalid_1's rmse: 0.101611\n",
      "[500]\ttraining's rmse: 0.0409045\tvalid_1's rmse: 0.101295\n",
      "[600]\ttraining's rmse: 0.0364307\tvalid_1's rmse: 0.101039\n",
      "Early stopping, best iteration is:\n",
      "[616]\ttraining's rmse: 0.035789\tvalid_1's rmse: 0.101025\n",
      "[RMSE] tr: 0.0358, va: 0.1010\n",
      "-------------------- 3 --------------------\n",
      "(11312, 3482) (11312, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.0790304\tvalid_1's rmse: 0.11279\n",
      "[200]\ttraining's rmse: 0.0630364\tvalid_1's rmse: 0.111782\n",
      "[300]\ttraining's rmse: 0.0527501\tvalid_1's rmse: 0.111109\n",
      "Early stopping, best iteration is:\n",
      "[328]\ttraining's rmse: 0.0504321\tvalid_1's rmse: 0.110972\n",
      "[RMSE] tr: 0.0504, va: 0.1110\n",
      "-------------------- 4 --------------------\n",
      "(11312, 3482) (11312, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.0808\tvalid_1's rmse: 0.109431\n",
      "[200]\ttraining's rmse: 0.0648869\tvalid_1's rmse: 0.107469\n",
      "[300]\ttraining's rmse: 0.0544013\tvalid_1's rmse: 0.106133\n",
      "[400]\ttraining's rmse: 0.046973\tvalid_1's rmse: 0.105398\n",
      "[500]\ttraining's rmse: 0.0412386\tvalid_1's rmse: 0.105218\n",
      "[600]\ttraining's rmse: 0.0368474\tvalid_1's rmse: 0.10495\n",
      "[700]\ttraining's rmse: 0.0332532\tvalid_1's rmse: 0.104578\n",
      "Early stopping, best iteration is:\n",
      "[703]\ttraining's rmse: 0.0331644\tvalid_1's rmse: 0.104575\n",
      "[RMSE] tr: 0.0332, va: 0.1046\n",
      "-------------------- result --------------------\n",
      "[[0.         0.02593529 0.1099637 ]\n",
      " [1.         0.04098608 0.1150667 ]\n",
      " [2.         0.03578896 0.1010246 ]\n",
      " [3.         0.05043215 0.11097162]\n",
      " [4.         0.03316445 0.10457523]]\n",
      "[cv] tr: 0.0373+-0.0082, va: 0.1083+-0.0049\n",
      "[oof]0.1084\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression_l2',\n",
    "    'metric': 'Root_Mean_Squared_Error',\n",
    "    'learning_rate': 0.05,\n",
    "    'num_leaves': 32,\n",
    "    'subsample': 0.7,\n",
    "    'subsample_freq': 1,\n",
    "    'feature_fraction': 0.8,\n",
    "    'min_data_in_leaf': 50,\n",
    "    'min_sum_hessian_in_leaf': 50,\n",
    "    'n_estimators': 1000,\n",
    "    'random_state': 123,\n",
    "    'importance_type': 'gain',\n",
    "}\n",
    "\n",
    "train_oof, imp, metrics = train_lgb_1(X_train,\n",
    "                                    y_train,\n",
    "                                    id_train,\n",
    "                                    params,\n",
    "                                    list_nfold=[0,1,2,3,4],\n",
    "                                    n_splits=5,\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "bd4242c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col</th>\n",
       "      <th>imp</th>\n",
       "      <th>imp_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3442</th>\n",
       "      <td>cover_0</td>\n",
       "      <td>3162.108555</td>\n",
       "      <td>22.949851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3470</th>\n",
       "      <td>min</td>\n",
       "      <td>554.126198</td>\n",
       "      <td>37.535101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3468</th>\n",
       "      <td>mean</td>\n",
       "      <td>490.754809</td>\n",
       "      <td>39.652152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3477</th>\n",
       "      <td>std</td>\n",
       "      <td>152.779309</td>\n",
       "      <td>27.562692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3466</th>\n",
       "      <td>max</td>\n",
       "      <td>55.513771</td>\n",
       "      <td>8.814508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3445</th>\n",
       "      <td>cover_2</td>\n",
       "      <td>13.557671</td>\n",
       "      <td>2.229298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3443</th>\n",
       "      <td>cover_1</td>\n",
       "      <td>10.553051</td>\n",
       "      <td>3.505403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2739</th>\n",
       "      <td>MIN_GARI</td>\n",
       "      <td>9.227729</td>\n",
       "      <td>2.863154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3467</th>\n",
       "      <td>max_min</td>\n",
       "      <td>6.965922</td>\n",
       "      <td>0.729239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3471</th>\n",
       "      <td>month</td>\n",
       "      <td>6.924054</td>\n",
       "      <td>0.679165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1128</th>\n",
       "      <td>MAX_mCRIG_2015</td>\n",
       "      <td>6.277777</td>\n",
       "      <td>3.657101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3469</th>\n",
       "      <td>mesh20</td>\n",
       "      <td>5.761950</td>\n",
       "      <td>1.434560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3358</th>\n",
       "      <td>MIN_VARIgreen_2016</td>\n",
       "      <td>4.729706</td>\n",
       "      <td>1.867739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2225</th>\n",
       "      <td>MED_VARIgreen_2008</td>\n",
       "      <td>4.571204</td>\n",
       "      <td>3.714597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3454</th>\n",
       "      <td>depth_original</td>\n",
       "      <td>4.516488</td>\n",
       "      <td>1.376004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3425</th>\n",
       "      <td>SLAVI</td>\n",
       "      <td>4.439517</td>\n",
       "      <td>1.160474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3476</th>\n",
       "      <td>sst_ymd</td>\n",
       "      <td>4.294799</td>\n",
       "      <td>1.462969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3475</th>\n",
       "      <td>sst_diff</td>\n",
       "      <td>4.213326</td>\n",
       "      <td>1.217281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1863</th>\n",
       "      <td>MED_MVI</td>\n",
       "      <td>3.630352</td>\n",
       "      <td>1.822042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2232</th>\n",
       "      <td>MED_VARIgreen_2015</td>\n",
       "      <td>3.443518</td>\n",
       "      <td>1.733397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>MAX_CSI</td>\n",
       "      <td>3.303420</td>\n",
       "      <td>1.025476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1855</th>\n",
       "      <td>MED_MCARI_MTVI2</td>\n",
       "      <td>3.176909</td>\n",
       "      <td>0.882349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2221</th>\n",
       "      <td>MED_VARIgreen_2004</td>\n",
       "      <td>3.118787</td>\n",
       "      <td>1.417671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Date_Acquired</td>\n",
       "      <td>2.980082</td>\n",
       "      <td>1.074208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3161</th>\n",
       "      <td>MIN_RDVI_2013</td>\n",
       "      <td>2.953449</td>\n",
       "      <td>2.221647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3430</th>\n",
       "      <td>TIRS2</td>\n",
       "      <td>2.914438</td>\n",
       "      <td>1.478317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3432</th>\n",
       "      <td>VARIgreen</td>\n",
       "      <td>2.913731</td>\n",
       "      <td>0.642642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>MAX_VARIgreen_2004</td>\n",
       "      <td>2.860686</td>\n",
       "      <td>1.450497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3419</th>\n",
       "      <td>PPR</td>\n",
       "      <td>2.784364</td>\n",
       "      <td>0.958523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1106</th>\n",
       "      <td>MAX_VARIgreen_2015</td>\n",
       "      <td>2.762636</td>\n",
       "      <td>1.123053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     col          imp    imp_std\n",
       "3442             cover_0  3162.108555  22.949851\n",
       "3470                 min   554.126198  37.535101\n",
       "3468                mean   490.754809  39.652152\n",
       "3477                 std   152.779309  27.562692\n",
       "3466                 max    55.513771   8.814508\n",
       "3445             cover_2    13.557671   2.229298\n",
       "3443             cover_1    10.553051   3.505403\n",
       "2739            MIN_GARI     9.227729   2.863154\n",
       "3467             max_min     6.965922   0.729239\n",
       "3471               month     6.924054   0.679165\n",
       "1128      MAX_mCRIG_2015     6.277777   3.657101\n",
       "3469              mesh20     5.761950   1.434560\n",
       "3358  MIN_VARIgreen_2016     4.729706   1.867739\n",
       "2225  MED_VARIgreen_2008     4.571204   3.714597\n",
       "3454      depth_original     4.516488   1.376004\n",
       "3425               SLAVI     4.439517   1.160474\n",
       "3476             sst_ymd     4.294799   1.462969\n",
       "3475            sst_diff     4.213326   1.217281\n",
       "1863             MED_MVI     3.630352   1.822042\n",
       "2232  MED_VARIgreen_2015     3.443518   1.733397\n",
       "184              MAX_CSI     3.303420   1.025476\n",
       "1855     MED_MCARI_MTVI2     3.176909   0.882349\n",
       "2221  MED_VARIgreen_2004     3.118787   1.417671\n",
       "16         Date_Acquired     2.980082   1.074208\n",
       "3161       MIN_RDVI_2013     2.953449   2.221647\n",
       "3430               TIRS2     2.914438   1.478317\n",
       "3432           VARIgreen     2.913731   0.642642\n",
       "1095  MAX_VARIgreen_2004     2.860686   1.450497\n",
       "3419                 PPR     2.784364   0.958523\n",
       "1106  MAX_VARIgreen_2015     2.762636   1.123053"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp.sort_values('imp',ascending=False).head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2277b20b",
   "metadata": {},
   "source": [
    "### 3-2-2 地理的な３つの区域毎に学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "263d8d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lgb_3(input_X,\n",
    "              input_y,\n",
    "              input_id,\n",
    "              params,\n",
    "              list_nfold=[0, 1, 2, 3, 4],\n",
    "              n_splits=5,\n",
    "              ):\n",
    "    metrics_list = []\n",
    "    train_oof_list =[]\n",
    "    imp_list =[]\n",
    "    for i in range(3):\n",
    "            tmp_X = input_X[input_X['cluster_id'] == i]\n",
    "            tmp_y = input_y[input_y['cluster_id'] == i]\n",
    "            tmp_id = input_id[input_id['cluster_id'] == i]\n",
    "\n",
    "            tmp_y.drop(columns=['cluster_id','cls_id_2'], inplace=True)\n",
    "            tmp_id.drop(columns=['cluster_id','cls_id_2'], inplace=True)\n",
    "            tmp_X.reset_index(drop=True, inplace=True)\n",
    "            tmp_y.reset_index(drop=True, inplace=True)\n",
    "            tmp_id.reset_index(drop=True, inplace=True)\n",
    "\n",
    "            train_oof = np.zeros(len(tmp_X))\n",
    "            metrics = []\n",
    "            imp = pd.DataFrame()\n",
    "\n",
    "                # cross-validation\n",
    "            cv = list(KFold(n_splits, random_state=123, shuffle=True).split(\n",
    "                    tmp_X, tmp_y))\n",
    "\n",
    "            for nfold in list_nfold:\n",
    "                print(\"-\" * 20, nfold, \"-\" * 20)\n",
    "                idx_tr, idx_va = cv[nfold][0], cv[nfold][1]\n",
    "                X_tr, y_tr, id_tr = tmp_X.loc[idx_tr, :], tmp_y.loc[idx_tr], \\\n",
    "                                    tmp_id.loc[idx_tr, :]\n",
    "                X_va, y_va, id_va = tmp_X.loc[idx_va, :], tmp_y.loc[idx_va], \\\n",
    "                                    tmp_id.loc[idx_va, :]\n",
    "                print(X_tr.shape, y_tr.shape)\n",
    "\n",
    "                # train\n",
    "                model = lgb.LGBMRegressor(**params)\n",
    "                model.fit(X_tr,\n",
    "                          y_tr,\n",
    "                          eval_set=[(X_tr, y_tr), (X_va, y_va)],\n",
    "                          early_stopping_rounds=50,\n",
    "                          verbose=100,\n",
    "                         )\n",
    "                fname_lgb = \"model_sbmt_1_6_cls{0}_lgb_fold{1}.pickle\".format(i, nfold)\n",
    "                with open(fname_lgb, \"wb\") as f:\n",
    "                    pickle.dump(model, f, protocol=4)\n",
    "                    \n",
    "                # evaluate\n",
    "                y_tr_pred = model.predict(X_tr)\n",
    "                y_va_pred = model.predict(X_va)\n",
    "                metric_tr = np.sqrt(mean_squared_error(y_tr, y_tr_pred))\n",
    "                metric_va = np.sqrt(mean_squared_error(y_va, y_va_pred))\n",
    "                metrics.append([nfold, metric_tr, metric_va])\n",
    "                print(\"[RMSE] tr: {:.4f}, va: {:.4f}\".format(metric_tr, metric_va))\n",
    "\n",
    "                # oof\n",
    "                train_oof[idx_va] = y_va_pred\n",
    "\n",
    "                # imp\n",
    "                _imp = pd.DataFrame(\n",
    "                    {\"col\": tmp_X.columns, \"imp\": model.feature_importances_, \n",
    "                     \"nfold\": nfold})\n",
    "                imp = pd.concat([imp, _imp])\n",
    "\n",
    "            # metric\n",
    "            print(\"-\" * 20, \"cls{}_result\".format(i), \"-\" * 20)\n",
    "            metrics = np.array(metrics)\n",
    "            print(metrics)\n",
    "            print(\"[cv] tr: {:.4f}+-{:.4f}, va: {:.4f}+-{:.4f}\".format(\n",
    "                metrics[:, 1].mean(), metrics[:, 1].std(),\n",
    "                metrics[:, 2].mean(), metrics[:, 2].std(),\n",
    "                ))\n",
    "            print(\"[oof]{:.4f}\".format(np.sqrt(mean_squared_error(tmp_y, train_oof))))\n",
    "            metrics_list.append(metrics)\n",
    "\n",
    "            # oof\n",
    "            train_oof = pd.concat([tmp_id, pd.DataFrame({\"pred\": train_oof})], axis=1)\n",
    "            train_oof_list.append(train_oof)\n",
    "\n",
    "            # importance\n",
    "            imp = imp.groupby(\"col\")[\"imp\"].agg([\"mean\", \"std\"]).reset_index(drop=False)\n",
    "            imp.columns = [\"col\", \"imp\", \"imp_std\"]\n",
    "            imp_list.append(imp)\n",
    "\n",
    "    return train_oof_list, imp_list, metrics_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f4e3b490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 0 --------------------\n",
      "(4077, 3482) (4077, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.0775861\tvalid_1's rmse: 0.112777\n",
      "[200]\ttraining's rmse: 0.0539212\tvalid_1's rmse: 0.112039\n",
      "[300]\ttraining's rmse: 0.0407875\tvalid_1's rmse: 0.111551\n",
      "Early stopping, best iteration is:\n",
      "[258]\ttraining's rmse: 0.0454688\tvalid_1's rmse: 0.111342\n",
      "[RMSE] tr: 0.0455, va: 0.1113\n",
      "-------------------- 1 --------------------\n",
      "(4077, 3482) (4077, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.0764944\tvalid_1's rmse: 0.128759\n",
      "[200]\ttraining's rmse: 0.0527425\tvalid_1's rmse: 0.127488\n",
      "[300]\ttraining's rmse: 0.0395808\tvalid_1's rmse: 0.126536\n",
      "[400]\ttraining's rmse: 0.0312278\tvalid_1's rmse: 0.126321\n",
      "Early stopping, best iteration is:\n",
      "[383]\ttraining's rmse: 0.0323727\tvalid_1's rmse: 0.126205\n",
      "[RMSE] tr: 0.0324, va: 0.1262\n",
      "-------------------- 2 --------------------\n",
      "(4078, 3482) (4078, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.0758783\tvalid_1's rmse: 0.131892\n",
      "[200]\ttraining's rmse: 0.0525796\tvalid_1's rmse: 0.13053\n",
      "[300]\ttraining's rmse: 0.0395194\tvalid_1's rmse: 0.12945\n",
      "[400]\ttraining's rmse: 0.0315665\tvalid_1's rmse: 0.12884\n",
      "[500]\ttraining's rmse: 0.0263382\tvalid_1's rmse: 0.128804\n",
      "[600]\ttraining's rmse: 0.0226893\tvalid_1's rmse: 0.128434\n",
      "Early stopping, best iteration is:\n",
      "[615]\ttraining's rmse: 0.0222419\tvalid_1's rmse: 0.128404\n",
      "[RMSE] tr: 0.0222, va: 0.1284\n",
      "-------------------- 3 --------------------\n",
      "(4078, 3482) (4078, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.0782037\tvalid_1's rmse: 0.119535\n",
      "[200]\ttraining's rmse: 0.0546591\tvalid_1's rmse: 0.117128\n",
      "[300]\ttraining's rmse: 0.0418201\tvalid_1's rmse: 0.115532\n",
      "Early stopping, best iteration is:\n",
      "[317]\ttraining's rmse: 0.0401734\tvalid_1's rmse: 0.115281\n",
      "[RMSE] tr: 0.0402, va: 0.1153\n",
      "-------------------- 4 --------------------\n",
      "(4078, 3482) (4078, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.0758064\tvalid_1's rmse: 0.131712\n",
      "[200]\ttraining's rmse: 0.0529366\tvalid_1's rmse: 0.129307\n",
      "[300]\ttraining's rmse: 0.040361\tvalid_1's rmse: 0.127469\n",
      "[400]\ttraining's rmse: 0.0325315\tvalid_1's rmse: 0.126688\n",
      "[500]\ttraining's rmse: 0.0274031\tvalid_1's rmse: 0.125827\n",
      "[600]\ttraining's rmse: 0.0236738\tvalid_1's rmse: 0.125572\n",
      "[700]\ttraining's rmse: 0.0210047\tvalid_1's rmse: 0.125075\n",
      "[800]\ttraining's rmse: 0.0190355\tvalid_1's rmse: 0.124968\n",
      "[900]\ttraining's rmse: 0.0175147\tvalid_1's rmse: 0.124714\n",
      "[1000]\ttraining's rmse: 0.0162748\tvalid_1's rmse: 0.124631\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's rmse: 0.0162748\tvalid_1's rmse: 0.124631\n",
      "[RMSE] tr: 0.0163, va: 0.1246\n",
      "-------------------- cls0_result --------------------\n",
      "[[0.         0.04546878 0.11134173]\n",
      " [1.         0.03237271 0.12620493]\n",
      " [2.         0.02224194 0.12840409]\n",
      " [3.         0.04017336 0.11528105]\n",
      " [4.         0.01627479 0.12463069]]\n",
      "[cv] tr: 0.0313+-0.0108, va: 0.1212+-0.0066\n",
      "[oof]0.1214\n",
      "-------------------- 0 --------------------\n",
      "(5162, 3482) (5162, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.0736842\tvalid_1's rmse: 0.107027\n",
      "[200]\ttraining's rmse: 0.0557344\tvalid_1's rmse: 0.103999\n",
      "[300]\ttraining's rmse: 0.045229\tvalid_1's rmse: 0.103395\n",
      "[400]\ttraining's rmse: 0.0380968\tvalid_1's rmse: 0.10247\n",
      "[500]\ttraining's rmse: 0.0330063\tvalid_1's rmse: 0.102004\n",
      "[600]\ttraining's rmse: 0.0293388\tvalid_1's rmse: 0.101621\n",
      "[700]\ttraining's rmse: 0.0264588\tvalid_1's rmse: 0.101468\n",
      "[800]\ttraining's rmse: 0.0242076\tvalid_1's rmse: 0.10122\n",
      "[900]\ttraining's rmse: 0.022368\tvalid_1's rmse: 0.101049\n",
      "Early stopping, best iteration is:\n",
      "[879]\ttraining's rmse: 0.0227073\tvalid_1's rmse: 0.10099\n",
      "[RMSE] tr: 0.0227, va: 0.1010\n",
      "-------------------- 1 --------------------\n",
      "(5162, 3482) (5162, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.0730109\tvalid_1's rmse: 0.10767\n",
      "[200]\ttraining's rmse: 0.0547188\tvalid_1's rmse: 0.10487\n",
      "[300]\ttraining's rmse: 0.0439102\tvalid_1's rmse: 0.103858\n",
      "[400]\ttraining's rmse: 0.0368104\tvalid_1's rmse: 0.103255\n",
      "Early stopping, best iteration is:\n",
      "[395]\ttraining's rmse: 0.037097\tvalid_1's rmse: 0.103185\n",
      "[RMSE] tr: 0.0371, va: 0.1032\n",
      "-------------------- 2 --------------------\n",
      "(5162, 3482) (5162, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.0720694\tvalid_1's rmse: 0.116171\n",
      "[200]\ttraining's rmse: 0.0541205\tvalid_1's rmse: 0.11492\n",
      "[300]\ttraining's rmse: 0.0439058\tvalid_1's rmse: 0.114406\n",
      "[400]\ttraining's rmse: 0.0369237\tvalid_1's rmse: 0.113745\n",
      "[500]\ttraining's rmse: 0.0318864\tvalid_1's rmse: 0.113422\n",
      "[600]\ttraining's rmse: 0.0282915\tvalid_1's rmse: 0.11323\n",
      "[700]\ttraining's rmse: 0.0254808\tvalid_1's rmse: 0.113053\n",
      "[800]\ttraining's rmse: 0.0232556\tvalid_1's rmse: 0.113015\n",
      "Early stopping, best iteration is:\n",
      "[767]\ttraining's rmse: 0.0239002\tvalid_1's rmse: 0.11292\n",
      "[RMSE] tr: 0.0239, va: 0.1129\n",
      "-------------------- 3 --------------------\n",
      "(5163, 3482) (5163, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.0739279\tvalid_1's rmse: 0.104521\n",
      "[200]\ttraining's rmse: 0.0551448\tvalid_1's rmse: 0.102013\n",
      "[300]\ttraining's rmse: 0.0442129\tvalid_1's rmse: 0.100724\n",
      "[400]\ttraining's rmse: 0.0369986\tvalid_1's rmse: 0.10003\n",
      "[500]\ttraining's rmse: 0.031874\tvalid_1's rmse: 0.0993602\n",
      "[600]\ttraining's rmse: 0.0281274\tvalid_1's rmse: 0.0991129\n",
      "Early stopping, best iteration is:\n",
      "[592]\ttraining's rmse: 0.0283849\tvalid_1's rmse: 0.0990345\n",
      "[RMSE] tr: 0.0284, va: 0.0990\n",
      "-------------------- 4 --------------------\n",
      "(5163, 3482) (5163, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.0714647\tvalid_1's rmse: 0.111123\n",
      "[200]\ttraining's rmse: 0.0534248\tvalid_1's rmse: 0.109266\n",
      "[300]\ttraining's rmse: 0.0432749\tvalid_1's rmse: 0.107861\n",
      "[400]\ttraining's rmse: 0.0363024\tvalid_1's rmse: 0.107157\n",
      "[500]\ttraining's rmse: 0.0314319\tvalid_1's rmse: 0.10659\n",
      "[600]\ttraining's rmse: 0.0278328\tvalid_1's rmse: 0.106171\n",
      "[700]\ttraining's rmse: 0.0251554\tvalid_1's rmse: 0.106006\n",
      "[800]\ttraining's rmse: 0.02297\tvalid_1's rmse: 0.105748\n",
      "[900]\ttraining's rmse: 0.021218\tvalid_1's rmse: 0.105644\n",
      "Early stopping, best iteration is:\n",
      "[900]\ttraining's rmse: 0.021218\tvalid_1's rmse: 0.105644\n",
      "[RMSE] tr: 0.0212, va: 0.1056\n",
      "-------------------- cls1_result --------------------\n",
      "[[0.         0.02270733 0.10098956]\n",
      " [1.         0.03709703 0.10318531]\n",
      " [2.         0.02390023 0.11292029]\n",
      " [3.         0.02838491 0.09903454]\n",
      " [4.         0.02121805 0.10564355]]\n",
      "[cv] tr: 0.0267+-0.0057, va: 0.1044+-0.0048\n",
      "[oof]0.1045\n",
      "-------------------- 0 --------------------\n",
      "(2072, 3482) (2072, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.0717777\tvalid_1's rmse: 0.0846936\n",
      "[200]\ttraining's rmse: 0.0565992\tvalid_1's rmse: 0.0818699\n",
      "[300]\ttraining's rmse: 0.046346\tvalid_1's rmse: 0.0804893\n",
      "[400]\ttraining's rmse: 0.0386534\tvalid_1's rmse: 0.0798751\n",
      "Early stopping, best iteration is:\n",
      "[351]\ttraining's rmse: 0.0421582\tvalid_1's rmse: 0.0797395\n",
      "[RMSE] tr: 0.0422, va: 0.0797\n",
      "-------------------- 1 --------------------\n",
      "(2072, 3482) (2072, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.0672163\tvalid_1's rmse: 0.108547\n",
      "[200]\ttraining's rmse: 0.0530432\tvalid_1's rmse: 0.106057\n",
      "[300]\ttraining's rmse: 0.0439592\tvalid_1's rmse: 0.105072\n",
      "[400]\ttraining's rmse: 0.0372892\tvalid_1's rmse: 0.104083\n",
      "[500]\ttraining's rmse: 0.0321004\tvalid_1's rmse: 0.103462\n",
      "[600]\ttraining's rmse: 0.0280885\tvalid_1's rmse: 0.103205\n",
      "Early stopping, best iteration is:\n",
      "[559]\ttraining's rmse: 0.0296882\tvalid_1's rmse: 0.103073\n",
      "[RMSE] tr: 0.0297, va: 0.1031\n",
      "-------------------- 2 --------------------\n",
      "(2072, 3482) (2072, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.0698171\tvalid_1's rmse: 0.08652\n",
      "Early stopping, best iteration is:\n",
      "[74]\ttraining's rmse: 0.0755393\tvalid_1's rmse: 0.0857626\n",
      "[RMSE] tr: 0.0755, va: 0.0858\n",
      "-------------------- 3 --------------------\n",
      "(2072, 3482) (2072, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.0685594\tvalid_1's rmse: 0.0911887\n",
      "[200]\ttraining's rmse: 0.053847\tvalid_1's rmse: 0.0893443\n",
      "[300]\ttraining's rmse: 0.0442457\tvalid_1's rmse: 0.0880138\n",
      "[400]\ttraining's rmse: 0.0375393\tvalid_1's rmse: 0.0869776\n",
      "Early stopping, best iteration is:\n",
      "[407]\ttraining's rmse: 0.0371703\tvalid_1's rmse: 0.0867993\n",
      "[RMSE] tr: 0.0372, va: 0.0868\n",
      "-------------------- 4 --------------------\n",
      "(2072, 3482) (2072, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.0693175\tvalid_1's rmse: 0.0944337\n",
      "[200]\ttraining's rmse: 0.0542805\tvalid_1's rmse: 0.0915478\n",
      "[300]\ttraining's rmse: 0.0435857\tvalid_1's rmse: 0.0901314\n",
      "[400]\ttraining's rmse: 0.0359233\tvalid_1's rmse: 0.0886734\n",
      "[500]\ttraining's rmse: 0.030413\tvalid_1's rmse: 0.0878618\n",
      "[600]\ttraining's rmse: 0.0262137\tvalid_1's rmse: 0.0874096\n",
      "Early stopping, best iteration is:\n",
      "[586]\ttraining's rmse: 0.0268135\tvalid_1's rmse: 0.0871912\n",
      "[RMSE] tr: 0.0268, va: 0.0872\n",
      "-------------------- cls2_result --------------------\n",
      "[[0.         0.04215817 0.07973951]\n",
      " [1.         0.02968822 0.10307291]\n",
      " [2.         0.07553931 0.08576264]\n",
      " [3.         0.03717035 0.08679931]\n",
      " [4.         0.02681353 0.08719117]]\n",
      "[cv] tr: 0.0423+-0.0175, va: 0.0885+-0.0078\n",
      "[oof]0.0889\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression_l2',\n",
    "    'metric': 'Root_Mean_Squared_Error',\n",
    "    'learning_rate': 0.05,\n",
    "    'num_leaves': 32,\n",
    "    'subsample': 0.7,\n",
    "    'subsample_freq': 1,\n",
    "    'feature_fraction': 0.8,\n",
    "    'min_data_in_leaf': 50,\n",
    "    'min_sum_hessian_in_leaf': 50,\n",
    "    'n_estimators': 1000,\n",
    "    'random_state': 123,\n",
    "    'importance_type': 'gain',\n",
    "}\n",
    "\n",
    "train_oof, imp, metrics = train_lgb_3(X_train,\n",
    "                                    y_train,\n",
    "                                    id_train,\n",
    "                                    params,\n",
    "                                    list_nfold=[0,1,2,3,4],\n",
    "                                    n_splits=5,\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e604cb86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.        , 0.04546878, 0.11134173],\n",
       "        [1.        , 0.03237271, 0.12620493],\n",
       "        [2.        , 0.02224194, 0.12840409],\n",
       "        [3.        , 0.04017336, 0.11528105],\n",
       "        [4.        , 0.01627479, 0.12463069]]),\n",
       " array([[0.        , 0.02270733, 0.10098956],\n",
       "        [1.        , 0.03709703, 0.10318531],\n",
       "        [2.        , 0.02390023, 0.11292029],\n",
       "        [3.        , 0.02838491, 0.09903454],\n",
       "        [4.        , 0.02121805, 0.10564355]]),\n",
       " array([[0.        , 0.04215817, 0.07973951],\n",
       "        [1.        , 0.02968822, 0.10307291],\n",
       "        [2.        , 0.07553931, 0.08576264],\n",
       "        [3.        , 0.03717035, 0.08679931],\n",
       "        [4.        , 0.02681353, 0.08719117]])]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6339e33a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col</th>\n",
       "      <th>imp</th>\n",
       "      <th>imp_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3442</th>\n",
       "      <td>cover_0</td>\n",
       "      <td>188.670119</td>\n",
       "      <td>43.606909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3470</th>\n",
       "      <td>min</td>\n",
       "      <td>79.169690</td>\n",
       "      <td>47.593659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3468</th>\n",
       "      <td>mean</td>\n",
       "      <td>55.448515</td>\n",
       "      <td>34.489858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3477</th>\n",
       "      <td>std</td>\n",
       "      <td>28.758034</td>\n",
       "      <td>11.427822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3466</th>\n",
       "      <td>max</td>\n",
       "      <td>6.084168</td>\n",
       "      <td>4.076325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>MAX_GEMI_2017</td>\n",
       "      <td>3.023788</td>\n",
       "      <td>1.074437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1042</th>\n",
       "      <td>MAX_TIRS1_2014</td>\n",
       "      <td>2.451206</td>\n",
       "      <td>3.931257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3443</th>\n",
       "      <td>cover_1</td>\n",
       "      <td>2.441550</td>\n",
       "      <td>0.833542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3356</th>\n",
       "      <td>MIN_VARIgreen_2014</td>\n",
       "      <td>1.860930</td>\n",
       "      <td>1.093803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2803</th>\n",
       "      <td>MIN_GLI_2018</td>\n",
       "      <td>1.736956</td>\n",
       "      <td>1.426598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1052</th>\n",
       "      <td>MAX_TIRS2_2003</td>\n",
       "      <td>1.485362</td>\n",
       "      <td>0.963235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>MAX_BRI</td>\n",
       "      <td>1.472041</td>\n",
       "      <td>1.004456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1354</th>\n",
       "      <td>MED_CVI_2020</td>\n",
       "      <td>1.363068</td>\n",
       "      <td>0.726235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2802</th>\n",
       "      <td>MIN_GLI_2017</td>\n",
       "      <td>1.334591</td>\n",
       "      <td>0.354833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3303</th>\n",
       "      <td>MIN_TIRS2_2003</td>\n",
       "      <td>1.331777</td>\n",
       "      <td>0.759139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3219</th>\n",
       "      <td>MIN_SLAVI_2005</td>\n",
       "      <td>1.308037</td>\n",
       "      <td>0.673442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2910</th>\n",
       "      <td>MIN_IF_2017</td>\n",
       "      <td>1.289306</td>\n",
       "      <td>0.656295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2980</th>\n",
       "      <td>MIN_MCARI_MTVI2</td>\n",
       "      <td>1.252010</td>\n",
       "      <td>0.763125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1375</th>\n",
       "      <td>MED_Chlgreen_2020</td>\n",
       "      <td>1.240267</td>\n",
       "      <td>0.527382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3453</th>\n",
       "      <td>depth</td>\n",
       "      <td>1.185491</td>\n",
       "      <td>1.543779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3232</th>\n",
       "      <td>MIN_SLAVI_2018</td>\n",
       "      <td>1.175109</td>\n",
       "      <td>0.572984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1392</th>\n",
       "      <td>MED_Chlred_edge_2015</td>\n",
       "      <td>1.163705</td>\n",
       "      <td>1.955410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3454</th>\n",
       "      <td>depth_original</td>\n",
       "      <td>1.098139</td>\n",
       "      <td>0.567135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2361</th>\n",
       "      <td>MIN_BWDRVI_2016</td>\n",
       "      <td>1.081077</td>\n",
       "      <td>1.644283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3360</th>\n",
       "      <td>MIN_VARIgreen_2018</td>\n",
       "      <td>1.051595</td>\n",
       "      <td>1.451000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2178</th>\n",
       "      <td>MED_TIRS2_2003</td>\n",
       "      <td>1.044486</td>\n",
       "      <td>1.093290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1765</th>\n",
       "      <td>MED_H_2019</td>\n",
       "      <td>0.977717</td>\n",
       "      <td>1.194490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3361</th>\n",
       "      <td>MIN_VARIgreen_2019</td>\n",
       "      <td>0.936849</td>\n",
       "      <td>1.995720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2800</th>\n",
       "      <td>MIN_GLI_2015</td>\n",
       "      <td>0.876984</td>\n",
       "      <td>0.224950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1418</th>\n",
       "      <td>MED_Cigreen_2020</td>\n",
       "      <td>0.871109</td>\n",
       "      <td>0.494261</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       col         imp    imp_std\n",
       "3442               cover_0  188.670119  43.606909\n",
       "3470                   min   79.169690  47.593659\n",
       "3468                  mean   55.448515  34.489858\n",
       "3477                   std   28.758034  11.427822\n",
       "3466                   max    6.084168   4.076325\n",
       "528          MAX_GEMI_2017    3.023788   1.074437\n",
       "1042        MAX_TIRS1_2014    2.451206   3.931257\n",
       "3443               cover_1    2.441550   0.833542\n",
       "3356    MIN_VARIgreen_2014    1.860930   1.093803\n",
       "2803          MIN_GLI_2018    1.736956   1.426598\n",
       "1052        MAX_TIRS2_2003    1.485362   0.963235\n",
       "91                 MAX_BRI    1.472041   1.004456\n",
       "1354          MED_CVI_2020    1.363068   0.726235\n",
       "2802          MIN_GLI_2017    1.334591   0.354833\n",
       "3303        MIN_TIRS2_2003    1.331777   0.759139\n",
       "3219        MIN_SLAVI_2005    1.308037   0.673442\n",
       "2910           MIN_IF_2017    1.289306   0.656295\n",
       "2980       MIN_MCARI_MTVI2    1.252010   0.763125\n",
       "1375     MED_Chlgreen_2020    1.240267   0.527382\n",
       "3453                 depth    1.185491   1.543779\n",
       "3232        MIN_SLAVI_2018    1.175109   0.572984\n",
       "1392  MED_Chlred_edge_2015    1.163705   1.955410\n",
       "3454        depth_original    1.098139   0.567135\n",
       "2361       MIN_BWDRVI_2016    1.081077   1.644283\n",
       "3360    MIN_VARIgreen_2018    1.051595   1.451000\n",
       "2178        MED_TIRS2_2003    1.044486   1.093290\n",
       "1765            MED_H_2019    0.977717   1.194490\n",
       "3361    MIN_VARIgreen_2019    0.936849   1.995720\n",
       "2800          MIN_GLI_2015    0.876984   0.224950\n",
       "1418      MED_Cigreen_2020    0.871109   0.494261"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp[2].sort_values('imp',ascending=False)[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d209bcc",
   "metadata": {},
   "source": [
    "### 3-2-3 地理的区域毎、かつサブクラス毎に学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "cbd6782e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lgb_9(input_X,\n",
    "              input_y,\n",
    "              input_id,\n",
    "              params,\n",
    "              list_nfold=[0, 1, 2, 3, 4],\n",
    "              n_splits=5,\n",
    "              cls_num=3,\n",
    "              cls_num_2=3,\n",
    "              ):\n",
    "    metrics_list = []\n",
    "    train_oof_list =[]\n",
    "    imp_list =[]\n",
    "    for i in range(cls_num):\n",
    "        tmp_2_X = input_X[input_X['cluster_id'] == i]\n",
    "        tmp_2_y = input_y[input_y['cluster_id'] == i]\n",
    "        tmp_2_id = input_id[input_id['cluster_id'] == i]\n",
    "        \n",
    "        for j in range(cls_num_2):\n",
    "                tmp_X = tmp_2_X[tmp_2_X['cls_id_2'] == j]\n",
    "                tmp_y = tmp_2_y[tmp_2_y['cls_id_2'] == j]\n",
    "                tmp_id = tmp_2_id[tmp_2_id['cls_id_2'] == j]\n",
    "            \n",
    "                tmp_y.drop(columns=['cluster_id','cls_id_2'], inplace=True)\n",
    "                tmp_id.drop(columns=['cluster_id','cls_id_2'], inplace=True)\n",
    "                tmp_X.reset_index(drop=True, inplace=True)\n",
    "                tmp_y.reset_index(drop=True, inplace=True)\n",
    "                tmp_id.reset_index(drop=True, inplace=True)\n",
    "\n",
    "                train_oof = np.zeros(len(tmp_X))\n",
    "                metrics = []\n",
    "                imp = pd.DataFrame()\n",
    "\n",
    "                # cross-validation\n",
    "                cv = list(KFold(n_splits, random_state=123, shuffle=True).split(\n",
    "                    tmp_X, tmp_y))\n",
    "\n",
    "                for nfold in list_nfold:\n",
    "                    print(\"-\" * 20, nfold, \"-\" * 20)\n",
    "                    idx_tr, idx_va = cv[nfold][0], cv[nfold][1]\n",
    "                    X_tr, y_tr, id_tr = tmp_X.loc[idx_tr, :], tmp_y.loc[idx_tr], \\\n",
    "                                        tmp_id.loc[idx_tr, :]\n",
    "                    X_va, y_va, id_va = tmp_X.loc[idx_va, :], tmp_y.loc[idx_va], \\\n",
    "                                        tmp_id.loc[idx_va, :]\n",
    "                    print(X_tr.shape, y_tr.shape)\n",
    "\n",
    "                    # train\n",
    "                    model = lgb.LGBMRegressor(**params)\n",
    "                    model.fit(X_tr,\n",
    "                              y_tr,\n",
    "                              eval_set=[(X_tr, y_tr), (X_va, y_va)],\n",
    "                              early_stopping_rounds=50,\n",
    "                              verbose=100,\n",
    "                              )\n",
    "                    fname_lgb = \"model_sbmt_1_6_cls{0}_{1}_lgb_fold{2}.pickle\".format(\n",
    "                        i,j, nfold)\n",
    "                    with open(fname_lgb, \"wb\") as f:\n",
    "                        pickle.dump(model, f, protocol=4)\n",
    "\n",
    "                    # evaluate\n",
    "                    y_tr_pred = model.predict(X_tr)\n",
    "                    y_va_pred = model.predict(X_va)\n",
    "                    metric_tr = np.sqrt(mean_squared_error(y_tr, y_tr_pred))\n",
    "                    metric_va = np.sqrt(mean_squared_error(y_va, y_va_pred))\n",
    "                    metrics.append([nfold, metric_tr, metric_va])\n",
    "                    print(\"[RMSE] tr: {:.4f}, va: {:.4f}\".format(metric_tr, metric_va))\n",
    "\n",
    "                    # oof\n",
    "                    train_oof[idx_va] = y_va_pred\n",
    "\n",
    "                    # imp\n",
    "                    _imp = pd.DataFrame(\n",
    "                        {\"col\": tmp_X.columns, \n",
    "                         \"imp\": model.feature_importances_, \n",
    "                         \"nfold\": nfold})\n",
    "                    imp = pd.concat([imp, _imp])\n",
    "\n",
    "                # metric\n",
    "                print(\"-\" * 20, \"cls{}_{}_result\".format(i,j), \"-\" * 20)\n",
    "                print(fname_lgb)\n",
    "                metrics = np.array(metrics)\n",
    "                print(metrics)\n",
    "                print(\"[cv] tr: {:.4f}+-{:.4f}, va: {:.4f}+-{:.4f}\".format(\n",
    "                    metrics[:, 1].mean(), metrics[:, 1].std(),\n",
    "                    metrics[:, 2].mean(), metrics[:, 2].std(),\n",
    "                ))\n",
    "                print(\"[oof]{:.4f}\".format(np.sqrt(mean_squared_error(tmp_y, train_oof))))\n",
    "                metrics_list.append(metrics)\n",
    "\n",
    "                # oof\n",
    "                train_oof = pd.concat([tmp_id, pd.DataFrame({\"pred\": train_oof})], axis=1)\n",
    "                train_oof_list.append(train_oof)\n",
    "\n",
    "                # importance\n",
    "                imp = imp.groupby(\"col\")[\"imp\"].agg([\"mean\", \"std\"]).reset_index(drop=False)\n",
    "                imp.columns = [\"col\", \"imp\", \"imp_std\"]\n",
    "                imp_list.append(imp)        \n",
    "\n",
    "    return train_oof_list, imp_list, metrics_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0ee1a682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 0 --------------------\n",
      "(1741, 3482) (1741, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.0577995\tvalid_1's rmse: 0.0853211\n",
      "[200]\ttraining's rmse: 0.0430167\tvalid_1's rmse: 0.0834213\n",
      "[300]\ttraining's rmse: 0.0338167\tvalid_1's rmse: 0.0827284\n",
      "Early stopping, best iteration is:\n",
      "[333]\ttraining's rmse: 0.0314572\tvalid_1's rmse: 0.0822579\n",
      "[RMSE] tr: 0.0315, va: 0.0823\n",
      "-------------------- 1 --------------------\n",
      "(1741, 3482) (1741, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.0618969\tvalid_1's rmse: 0.0694888\n",
      "[200]\ttraining's rmse: 0.0471199\tvalid_1's rmse: 0.0657534\n",
      "Early stopping, best iteration is:\n",
      "[172]\ttraining's rmse: 0.050605\tvalid_1's rmse: 0.0656452\n",
      "[RMSE] tr: 0.0506, va: 0.0656\n",
      "-------------------- 2 --------------------\n",
      "(1742, 3482) (1742, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.0598557\tvalid_1's rmse: 0.0720892\n",
      "[200]\ttraining's rmse: 0.0453496\tvalid_1's rmse: 0.0691987\n",
      "Early stopping, best iteration is:\n",
      "[249]\ttraining's rmse: 0.040483\tvalid_1's rmse: 0.0688311\n",
      "[RMSE] tr: 0.0405, va: 0.0688\n",
      "-------------------- 3 --------------------\n",
      "(1742, 3482) (1742, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.0580303\tvalid_1's rmse: 0.0827625\n",
      "[200]\ttraining's rmse: 0.0429525\tvalid_1's rmse: 0.0819548\n",
      "Early stopping, best iteration is:\n",
      "[187]\ttraining's rmse: 0.0444407\tvalid_1's rmse: 0.0816999\n",
      "[RMSE] tr: 0.0444, va: 0.0817\n",
      "-------------------- 4 --------------------\n",
      "(1742, 3482) (1742, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.0598919\tvalid_1's rmse: 0.0709374\n",
      "[200]\ttraining's rmse: 0.0448526\tvalid_1's rmse: 0.0681166\n",
      "[300]\ttraining's rmse: 0.0354896\tvalid_1's rmse: 0.0666522\n",
      "[400]\ttraining's rmse: 0.0287521\tvalid_1's rmse: 0.0661989\n",
      "[500]\ttraining's rmse: 0.0239026\tvalid_1's rmse: 0.0655274\n",
      "Early stopping, best iteration is:\n",
      "[485]\ttraining's rmse: 0.0244843\tvalid_1's rmse: 0.0654365\n",
      "[RMSE] tr: 0.0245, va: 0.0654\n",
      "-------------------- cls0_0_result --------------------\n",
      "model_sbmt_1_6_cls0_0_lgb_fold4.pickle\n",
      "[[0.         0.03145719 0.08225792]\n",
      " [1.         0.05060498 0.06564522]\n",
      " [2.         0.04048305 0.06883107]\n",
      " [3.         0.04444071 0.08169995]\n",
      " [4.         0.02448431 0.06543654]]\n",
      "[cv] tr: 0.0383+-0.0093, va: 0.0728+-0.0076\n",
      "[oof]0.0732\n",
      "-------------------- 0 --------------------\n",
      "(1407, 3482) (1407, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.0849431\tvalid_1's rmse: 0.121634\n",
      "[200]\ttraining's rmse: 0.0600591\tvalid_1's rmse: 0.11699\n",
      "[300]\ttraining's rmse: 0.045673\tvalid_1's rmse: 0.114961\n",
      "[400]\ttraining's rmse: 0.0361798\tvalid_1's rmse: 0.114484\n",
      "Early stopping, best iteration is:\n",
      "[406]\ttraining's rmse: 0.0357971\tvalid_1's rmse: 0.114403\n",
      "[RMSE] tr: 0.0358, va: 0.1144\n",
      "-------------------- 1 --------------------\n",
      "(1407, 3482) (1407, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.0820052\tvalid_1's rmse: 0.129912\n",
      "[200]\ttraining's rmse: 0.0565197\tvalid_1's rmse: 0.128097\n",
      "[300]\ttraining's rmse: 0.0425982\tvalid_1's rmse: 0.126618\n",
      "[400]\ttraining's rmse: 0.0340165\tvalid_1's rmse: 0.126196\n",
      "Early stopping, best iteration is:\n",
      "[359]\ttraining's rmse: 0.0371199\tvalid_1's rmse: 0.125776\n",
      "[RMSE] tr: 0.0371, va: 0.1258\n",
      "-------------------- 2 --------------------\n",
      "(1407, 3482) (1407, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.0785453\tvalid_1's rmse: 0.141795\n",
      "Early stopping, best iteration is:\n",
      "[75]\ttraining's rmse: 0.0885006\tvalid_1's rmse: 0.141064\n",
      "[RMSE] tr: 0.0885, va: 0.1411\n",
      "-------------------- 3 --------------------\n",
      "(1407, 3482) (1407, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.0830577\tvalid_1's rmse: 0.1275\n",
      "[200]\ttraining's rmse: 0.05914\tvalid_1's rmse: 0.122036\n",
      "[300]\ttraining's rmse: 0.0450103\tvalid_1's rmse: 0.119911\n",
      "[400]\ttraining's rmse: 0.0358862\tvalid_1's rmse: 0.119286\n",
      "[500]\ttraining's rmse: 0.0298568\tvalid_1's rmse: 0.119075\n",
      "Early stopping, best iteration is:\n",
      "[549]\ttraining's rmse: 0.0276175\tvalid_1's rmse: 0.118882\n",
      "[RMSE] tr: 0.0276, va: 0.1189\n",
      "-------------------- 4 --------------------\n",
      "(1408, 3482) (1408, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's rmse: 0.0844656\tvalid_1's rmse: 0.119983\n",
      "[200]\ttraining's rmse: 0.0595386\tvalid_1's rmse: 0.115405\n",
      "[300]\ttraining's rmse: 0.0452109\tvalid_1's rmse: 0.114284\n",
      "Early stopping, best iteration is:\n",
      "[330]\ttraining's rmse: 0.0419046\tvalid_1's rmse: 0.113773\n",
      "[RMSE] tr: 0.0419, va: 0.1138\n",
      "-------------------- cls0_1_result --------------------\n",
      "model_sbmt_1_6_cls0_1_lgb_fold4.pickle\n",
      "[[0.         0.03579707 0.11440256]\n",
      " [1.         0.03711991 0.12577636]\n",
      " [2.         0.08850061 0.14106388]\n",
      " [3.         0.02761745 0.11888153]\n",
      " [4.         0.04190457 0.11377251]]\n",
      "[cv] tr: 0.0462+-0.0217, va: 0.1228+-0.0101\n",
      "[oof]0.1232\n",
      "-------------------- 0 --------------------\n",
      "(928, 3482) (928, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.115212\tvalid_1's rmse: 0.180685\n",
      "[200]\ttraining's rmse: 0.0800909\tvalid_1's rmse: 0.179715\n",
      "[300]\ttraining's rmse: 0.0614966\tvalid_1's rmse: 0.177017\n",
      "Early stopping, best iteration is:\n",
      "[319]\ttraining's rmse: 0.058716\tvalid_1's rmse: 0.176449\n",
      "[RMSE] tr: 0.0587, va: 0.1764\n",
      "-------------------- 1 --------------------\n",
      "(929, 3482) (929, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.115327\tvalid_1's rmse: 0.184905\n",
      "Early stopping, best iteration is:\n",
      "[120]\ttraining's rmse: 0.106081\tvalid_1's rmse: 0.183668\n",
      "[RMSE] tr: 0.1061, va: 0.1837\n",
      "-------------------- 2 --------------------\n",
      "(929, 3482) (929, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.116197\tvalid_1's rmse: 0.175105\n",
      "[200]\ttraining's rmse: 0.0818101\tvalid_1's rmse: 0.172317\n",
      "[300]\ttraining's rmse: 0.0627698\tvalid_1's rmse: 0.171404\n",
      "Early stopping, best iteration is:\n",
      "[260]\ttraining's rmse: 0.0691651\tvalid_1's rmse: 0.170881\n",
      "[RMSE] tr: 0.0692, va: 0.1709\n",
      "-------------------- 3 --------------------\n",
      "(929, 3482) (929, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.118089\tvalid_1's rmse: 0.180028\n",
      "[200]\ttraining's rmse: 0.0831501\tvalid_1's rmse: 0.17114\n",
      "[300]\ttraining's rmse: 0.0644115\tvalid_1's rmse: 0.166809\n",
      "[400]\ttraining's rmse: 0.0525136\tvalid_1's rmse: 0.16482\n",
      "[500]\ttraining's rmse: 0.0450054\tvalid_1's rmse: 0.162461\n",
      "Early stopping, best iteration is:\n",
      "[542]\ttraining's rmse: 0.0424796\tvalid_1's rmse: 0.162018\n",
      "[RMSE] tr: 0.0425, va: 0.1620\n",
      "-------------------- 4 --------------------\n",
      "(929, 3482) (929, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.11389\tvalid_1's rmse: 0.192138\n",
      "Early stopping, best iteration is:\n",
      "[104]\ttraining's rmse: 0.11211\tvalid_1's rmse: 0.191801\n",
      "[RMSE] tr: 0.1121, va: 0.1918\n",
      "-------------------- cls0_2_result --------------------\n",
      "model_sbmt_1_6_cls0_2_lgb_fold4.pickle\n",
      "[[0.         0.05871604 0.17644928]\n",
      " [1.         0.10608069 0.1836682 ]\n",
      " [2.         0.06916512 0.17088142]\n",
      " [3.         0.04247962 0.16201819]\n",
      " [4.         0.11211039 0.19180061]]\n",
      "[cv] tr: 0.0777+-0.0271, va: 0.1770+-0.0103\n",
      "[oof]0.1773\n",
      "-------------------- 0 --------------------\n",
      "(432, 3482) (432, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.10743\tvalid_1's rmse: 0.1665\n",
      "[200]\ttraining's rmse: 0.0875483\tvalid_1's rmse: 0.161662\n",
      "[300]\ttraining's rmse: 0.075683\tvalid_1's rmse: 0.159185\n",
      "[400]\ttraining's rmse: 0.0663111\tvalid_1's rmse: 0.157006\n",
      "[500]\ttraining's rmse: 0.0585191\tvalid_1's rmse: 0.156201\n",
      "Early stopping, best iteration is:\n",
      "[455]\ttraining's rmse: 0.0619742\tvalid_1's rmse: 0.155779\n",
      "[RMSE] tr: 0.0620, va: 0.1558\n",
      "-------------------- 1 --------------------\n",
      "(432, 3482) (432, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.111312\tvalid_1's rmse: 0.149777\n",
      "[200]\ttraining's rmse: 0.0891904\tvalid_1's rmse: 0.145902\n",
      "Early stopping, best iteration is:\n",
      "[210]\ttraining's rmse: 0.0879376\tvalid_1's rmse: 0.145651\n",
      "[RMSE] tr: 0.0879, va: 0.1457\n",
      "-------------------- 2 --------------------\n",
      "(432, 3482) (432, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.108703\tvalid_1's rmse: 0.16035\n",
      "[200]\ttraining's rmse: 0.0877918\tvalid_1's rmse: 0.155083\n",
      "Early stopping, best iteration is:\n",
      "[227]\ttraining's rmse: 0.0840046\tvalid_1's rmse: 0.153817\n",
      "[RMSE] tr: 0.0840, va: 0.1538\n",
      "-------------------- 3 --------------------\n",
      "(432, 3482) (432, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.11069\tvalid_1's rmse: 0.146645\n",
      "[200]\ttraining's rmse: 0.0900046\tvalid_1's rmse: 0.144739\n",
      "[300]\ttraining's rmse: 0.0780429\tvalid_1's rmse: 0.143148\n",
      "Early stopping, best iteration is:\n",
      "[269]\ttraining's rmse: 0.0811424\tvalid_1's rmse: 0.142347\n",
      "[RMSE] tr: 0.0811, va: 0.1423\n",
      "-------------------- 4 --------------------\n",
      "(432, 3482) (432, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.112334\tvalid_1's rmse: 0.134462\n",
      "[200]\ttraining's rmse: 0.0914533\tvalid_1's rmse: 0.129877\n",
      "[300]\ttraining's rmse: 0.0783979\tvalid_1's rmse: 0.129701\n",
      "Early stopping, best iteration is:\n",
      "[274]\ttraining's rmse: 0.0811782\tvalid_1's rmse: 0.129023\n",
      "[RMSE] tr: 0.0812, va: 0.1290\n",
      "-------------------- cls1_0_result --------------------\n",
      "model_sbmt_1_6_cls1_0_lgb_fold4.pickle\n",
      "[[0.         0.06197422 0.15577918]\n",
      " [1.         0.0879376  0.14565119]\n",
      " [2.         0.08400462 0.15381696]\n",
      " [3.         0.0811424  0.14234665]\n",
      " [4.         0.08117818 0.12902339]]\n",
      "[cv] tr: 0.0792+-0.0090, va: 0.1453+-0.0096\n",
      "[oof]0.1456\n",
      "-------------------- 0 --------------------\n",
      "(2630, 3482) (2630, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.0456603\tvalid_1's rmse: 0.0645685\n",
      "[200]\ttraining's rmse: 0.0357753\tvalid_1's rmse: 0.0629457\n",
      "[300]\ttraining's rmse: 0.0297597\tvalid_1's rmse: 0.0627496\n",
      "Early stopping, best iteration is:\n",
      "[272]\ttraining's rmse: 0.0312978\tvalid_1's rmse: 0.062628\n",
      "[RMSE] tr: 0.0313, va: 0.0626\n",
      "-------------------- 1 --------------------\n",
      "(2630, 3482) (2630, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.0452594\tvalid_1's rmse: 0.0715256\n",
      "Early stopping, best iteration is:\n",
      "[74]\ttraining's rmse: 0.0491407\tvalid_1's rmse: 0.0712121\n",
      "[RMSE] tr: 0.0491, va: 0.0712\n",
      "-------------------- 2 --------------------\n",
      "(2630, 3482) (2630, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.0472162\tvalid_1's rmse: 0.0571253\n",
      "[200]\ttraining's rmse: 0.037444\tvalid_1's rmse: 0.0556779\n",
      "[300]\ttraining's rmse: 0.0313068\tvalid_1's rmse: 0.0556001\n",
      "Early stopping, best iteration is:\n",
      "[259]\ttraining's rmse: 0.033675\tvalid_1's rmse: 0.0554032\n",
      "[RMSE] tr: 0.0337, va: 0.0554\n",
      "-------------------- 3 --------------------\n",
      "(2631, 3482) (2631, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.0457797\tvalid_1's rmse: 0.0621876\n",
      "[200]\ttraining's rmse: 0.0365241\tvalid_1's rmse: 0.0618465\n",
      "Early stopping, best iteration is:\n",
      "[158]\ttraining's rmse: 0.0396568\tvalid_1's rmse: 0.0614348\n",
      "[RMSE] tr: 0.0397, va: 0.0614\n",
      "-------------------- 4 --------------------\n",
      "(2631, 3482) (2631, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.0476557\tvalid_1's rmse: 0.0514075\n",
      "[200]\ttraining's rmse: 0.0376358\tvalid_1's rmse: 0.0483852\n",
      "[300]\ttraining's rmse: 0.0310459\tvalid_1's rmse: 0.0477747\n",
      "[400]\ttraining's rmse: 0.0263833\tvalid_1's rmse: 0.0477582\n",
      "Early stopping, best iteration is:\n",
      "[374]\ttraining's rmse: 0.0274813\tvalid_1's rmse: 0.0475912\n",
      "[RMSE] tr: 0.0275, va: 0.0476\n",
      "-------------------- cls1_1_result --------------------\n",
      "model_sbmt_1_6_cls1_1_lgb_fold4.pickle\n",
      "[[0.         0.03129784 0.06262796]\n",
      " [1.         0.04914071 0.07121213]\n",
      " [2.         0.03367498 0.05540323]\n",
      " [3.         0.03965681 0.06143484]\n",
      " [4.         0.02748133 0.0475912 ]]\n",
      "[cv] tr: 0.0363+-0.0076, va: 0.0597+-0.0079\n",
      "[oof]0.0602\n",
      "-------------------- 0 --------------------\n",
      "(2100, 3482) (2100, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.0904484\tvalid_1's rmse: 0.143292\n",
      "[200]\ttraining's rmse: 0.0641482\tvalid_1's rmse: 0.139659\n",
      "[300]\ttraining's rmse: 0.0495195\tvalid_1's rmse: 0.138066\n",
      "[400]\ttraining's rmse: 0.0404511\tvalid_1's rmse: 0.137159\n",
      "[500]\ttraining's rmse: 0.0342978\tvalid_1's rmse: 0.136886\n",
      "Early stopping, best iteration is:\n",
      "[519]\ttraining's rmse: 0.0333411\tvalid_1's rmse: 0.136811\n",
      "[RMSE] tr: 0.0333, va: 0.1368\n",
      "-------------------- 1 --------------------\n",
      "(2100, 3482) (2100, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.0904132\tvalid_1's rmse: 0.145238\n",
      "[200]\ttraining's rmse: 0.0651728\tvalid_1's rmse: 0.141815\n",
      "[300]\ttraining's rmse: 0.0512532\tvalid_1's rmse: 0.140697\n",
      "[400]\ttraining's rmse: 0.0425602\tvalid_1's rmse: 0.140431\n",
      "[500]\ttraining's rmse: 0.0364521\tvalid_1's rmse: 0.139889\n",
      "Early stopping, best iteration is:\n",
      "[532]\ttraining's rmse: 0.0348662\tvalid_1's rmse: 0.139863\n",
      "[RMSE] tr: 0.0349, va: 0.1399\n",
      "-------------------- 2 --------------------\n",
      "(2100, 3482) (2100, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.0914424\tvalid_1's rmse: 0.136843\n",
      "[200]\ttraining's rmse: 0.0647843\tvalid_1's rmse: 0.132612\n",
      "[300]\ttraining's rmse: 0.0505755\tvalid_1's rmse: 0.130759\n",
      "[400]\ttraining's rmse: 0.0414477\tvalid_1's rmse: 0.129665\n",
      "Early stopping, best iteration is:\n",
      "[399]\ttraining's rmse: 0.0415173\tvalid_1's rmse: 0.129647\n",
      "[RMSE] tr: 0.0415, va: 0.1296\n",
      "-------------------- 3 --------------------\n",
      "(2100, 3482) (2100, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's rmse: 0.0913081\tvalid_1's rmse: 0.140317\n",
      "[200]\ttraining's rmse: 0.0645193\tvalid_1's rmse: 0.138133\n",
      "[300]\ttraining's rmse: 0.0507842\tvalid_1's rmse: 0.137478\n",
      "[400]\ttraining's rmse: 0.0421459\tvalid_1's rmse: 0.136189\n",
      "[500]\ttraining's rmse: 0.0364508\tvalid_1's rmse: 0.135452\n",
      "Early stopping, best iteration is:\n",
      "[539]\ttraining's rmse: 0.0348172\tvalid_1's rmse: 0.135146\n",
      "[RMSE] tr: 0.0348, va: 0.1351\n",
      "-------------------- 4 --------------------\n",
      "(2100, 3482) (2100, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.0904772\tvalid_1's rmse: 0.145458\n",
      "[200]\ttraining's rmse: 0.062868\tvalid_1's rmse: 0.142397\n",
      "[300]\ttraining's rmse: 0.0481597\tvalid_1's rmse: 0.140937\n",
      "[400]\ttraining's rmse: 0.0388078\tvalid_1's rmse: 0.140434\n",
      "Early stopping, best iteration is:\n",
      "[437]\ttraining's rmse: 0.0363688\tvalid_1's rmse: 0.140312\n",
      "[RMSE] tr: 0.0364, va: 0.1403\n",
      "-------------------- cls1_2_result --------------------\n",
      "model_sbmt_1_6_cls1_2_lgb_fold4.pickle\n",
      "[[0.         0.03334111 0.1368113 ]\n",
      " [1.         0.03486615 0.13986257]\n",
      " [2.         0.04151726 0.12964677]\n",
      " [3.         0.0348172  0.13514556]\n",
      " [4.         0.03636878 0.14031157]]\n",
      "[cv] tr: 0.0362+-0.0028, va: 0.1364+-0.0039\n",
      "[oof]0.1364\n",
      "-------------------- 0 --------------------\n",
      "(1797, 3482) (1797, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.0487134\tvalid_1's rmse: 0.0640634\n",
      "[200]\ttraining's rmse: 0.038809\tvalid_1's rmse: 0.0609151\n",
      "[300]\ttraining's rmse: 0.0326635\tvalid_1's rmse: 0.0593193\n",
      "[400]\ttraining's rmse: 0.0286363\tvalid_1's rmse: 0.0588634\n",
      "[500]\ttraining's rmse: 0.0253029\tvalid_1's rmse: 0.0587071\n",
      "Early stopping, best iteration is:\n",
      "[481]\ttraining's rmse: 0.0258632\tvalid_1's rmse: 0.058572\n",
      "[RMSE] tr: 0.0259, va: 0.0586\n",
      "-------------------- 1 --------------------\n",
      "(1797, 3482) (1797, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.0486271\tvalid_1's rmse: 0.070158\n",
      "[200]\ttraining's rmse: 0.0371056\tvalid_1's rmse: 0.0665235\n",
      "[300]\ttraining's rmse: 0.0307786\tvalid_1's rmse: 0.0658156\n",
      "[400]\ttraining's rmse: 0.0264117\tvalid_1's rmse: 0.0647762\n",
      "[500]\ttraining's rmse: 0.0227374\tvalid_1's rmse: 0.0643329\n",
      "[600]\ttraining's rmse: 0.0201458\tvalid_1's rmse: 0.063659\n",
      "Early stopping, best iteration is:\n",
      "[605]\ttraining's rmse: 0.0199925\tvalid_1's rmse: 0.0636058\n",
      "[RMSE] tr: 0.0200, va: 0.0636\n",
      "-------------------- 2 --------------------\n",
      "(1798, 3482) (1798, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.0479725\tvalid_1's rmse: 0.0750428\n",
      "[200]\ttraining's rmse: 0.0369692\tvalid_1's rmse: 0.0737564\n",
      "Early stopping, best iteration is:\n",
      "[219]\ttraining's rmse: 0.035422\tvalid_1's rmse: 0.0734689\n",
      "[RMSE] tr: 0.0354, va: 0.0735\n",
      "-------------------- 3 --------------------\n",
      "(1798, 3482) (1798, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.0514369\tvalid_1's rmse: 0.0526034\n",
      "[200]\ttraining's rmse: 0.0401838\tvalid_1's rmse: 0.0497618\n",
      "[300]\ttraining's rmse: 0.0339902\tvalid_1's rmse: 0.0492851\n",
      "[400]\ttraining's rmse: 0.0291556\tvalid_1's rmse: 0.0488778\n",
      "Early stopping, best iteration is:\n",
      "[353]\ttraining's rmse: 0.0312358\tvalid_1's rmse: 0.0487206\n",
      "[RMSE] tr: 0.0312, va: 0.0487\n",
      "-------------------- 4 --------------------\n",
      "(1798, 3482) (1798, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.0508978\tvalid_1's rmse: 0.0512772\n",
      "[200]\ttraining's rmse: 0.0389719\tvalid_1's rmse: 0.0504337\n",
      "Early stopping, best iteration is:\n",
      "[155]\ttraining's rmse: 0.0434462\tvalid_1's rmse: 0.0501314\n",
      "[RMSE] tr: 0.0434, va: 0.0501\n",
      "-------------------- cls2_0_result --------------------\n",
      "model_sbmt_1_6_cls2_0_lgb_fold4.pickle\n",
      "[[0.         0.02586323 0.05857202]\n",
      " [1.         0.0199925  0.06360579]\n",
      " [2.         0.035422   0.0734689 ]\n",
      " [3.         0.03123585 0.04872058]\n",
      " [4.         0.04344624 0.05013137]]\n",
      "[cv] tr: 0.0312+-0.0080, va: 0.0589+-0.0091\n",
      "[oof]0.0596\n",
      "-------------------- 0 --------------------\n",
      "(13, 3482) (13, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's rmse: 0.0974083\tvalid_1's rmse: 0.115333\n",
      "[RMSE] tr: 0.0650, va: 0.1290\n",
      "-------------------- 1 --------------------\n",
      "(13, 3482) (13, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's rmse: 0.108106\tvalid_1's rmse: 0.115344\n",
      "[RMSE] tr: 0.0738, va: 0.1099\n",
      "-------------------- 2 --------------------\n",
      "(14, 3482) (14, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's rmse: 0.128251\tvalid_1's rmse: 0.117157\n",
      "[RMSE] tr: 0.0907, va: 0.0337\n",
      "-------------------- 3 --------------------\n",
      "(14, 3482) (14, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's rmse: 0.130323\tvalid_1's rmse: 0.138571\n",
      "[RMSE] tr: 0.0900, va: 0.0443\n",
      "-------------------- 4 --------------------\n",
      "(14, 3482) (14, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's rmse: 0.130323\tvalid_1's rmse: 0.138571\n",
      "[RMSE] tr: 0.0900, va: 0.0443\n",
      "-------------------- cls2_1_result --------------------\n",
      "model_sbmt_1_6_cls2_1_lgb_fold4.pickle\n",
      "[[0.         0.06501197 0.12895811]\n",
      " [1.         0.07379598 0.10990792]\n",
      " [2.         0.09066061 0.03367259]\n",
      " [3.         0.08996859 0.04428572]\n",
      " [4.         0.08996859 0.04428572]]\n",
      "[cv] tr: 0.0819+-0.0106, va: 0.0722+-0.0392\n",
      "[oof]0.0875\n",
      "-------------------- 0 --------------------\n",
      "(260, 3482) (260, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.147718\tvalid_1's rmse: 0.230341\n",
      "[200]\ttraining's rmse: 0.114284\tvalid_1's rmse: 0.225341\n",
      "[300]\ttraining's rmse: 0.0931749\tvalid_1's rmse: 0.221059\n",
      "[400]\ttraining's rmse: 0.0787009\tvalid_1's rmse: 0.217516\n",
      "[500]\ttraining's rmse: 0.0674377\tvalid_1's rmse: 0.215819\n",
      "Early stopping, best iteration is:\n",
      "[527]\ttraining's rmse: 0.0647136\tvalid_1's rmse: 0.215308\n",
      "[RMSE] tr: 0.0647, va: 0.2153\n",
      "-------------------- 1 --------------------\n",
      "(261, 3482) (261, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.157645\tvalid_1's rmse: 0.157252\n",
      "[200]\ttraining's rmse: 0.120268\tvalid_1's rmse: 0.15163\n",
      "Early stopping, best iteration is:\n",
      "[225]\ttraining's rmse: 0.114377\tvalid_1's rmse: 0.151125\n",
      "[RMSE] tr: 0.1144, va: 0.1511\n",
      "-------------------- 2 --------------------\n",
      "(261, 3482) (261, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.15696\tvalid_1's rmse: 0.192618\n",
      "Early stopping, best iteration is:\n",
      "[135]\ttraining's rmse: 0.142058\tvalid_1's rmse: 0.188536\n",
      "[RMSE] tr: 0.1421, va: 0.1885\n",
      "-------------------- 3 --------------------\n",
      "(261, 3482) (261, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.14605\tvalid_1's rmse: 0.22367\n",
      "[200]\ttraining's rmse: 0.113407\tvalid_1's rmse: 0.215688\n",
      "[300]\ttraining's rmse: 0.0936026\tvalid_1's rmse: 0.21285\n",
      "[400]\ttraining's rmse: 0.079328\tvalid_1's rmse: 0.210844\n",
      "Early stopping, best iteration is:\n",
      "[376]\ttraining's rmse: 0.0820668\tvalid_1's rmse: 0.210305\n",
      "[RMSE] tr: 0.0821, va: 0.2103\n",
      "-------------------- 4 --------------------\n",
      "(261, 3482) (261, 1)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 0.147001\tvalid_1's rmse: 0.226346\n",
      "[200]\ttraining's rmse: 0.113674\tvalid_1's rmse: 0.222142\n",
      "[300]\ttraining's rmse: 0.0935338\tvalid_1's rmse: 0.218895\n",
      "[400]\ttraining's rmse: 0.0787366\tvalid_1's rmse: 0.215579\n",
      "Early stopping, best iteration is:\n",
      "[433]\ttraining's rmse: 0.0750005\tvalid_1's rmse: 0.214214\n",
      "[RMSE] tr: 0.0750, va: 0.2142\n",
      "-------------------- cls2_2_result --------------------\n",
      "model_sbmt_1_6_cls2_2_lgb_fold4.pickle\n",
      "[[0.         0.06471357 0.21530788]\n",
      " [1.         0.11437704 0.15112493]\n",
      " [2.         0.14205828 0.18853606]\n",
      " [3.         0.08206678 0.21030472]\n",
      " [4.         0.07500048 0.21421376]]\n",
      "[cv] tr: 0.0956+-0.0285, va: 0.1959+-0.0244\n",
      "[oof]0.1975\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression_l2',\n",
    "    'metric': 'Root_Mean_Squared_Error',\n",
    "    'learning_rate': 0.05,\n",
    "    'num_leaves': 32,\n",
    "    'subsample': 0.7,\n",
    "    'subsample_freq': 1,\n",
    "    'feature_fraction': 0.8,\n",
    "    'min_data_in_leaf': 50,\n",
    "    'min_sum_hessian_in_leaf': 50,\n",
    "    'n_estimators': 1000,\n",
    "    'random_state': 123,\n",
    "    'importance_type': 'gain',\n",
    "}\n",
    "\n",
    "train_oof_list, imp_list, metrics_list = train_lgb_9(X_train,\n",
    "                                                   y_train,\n",
    "                                                   id_train,\n",
    "                                                   params,\n",
    "                                                   list_nfold=[0,1,2,3,4],\n",
    "                                                   n_splits=5,\n",
    "                                                   cls_num=3,\n",
    "                                                   cls_num_2=3,\n",
    "                                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "58b4fc42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.        , 0.03145719, 0.08225792],\n",
       "        [1.        , 0.05060498, 0.06564522],\n",
       "        [2.        , 0.04048305, 0.06883107],\n",
       "        [3.        , 0.04444071, 0.08169995],\n",
       "        [4.        , 0.02448431, 0.06543654]]),\n",
       " array([[0.        , 0.03579707, 0.11440256],\n",
       "        [1.        , 0.03711991, 0.12577636],\n",
       "        [2.        , 0.08850061, 0.14106388],\n",
       "        [3.        , 0.02761745, 0.11888153],\n",
       "        [4.        , 0.04190457, 0.11377251]]),\n",
       " array([[0.        , 0.05871604, 0.17644928],\n",
       "        [1.        , 0.10608069, 0.1836682 ],\n",
       "        [2.        , 0.06916512, 0.17088142],\n",
       "        [3.        , 0.04247962, 0.16201819],\n",
       "        [4.        , 0.11211039, 0.19180061]]),\n",
       " array([[0.        , 0.06197422, 0.15577918],\n",
       "        [1.        , 0.0879376 , 0.14565119],\n",
       "        [2.        , 0.08400462, 0.15381696],\n",
       "        [3.        , 0.0811424 , 0.14234665],\n",
       "        [4.        , 0.08117818, 0.12902339]]),\n",
       " array([[0.        , 0.03129784, 0.06262796],\n",
       "        [1.        , 0.04914071, 0.07121213],\n",
       "        [2.        , 0.03367498, 0.05540323],\n",
       "        [3.        , 0.03965681, 0.06143484],\n",
       "        [4.        , 0.02748133, 0.0475912 ]]),\n",
       " array([[0.        , 0.03334111, 0.1368113 ],\n",
       "        [1.        , 0.03486615, 0.13986257],\n",
       "        [2.        , 0.04151726, 0.12964677],\n",
       "        [3.        , 0.0348172 , 0.13514556],\n",
       "        [4.        , 0.03636878, 0.14031157]]),\n",
       " array([[0.        , 0.02586323, 0.05857202],\n",
       "        [1.        , 0.0199925 , 0.06360579],\n",
       "        [2.        , 0.035422  , 0.0734689 ],\n",
       "        [3.        , 0.03123585, 0.04872058],\n",
       "        [4.        , 0.04344624, 0.05013137]]),\n",
       " array([[0.        , 0.06501197, 0.12895811],\n",
       "        [1.        , 0.07379598, 0.10990792],\n",
       "        [2.        , 0.09066061, 0.03367259],\n",
       "        [3.        , 0.08996859, 0.04428572],\n",
       "        [4.        , 0.08996859, 0.04428572]]),\n",
       " array([[0.        , 0.06471357, 0.21530788],\n",
       "        [1.        , 0.11437704, 0.15112493],\n",
       "        [2.        , 0.14205828, 0.18853606],\n",
       "        [3.        , 0.08206678, 0.21030472],\n",
       "        [4.        , 0.07500048, 0.21421376]])]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "42ac7c1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col</th>\n",
       "      <th>imp</th>\n",
       "      <th>imp_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3477</th>\n",
       "      <td>std</td>\n",
       "      <td>48.580179</td>\n",
       "      <td>30.636281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3442</th>\n",
       "      <td>cover_0</td>\n",
       "      <td>39.826205</td>\n",
       "      <td>19.962763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3470</th>\n",
       "      <td>min</td>\n",
       "      <td>34.518679</td>\n",
       "      <td>18.504829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3466</th>\n",
       "      <td>max</td>\n",
       "      <td>16.382101</td>\n",
       "      <td>13.280762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2799</th>\n",
       "      <td>MIN_GLI_2014</td>\n",
       "      <td>8.650922</td>\n",
       "      <td>6.469825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2907</th>\n",
       "      <td>MIN_IF_2014</td>\n",
       "      <td>6.649405</td>\n",
       "      <td>5.399920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2474</th>\n",
       "      <td>MIN_CVI_2016</td>\n",
       "      <td>5.732517</td>\n",
       "      <td>7.164911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1350</th>\n",
       "      <td>MED_CVI_2016</td>\n",
       "      <td>5.404938</td>\n",
       "      <td>5.085990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2238</th>\n",
       "      <td>MED_WVP</td>\n",
       "      <td>3.336001</td>\n",
       "      <td>2.261879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1676</th>\n",
       "      <td>MED_GLI_2016</td>\n",
       "      <td>2.566310</td>\n",
       "      <td>2.457506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2330</th>\n",
       "      <td>MIN_B02</td>\n",
       "      <td>2.321924</td>\n",
       "      <td>2.866379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>MAX_GEMI_2017</td>\n",
       "      <td>1.714120</td>\n",
       "      <td>1.230674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3468</th>\n",
       "      <td>mean</td>\n",
       "      <td>1.578527</td>\n",
       "      <td>2.179889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3035</th>\n",
       "      <td>MIN_NIR_2015</td>\n",
       "      <td>1.570189</td>\n",
       "      <td>1.315284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2361</th>\n",
       "      <td>MIN_BWDRVI_2016</td>\n",
       "      <td>1.363223</td>\n",
       "      <td>0.606131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1106</th>\n",
       "      <td>MAX_VARIgreen_2015</td>\n",
       "      <td>1.152027</td>\n",
       "      <td>0.741177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1953</th>\n",
       "      <td>MED_NormG_2016</td>\n",
       "      <td>0.988524</td>\n",
       "      <td>1.145275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>MAX_BRI</td>\n",
       "      <td>0.976193</td>\n",
       "      <td>0.716639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2586</th>\n",
       "      <td>MIN_D678_500_2020</td>\n",
       "      <td>0.962898</td>\n",
       "      <td>0.922683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>MAX_GDVI</td>\n",
       "      <td>0.940341</td>\n",
       "      <td>0.692437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>MAX_GLI</td>\n",
       "      <td>0.921423</td>\n",
       "      <td>1.106326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2097</th>\n",
       "      <td>MED_SLAVI_2008</td>\n",
       "      <td>0.902864</td>\n",
       "      <td>0.518078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3356</th>\n",
       "      <td>MIN_VARIgreen_2014</td>\n",
       "      <td>0.893024</td>\n",
       "      <td>0.839269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>MAX_Ferrous_Silicates_2015</td>\n",
       "      <td>0.820886</td>\n",
       "      <td>0.479401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>MAX_D678_500</td>\n",
       "      <td>0.815996</td>\n",
       "      <td>1.824623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2892</th>\n",
       "      <td>MIN_IF</td>\n",
       "      <td>0.814317</td>\n",
       "      <td>0.312661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3012</th>\n",
       "      <td>MIN_NDBI</td>\n",
       "      <td>0.798766</td>\n",
       "      <td>0.460502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>MED_Blue_2014</td>\n",
       "      <td>0.793733</td>\n",
       "      <td>0.912191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2725</th>\n",
       "      <td>MIN_Ferrous_Silicates_2007</td>\n",
       "      <td>0.783551</td>\n",
       "      <td>0.295554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2986</th>\n",
       "      <td>MIN_MSI</td>\n",
       "      <td>0.761458</td>\n",
       "      <td>0.967331</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             col        imp    imp_std\n",
       "3477                         std  48.580179  30.636281\n",
       "3442                     cover_0  39.826205  19.962763\n",
       "3470                         min  34.518679  18.504829\n",
       "3466                         max  16.382101  13.280762\n",
       "2799                MIN_GLI_2014   8.650922   6.469825\n",
       "2907                 MIN_IF_2014   6.649405   5.399920\n",
       "2474                MIN_CVI_2016   5.732517   7.164911\n",
       "1350                MED_CVI_2016   5.404938   5.085990\n",
       "2238                     MED_WVP   3.336001   2.261879\n",
       "1676                MED_GLI_2016   2.566310   2.457506\n",
       "2330                     MIN_B02   2.321924   2.866379\n",
       "528                MAX_GEMI_2017   1.714120   1.230674\n",
       "3468                        mean   1.578527   2.179889\n",
       "3035                MIN_NIR_2015   1.570189   1.315284\n",
       "2361             MIN_BWDRVI_2016   1.363223   0.606131\n",
       "1106          MAX_VARIgreen_2015   1.152027   0.741177\n",
       "1953              MED_NormG_2016   0.988524   1.145275\n",
       "91                       MAX_BRI   0.976193   0.716639\n",
       "2586           MIN_D678_500_2020   0.962898   0.922683\n",
       "510                     MAX_GDVI   0.940341   0.692437\n",
       "533                      MAX_GLI   0.921423   1.106326\n",
       "2097              MED_SLAVI_2008   0.902864   0.518078\n",
       "3356          MIN_VARIgreen_2014   0.893024   0.839269\n",
       "482   MAX_Ferrous_Silicates_2015   0.820886   0.479401\n",
       "314                 MAX_D678_500   0.815996   1.824623\n",
       "2892                      MIN_IF   0.814317   0.312661\n",
       "3012                    MIN_NDBI   0.798766   0.460502\n",
       "1257               MED_Blue_2014   0.793733   0.912191\n",
       "2725  MIN_Ferrous_Silicates_2007   0.783551   0.295554\n",
       "2986                     MIN_MSI   0.761458   0.967331"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp_list[8].sort_values('imp',ascending=False).head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2f7b98",
   "metadata": {},
   "source": [
    "# 4 予測\n",
    "## 4-1 予測用データ作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7d368928",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df[df['cover'] == 'a'].reset_index(drop=True)\n",
    "df_test = df_test.drop(columns=['cover'])\n",
    "col_cat = ['mesh20','cluster_id','cls_id_2']\n",
    "for col in col_cat:\n",
    "    df_test[col] = df_test[col].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ec8cc107",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df_test.copy()\n",
    "id_test = pd.DataFrame(df_test.index)\n",
    "id_test['cluster_id'] = df_test['cluster_id']\n",
    "id_test['cls_id_2'] = df_test['cls_id_2']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ec2844",
   "metadata": {},
   "source": [
    "## 4-2 予測\n",
    "- ３つの学習モデルをアンサンブル実施。重みづけは実施せず、平均値を予測値とした"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "067487e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_lgb_9(input_X,\n",
    "                input_id,\n",
    "                list_nfold_0=[0,1,2,3,4],\n",
    "                list_nfold_1=[0,1,2,3,4],\n",
    "                list_nfold_2=[0,1,2,3,4],\n",
    "               ):\n",
    "    pred_list = []\n",
    "    for i in range(3):\n",
    "            tmp_2_X = input_X[input_X['cluster_id'] == i]\n",
    "            tmp_2_id = input_id[input_id['cluster_id'] == i]\n",
    "            tmp_2_id.drop(columns=['cluster_id'], inplace=True)\n",
    "            \n",
    "            for j in range(3):                 \n",
    "                    tmp_X = tmp_2_X[tmp_2_X['cls_id_2'] == j]\n",
    "                    tmp_id = tmp_2_id[tmp_2_id['cls_id_2'] == j]\n",
    "                    tmp_id.drop(columns=['cls_id_2'], inplace=True)\n",
    "                    pred = np.zeros((len(tmp_X), \n",
    "                                     len(list_nfold_0)\n",
    "                                    + len(list_nfold_1) \n",
    "                                     + len(list_nfold_2)))\n",
    "                    \n",
    "                    for nfold in list_nfold_2:\n",
    "                        print(\"-\"*20, nfold, \"-\"*20)\n",
    "                        fname_lgb_1 = \"model_sbmt_1_6_cls{}_lgb_fold{}.pickle\".format(\n",
    "                            i,nfold)\n",
    "                        with open(fname_lgb_1, \"rb\") as f:\n",
    "                            model = pickle.load(f)\n",
    "                        pred[:, len(list_nfold_0) + \n",
    "                             len(list_nfold_1) + nfold] = model.predict(tmp_X)\n",
    "                                            \n",
    "                    for nfold in list_nfold_1:\n",
    "                        print(\"-\"*20, nfold, \"-\"*20)\n",
    "                        fname_lgb_2 = \"model_sbmt_1_6_cls{}_{}_lgb_fold{}.pickle\".format(\n",
    "                            i,j,nfold)\n",
    "                        with open(fname_lgb_2, \"rb\") as f:\n",
    "                            model = pickle.load(f)\n",
    "                        pred[:, len(list_nfold_0) + nfold] = model.predict(tmp_X)\n",
    "                    \n",
    "                    for nfold in list_nfold_0:\n",
    "                        print(\"-\"*20, nfold, \"-\"*20)\n",
    "                        fname_lgb_3 = \"model_sbmt_1_6_lgb_fold{}.pickle\".format(nfold)\n",
    "                        with open(fname_lgb_3, \"rb\") as f:\n",
    "                            model = pickle.load(f)\n",
    "                        pred[:, nfold] = model.predict(tmp_X)\n",
    "                    \n",
    "                    df_pred = pd.DataFrame({\"pred\": pred.mean(axis=1)})\n",
    "                    df_pred.index = tmp_id.index\n",
    "                    pred = pd.concat([\n",
    "                        tmp_id,df_pred,], axis=1)\n",
    "                    pred_list.append(pred)\n",
    "                    text = 'cls{}_{}_Done.'.format(i,j)\n",
    "                    print(len(tmp_X))\n",
    "                    print(text + '_' + fname_lgb_3 + '_' + fname_lgb_1 + '_' + fname_lgb_2)\n",
    "                    print(len(pred))                    \n",
    "\n",
    "    return pred_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2255bc27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 0 --------------------\n",
      "-------------------- 1 --------------------\n",
      "-------------------- 2 --------------------\n",
      "-------------------- 3 --------------------\n",
      "-------------------- 4 --------------------\n",
      "-------------------- 0 --------------------\n",
      "-------------------- 1 --------------------\n",
      "-------------------- 2 --------------------\n",
      "-------------------- 3 --------------------\n",
      "-------------------- 4 --------------------\n",
      "-------------------- 0 --------------------\n",
      "-------------------- 1 --------------------\n",
      "-------------------- 2 --------------------\n",
      "-------------------- 3 --------------------\n",
      "-------------------- 4 --------------------\n",
      "709\n",
      "cls0_0_Done._model_sbmt_1_6_lgb_fold4.pickle_model_sbmt_1_6_cls0_lgb_fold4.pickle_model_sbmt_1_6_cls0_0_lgb_fold4.pickle\n",
      "709\n",
      "-------------------- 0 --------------------\n",
      "-------------------- 1 --------------------\n",
      "-------------------- 2 --------------------\n",
      "-------------------- 3 --------------------\n",
      "-------------------- 4 --------------------\n",
      "-------------------- 0 --------------------\n",
      "-------------------- 1 --------------------\n",
      "-------------------- 2 --------------------\n",
      "-------------------- 3 --------------------\n",
      "-------------------- 4 --------------------\n",
      "-------------------- 0 --------------------\n",
      "-------------------- 1 --------------------\n",
      "-------------------- 2 --------------------\n",
      "-------------------- 3 --------------------\n",
      "-------------------- 4 --------------------\n",
      "187\n",
      "cls0_1_Done._model_sbmt_1_6_lgb_fold4.pickle_model_sbmt_1_6_cls0_lgb_fold4.pickle_model_sbmt_1_6_cls0_1_lgb_fold4.pickle\n",
      "187\n",
      "-------------------- 0 --------------------\n",
      "-------------------- 1 --------------------\n",
      "-------------------- 2 --------------------\n",
      "-------------------- 3 --------------------\n",
      "-------------------- 4 --------------------\n",
      "-------------------- 0 --------------------\n",
      "-------------------- 1 --------------------\n",
      "-------------------- 2 --------------------\n",
      "-------------------- 3 --------------------\n",
      "-------------------- 4 --------------------\n",
      "-------------------- 0 --------------------\n",
      "-------------------- 1 --------------------\n",
      "-------------------- 2 --------------------\n",
      "-------------------- 3 --------------------\n",
      "-------------------- 4 --------------------\n",
      "244\n",
      "cls0_2_Done._model_sbmt_1_6_lgb_fold4.pickle_model_sbmt_1_6_cls0_lgb_fold4.pickle_model_sbmt_1_6_cls0_2_lgb_fold4.pickle\n",
      "244\n",
      "-------------------- 0 --------------------\n",
      "-------------------- 1 --------------------\n",
      "-------------------- 2 --------------------\n",
      "-------------------- 3 --------------------\n",
      "-------------------- 4 --------------------\n",
      "-------------------- 0 --------------------\n",
      "-------------------- 1 --------------------\n",
      "-------------------- 2 --------------------\n",
      "-------------------- 3 --------------------\n",
      "-------------------- 4 --------------------\n",
      "-------------------- 0 --------------------\n",
      "-------------------- 1 --------------------\n",
      "-------------------- 2 --------------------\n",
      "-------------------- 3 --------------------\n",
      "-------------------- 4 --------------------\n",
      "47\n",
      "cls1_0_Done._model_sbmt_1_6_lgb_fold4.pickle_model_sbmt_1_6_cls1_lgb_fold4.pickle_model_sbmt_1_6_cls1_0_lgb_fold4.pickle\n",
      "47\n",
      "-------------------- 0 --------------------\n",
      "-------------------- 1 --------------------\n",
      "-------------------- 2 --------------------\n",
      "-------------------- 3 --------------------\n",
      "-------------------- 4 --------------------\n",
      "-------------------- 0 --------------------\n",
      "-------------------- 1 --------------------\n",
      "-------------------- 2 --------------------\n",
      "-------------------- 3 --------------------\n",
      "-------------------- 4 --------------------\n",
      "-------------------- 0 --------------------\n",
      "-------------------- 1 --------------------\n",
      "-------------------- 2 --------------------\n",
      "-------------------- 3 --------------------\n",
      "-------------------- 4 --------------------\n",
      "891\n",
      "cls1_1_Done._model_sbmt_1_6_lgb_fold4.pickle_model_sbmt_1_6_cls1_lgb_fold4.pickle_model_sbmt_1_6_cls1_1_lgb_fold4.pickle\n",
      "891\n",
      "-------------------- 0 --------------------\n",
      "-------------------- 1 --------------------\n",
      "-------------------- 2 --------------------\n",
      "-------------------- 3 --------------------\n",
      "-------------------- 4 --------------------\n",
      "-------------------- 0 --------------------\n",
      "-------------------- 1 --------------------\n",
      "-------------------- 2 --------------------\n",
      "-------------------- 3 --------------------\n",
      "-------------------- 4 --------------------\n",
      "-------------------- 0 --------------------\n",
      "-------------------- 1 --------------------\n",
      "-------------------- 2 --------------------\n",
      "-------------------- 3 --------------------\n",
      "-------------------- 4 --------------------\n",
      "724\n",
      "cls1_2_Done._model_sbmt_1_6_lgb_fold4.pickle_model_sbmt_1_6_cls1_lgb_fold4.pickle_model_sbmt_1_6_cls1_2_lgb_fold4.pickle\n",
      "724\n",
      "-------------------- 0 --------------------\n",
      "-------------------- 1 --------------------\n",
      "-------------------- 2 --------------------\n",
      "-------------------- 3 --------------------\n",
      "-------------------- 4 --------------------\n",
      "-------------------- 0 --------------------\n",
      "-------------------- 1 --------------------\n",
      "-------------------- 2 --------------------\n",
      "-------------------- 3 --------------------\n",
      "-------------------- 4 --------------------\n",
      "-------------------- 0 --------------------\n",
      "-------------------- 1 --------------------\n",
      "-------------------- 2 --------------------\n",
      "-------------------- 3 --------------------\n",
      "-------------------- 4 --------------------\n",
      "187\n",
      "cls2_0_Done._model_sbmt_1_6_lgb_fold4.pickle_model_sbmt_1_6_cls2_lgb_fold4.pickle_model_sbmt_1_6_cls2_0_lgb_fold4.pickle\n",
      "187\n",
      "-------------------- 0 --------------------\n",
      "-------------------- 1 --------------------\n",
      "-------------------- 2 --------------------\n",
      "-------------------- 3 --------------------\n",
      "-------------------- 4 --------------------\n",
      "-------------------- 0 --------------------\n",
      "-------------------- 1 --------------------\n",
      "-------------------- 2 --------------------\n",
      "-------------------- 3 --------------------\n",
      "-------------------- 4 --------------------\n",
      "-------------------- 0 --------------------\n",
      "-------------------- 1 --------------------\n",
      "-------------------- 2 --------------------\n",
      "-------------------- 3 --------------------\n",
      "-------------------- 4 --------------------\n",
      "671\n",
      "cls2_1_Done._model_sbmt_1_6_lgb_fold4.pickle_model_sbmt_1_6_cls2_lgb_fold4.pickle_model_sbmt_1_6_cls2_1_lgb_fold4.pickle\n",
      "671\n",
      "-------------------- 0 --------------------\n",
      "-------------------- 1 --------------------\n",
      "-------------------- 2 --------------------\n",
      "-------------------- 3 --------------------\n",
      "-------------------- 4 --------------------\n",
      "-------------------- 0 --------------------\n",
      "-------------------- 1 --------------------\n",
      "-------------------- 2 --------------------\n",
      "-------------------- 3 --------------------\n",
      "-------------------- 4 --------------------\n",
      "-------------------- 0 --------------------\n",
      "-------------------- 1 --------------------\n",
      "-------------------- 2 --------------------\n",
      "-------------------- 3 --------------------\n",
      "-------------------- 4 --------------------\n",
      "379\n",
      "cls2_2_Done._model_sbmt_1_6_lgb_fold4.pickle_model_sbmt_1_6_cls2_lgb_fold4.pickle_model_sbmt_1_6_cls2_2_lgb_fold4.pickle\n",
      "379\n"
     ]
    }
   ],
   "source": [
    "test_pred_2 = predict_lgb_9(\n",
    "    X_test,id_test,list_nfold_1=[0,1,2,3,4],list_nfold_2=[0,1,2,3,4],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f65072c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = pd.DataFrame()\n",
    "for i in range(9):\n",
    "    tmp = test_pred_2[i]\n",
    "    test_pred = pd.concat([test_pred,tmp])\n",
    "test_pred = test_pred.sort_values(0)\n",
    "# 負の値はゼロに、１を超えた値は１に修正\n",
    "test_pred['pred'] = test_pred['pred'].apply(lambda x: 0 if x<0 else (1 if x>1 else x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c126f87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred.to_csv(\"sbmt_test_1_6.csv\", header=False,index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
